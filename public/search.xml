<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title><![CDATA[git常用命令总结]]></title>
    <url>%2F2018%2F07%2F21%2F2018-7-21-git-cmd-summary%2F</url>
    <content type="text"><![CDATA[版本控制系统（VCS） 版本控制系统（Version Control System）是一种记录一个或若干文件内容变化历史的系统。集中化的版本控制系统(CVS，SVN) 分布式版本控制系统（Git) Git 的诞生 Git是目前世界上最先进的分布式版本控制系统（没有之一） 好不好用，看看它的开发者是谁就知道了：Linux之父 Linus Torvalds Linux内核社区原本使用的是名为BitKeeper的商业化版本控制工具，2005年，因为社区内有人试图破解BitKeeper的协议，BitMover公司收回了免费使用BitKeeper的权力； Linus原本可以出面道个歉，继续使用BitKeeper，然而并没有… Linus大神仅用了两周时间，自已用C写了一个分布式版本控制系统，于是Git诞生了！ Git 与GitHub Git： 是一种开源的版本控制系统，可以高效的管理项目版本，同时也是一种协议； GitHub： 是一个面向开源及私有软件项目的托管平台, 私有项目收费； GitLab： 社区版相当于私有版的github，可以自己搭建GitLab仓库服务器，企业版收费； Gitee：码云(gitee.com)是开源中国推出的代码托管平台,支持 Git 和 SVN,提供免费的私有仓库托管；linus大叔 Git基本原理 git add files 把当前文件放入暂存区域。 git commit 给暂存区域生成快照并提交。 git reset – files 用来撤销最后一次git add files，你也可以用git reset 撤销所有暂存区域文件。 git checkout – files 把文件从暂存区域复制到工作目录，用来丢弃本地修改。 git commit -a 相当于运行 git add 把所有当前目录下的文件加入暂存区域再运行git commit. git commit files 进行一次包含最后一次提交加上工作目录中文件快照的提交。并且文件被添加到暂存区域。 git checkout HEAD – files 回滚到复制最后一次提交。 Git基本命令123456789git status 查看代码修改状态git clone 克隆代码git diff 查看差异部分git pull origin &lt;branch&gt; 拉取git push origin &lt;branch&gt; 推送git checkout &lt;本地分支名&gt; 切换到指定分支git checkout –b &lt;new_branch&gt; 基于当前分支切换到指定分支git merge &lt;other_branch&gt; 合并其他分支到当前分支(多了一次merge信息)git rebase &lt;other_branch&gt; 基于其他分支应用合并 git常见冲突解决1234567CONFLICT (content): Merge conflict in readme.mdgit merge中：git add . git commit –m ””git rebase :git rebase –continue 紧急bug修复123git stash :暂存当前编辑的代码git checkout hotfixgit stash pop :切换到bug修复前的工作目录 快捷键设置 经常使用git命令,设置快捷键会方便很多,设置方式如下: 1git config --global alias.st status 或者: 修改~/.gitconfig,加入以下部分: 1234567891011[alias]co = checkoutci = commitst = statusbr = branchsh = stashsp = stash poppu = pushpr = pull -rrb = rebaselg = log -p 更多命令：git help]]></content>
      <categories>
        <category>git</category>
        <category>cmd</category>
        <category>summary</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[django migrate]]></title>
    <url>%2F2018%2F06%2F14%2F2018-06-14-django-migrate%2F</url>
    <content type="text"><![CDATA[django migrate12345# 删除本地migrate文件rm apps/*/migrations/*.pypython manage.py migrate recruitment --fake-initialpython manage.py makemigrations recruitmentpython manage.py migrate recruitment –fake-inital 会在数据库中的 migrations表中记录当前这个app 执行到 0001_initial.py ，但是它不会真的执行该文件中的 代码。 这样就做到了，既不对现有的数据库改动，而又可以重置 migraion 文件]]></content>
  </entry>
  <entry>
    <title><![CDATA[selenium python笔记]]></title>
    <url>%2F2018%2F06%2F13%2F2018-6-13-selenium-python%2F</url>
    <content type="text"><![CDATA[selenium python 最新版selenium 3.x已经不支持phantomjs了，桑心；需要用phantomjs的可以用selenium2.x selenium调用webdriver可以是本地的浏览器也可以是远程的，本地的webdriver(chrome,firefox)都需要下载driver，远程的需要下载一个selenium-stand，然后java -jar selenium-server-standalone-3.12.0.jar 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748from PIL import Imagefrom selenium import webdriverfrom selenium.webdriver.common.desired_capabilities import DesiredCapabilitiesUSER_AGENT = 'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_12_5) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/65.0.3325.181 Safari/537.36'chrome_options = Options()chrome_options.add_argument('user-agent=&#123;&#125;'.format(USER_AGENT))chrome_options.add_argument('--headless')# local webdriverdriver = webdriver.Firefox(executable_path='./geckodriver', firefox_options=chrome_options)# remote webdriverdcap = dict(DesiredCapabilities.PHANTOMJS)dcap["phantomjs.page.settings.userAgent"] = ( 'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_12_5) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/66.0.3359.181 Safari/537.36')driver = webdriver.remote.webdriver.WebDriver(command_executor="http://172.16.56.13:4444/wd/hub", desired_capabilities=dcap)# set cookiedriver.get('https://baidu.com/')driver.delete_all_cookies()cookie_list = [ &#123;'name': 'hehe', 'value':'222'&#125;]for i in cookie_list: driver.add_cookie(i)real_url = 'https://baidu.com'driver.get(real_url)# screenshotdriver.get_screenshot_as_file(before_png)# save htmlwith open(before_html, 'w') as fp: fp.write(driver.page_source.encode('utf-8'))# find selector and clicknext_step = driver.find_element_by_css_selector('a[data="guideLayer"]')next_step.click()# scrop selectordef crop_selector(driver, filename, selector, dist): """ crop photo through selector. """ element = driver.find_element_by_css_selector(selector) left = element.location['x'] top = element.location['y'] right = element.location['x'] + element.size['width'] bottom = element.location['y'] + element.size['height'] im = Image.open(filename) im = im.crop((left, top, right, bottom)) im.save(dist)crop_selector(driver, full_screen, 'img.book', email)driver.quit() 几个小坑 add_cookie在使用chrome或firefox作为webdriver的时候，必须先get一次目标站点的域名，然后再add，推测可能是driver的问题，使用phantomjs可以直接add之后再get； remote webdriver使用phantomjs必须使用selenium-server-standalone-2.x.jar1java -jar selenium-server-standalone-2.53.1.jar -Dphantomjs.binary.path=/usr/local/bin/phantomjs]]></content>
  </entry>
  <entry>
    <title><![CDATA[flask设置永久访问token]]></title>
    <url>%2F2018%2F04%2F04%2F2018-04-4-flask-token%2F</url>
    <content type="text"><![CDATA[flask设置永久访问token12345678910111213141516171819202122from flask_httpauth import HTTPTokenAuthauth = HTTPTokenAuth(scheme='Bearer') tokens = &#123; "12aaa0c64bc5dbc2026be1071df5c0db47659d45": "user1", "23370cec94ddc0dc2a50432a90500b2bc55d014e": "user2", &#125; @auth.verify_token def verify_token(token): g.user = None if token in tokens: g.user = tokens[token] return True return False class ContactOcr(Resource): @auth.login_required def post(self): logger.info(u'user:&#123;&#125; reconginzed: &#123;&#125;'.format(g.user, res)) return &#123;'res': res&#125;, 200]]></content>
      <categories>
        <category>gflask</category>
        <category>token</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[获取http only数据]]></title>
    <url>%2F2018%2F03%2F28%2F2018-3-28-get_http_only%2F</url>
    <content type="text"><![CDATA[###nightmare A ConservativePublishedNovember 19, 2016in JavaScript爬虫的终极形态：nightmarenightmare 是一个基于 electron 的自动化库（意思是说它自带浏览器），用于实现爬虫或自动化测试。相较于传统的爬虫框架（scrapy/pyspider），或者dom操作库（cheerio/jsdom），或者基于浏览器的自动化框架（selenium/phantomjs），他的优势在于提供了一个简洁有效 的编程模型。 ###安装1234npm install init -y npm install --save-dev spectronnpm install --save nightmarenpm run dev ###获取cookie123456789101112131415161718192021222324252627option = &#123;openDevTools: &#123; mode: 'bottom', // 开发者工具位置：right, bottom, undocked, detach&#125;, show: true, // 要不要显示浏览器 dock: true, // 要不要在Dock上显示图标 waitTimeout: 6000000, // .wait() 方法超时时长，单位:ms executionTimeout: 86400000, // .evaluate() 方法超时时长，单位:ms&#125;let Nightmare = require('nightmare');const nightmare = Nightmare(option);nightmare.goto('https://baidu.com/') .evaluate(() =&gt; &#123; return document.title; &#125;) .wait('#MainMenuNew1_m3') //.cookies.get(&#123; url: null &#125;) .cookies.get(&#123; domain: 'baidu.com' &#125;) .then((cookies) =&gt; &#123; console.log(cookies); console.log('加载完成'); &#125;)]]></content>
  </entry>
  <entry>
    <title><![CDATA[python中使用grpc]]></title>
    <url>%2F2018%2F03%2F27%2F2018-3-27-grpc%2F</url>
    <content type="text"><![CDATA[###简介gRPC 是一个高性能、开源和通用的 RPC 框架，面向移动和 HTTP/2 设计。目前提供 C、Java 和 Go 语言版本，分别是：grpc, grpc-java, grpc-go. 其中 C 版本支持 C, C++, Node.js, Python, Ruby, Objective-C, PHP 和 C# 支持. gRPC 基于 HTTP/2 标准设计，带来诸如双向流、流控、头部压缩、单 TCP 连接上的多复用请求等特。这些特性使得其在移动设备上表现更好，更省电和节省空间占用。 ###gRPC 是什么？在 gRPC 里客户端应用可以像调用本地对象一样直接调用另一台不同的机器上服务端应用的方法，使得您能够更容易地创建分布式应用和服务。与许多 RPC 系统类似，gRPC 也是基于以下理念：定义一个服务，指定其能够被远程调用的方法（包含参数和返回类型）。在服务端实现这个接口，并运行一个 gRPC 服务器来处理客户端调用。在客户端拥有一个存根能够像服务端一样的方法。 123pip install grpcpip install grpciopip install grpcio-tools ####编写数据data.proto12345678syntax = &quot;proto3&quot;;package example;message Data &#123; string text = 1;&#125;service FormatData &#123; rpc DoFormat(Data) returns (Data)&#123;&#125;&#125; ####生成客户端和服务器端代码1python -m grpc_tools.protoc -I. –python_out=. –grpc_python_out=. data.proto ###客户端：123456789101112131415161718#! /usr/bin/env python# -*- coding: utf-8 -*-import grpcimport data_pb2_grpcimport data_pb2_HOST = '0.0.0.0'_PORT = '8080'def run(): conn = grpc.insecure_channel(_HOST + ':' + _PORT) client = data_pb2_grpc.FormatDataStub(channel=conn) response = client.DoFormat(data_pb2.Data(text='hello,world!')) print("received: " + response.text)if __name__ == '__main__': run() ###服务器：1234567891011121314151617181920212223242526272829303132333435#! /usr/bin/env python# -*- coding: utf-8 -*-import timeimport grpcfrom concurrent import futuresimport data_pb2_grpcimport data_pb2_ONE_DAY_IN_SECONDS = 60 * 60 * 24_HOST = '0.0.0.0'_PORT = '8080'class FormatData(data_pb2_grpc.FormatDataServicer): def DoFormat(self, request, context): str = request.text return data_pb2.Data(text=str.upper())def serve(): grpcServer = grpc.server(futures.ThreadPoolExecutor(max_workers=4)) data_pb2_grpc.add_FormatDataServicer_to_server(FormatData(), grpcServer) grpcServer.add_insecure_port(_HOST + ':' + _PORT) grpcServer.start() try: print 'enter try' while True: print 'enter True' time.sleep(_ONE_DAY_IN_SECONDS) print 'after time.sleep' except KeyboardInterrupt: grpcServer.stop(0)if __name__ == '__main__': serve()]]></content>
  </entry>
  <entry>
    <title><![CDATA[git命令行操作]]></title>
    <url>%2F2018%2F03%2F09%2F2018-3-9-git-cmd%2F</url>
    <content type="text"><![CDATA[###git 命令搜集 下载git项目下某个目录下的文件例如：想下载链接https://github.com/grpc/grpc/tree/master/examples/python/helloworld这个目录12tree/master 改为 trunksvn checkout https://github.com/grpc/grpc/trunk/examples/python/helloworld]]></content>
  </entry>
  <entry>
    <title><![CDATA[改善程序员生活质量的 3+10 习惯]]></title>
    <url>%2F2017%2F11%2F21%2F2017-11-21-improve-quality-of-life%2F</url>
    <content type="text"><![CDATA[段子背后的真相有一则段子是这么描述程序员的职业发展： 某编程语言入门 -> 某编程语言进阶 -&gt; 某编程语言最佳实践 -&gt; 架构的艺术 -&gt; 颈椎病康复指南. 每次看到这个段子，我都只是一笑而过，还偶尔给别人讲起逗逗乐。可如今它不仅是一个段子，更像是一则不那么古老的寓言应验了！或许你会说：腰肌劳损、腰椎盘突出、颈椎弯曲这些在程序员圈子司空见惯了。 真相又是什么呢？因为我身边的例子为数不多，我仍然跟之前一样保持疑问的态度。 可不管真相如何，这封邮件却触动了我，让我想写点东西，来分享我平时在做且自认为很有意义的事情。 认知是一切的基础 古人所说知行合一，强调的是认知和行为一致，人们在做一件事情之前首先是要形成一定的认知。比如，我为什么要持续学习？我为什么要花时间去健身？而只有当我的认知中，认识到学习是具备价值，认识到健身是能给我带来益处的时候，我才会自我驱动地去做这些事情，在行动的过程中达到知行合一。 我曾经给一些朋友讲健康饮食、规律作息和运动健身的好处，讲它们对一个人工作生活有多么重要的影响，当他们若有所感地回应我的时候，我会接着告诉他们一些健康的食物、一些规律的作息时间、一些健身的软件和圈子。到最后，我才发现，他们几乎没有改变。一方面，因为他们没有切身体会到这些好处，另一方面，他们目前的生活并没有无法容忍的痛点，偶尔抱怨一下也只是过过嘴瘾。 根本原因在于认知！ 最快改变一个人的认知的方式是残酷地摧毁这个人先前的认知。举个真实极端点的例子：某某因为工作长期无节制的饮食和无规律的作息查出胃癌晚期的时候，即便用所有的钱去换回健康也为时过晚，我相信此时ta比任何人都知道健康的重要性，如果可以再来，他一定会摒弃之前所有的不良习惯，好好生活。 另外一种改变认知的方式就是形成一定的基础认知，然后通过身体力行，循序渐进地付出努力去强化自己的认知，最终达到知行合一。 我将从健康饮食、规律作息和健身运动方面去分享一些小知识。一旦形成了这种认知，我们就可以通过养成一些小习惯来不断强化提升，而作为一枚程序员的我也一直在通过这种方式不断地改善自己的工作效率，提升生活质量。 让行为成为习惯 《不抱怨的世界》中介绍了一个21天不抱怨手环，旨在坚持连续21天不抱怨，一旦说出了抱怨的话就将手环从一只手移动到另一只手，并且重新计数。如果你也跟我一样这么想：不就是21天嘛，小case，看我是如何做到的！ 你就大错特错了。因为我一开始也是这么想的，结果…! 至于为什么是21天呢，相信大家耳熟能详了。 看似不长的21一天，连续坚持下来却是一个大大的考验。有了21天培养一个习惯的指导方针，我们应该大胆相信自己能将饮食、作息、运动相关的良好行为培养成习惯，从而决定我们身体的命运（习惯决定性格，性格决定命运） 《黄帝内经》中素问上第一章 上古天真论中提到 “食饮有节，起居有常，不妄作劳，故能形与神俱，而尽终其天年，度百岁乃去”。下面我们就来探讨一下食饮有节，起居有常，不妄作劳的奥秘。 食饮有节 饮食应该持有节制，切勿暴饮暴食或不吃不喝。 不可否认，很多疾病是吃出来的。暴饮暴食和绝食都属于极端的行为。而相比于长期因为营养不足引发营养不良，长期暴饮暴食导致体内毒素积累过度带来的危害更为严重。有人说：我要减肥，必须控制饮食，从而控制体重。 没错，控制饮食是控制体重的最好的方式（另外配合运动更加健康）。也就是经常饿一饿，但饿也是有讲究的，先来看看一些极为不健康的饿法： 早起太晚，没时间吃早餐，匆匆忙忙赶到办公室饿着肚子干到中午。 中午外面太阳太热了，外卖已吃腻，两杯咖啡打发下午。 晚上好饿呀，撑不住了，正道人间美味，何不享受今宵。 再来看看健康的饿法： 早上有点饿感，（空腹练上30分钟左右的瑜伽），喝杯温水，洗漱完给自己做一顿营养早餐（量不大）。 中午饭点了，饿感来袭，去吃一顿7、8分饱的午餐，午休30分钟。 晚上了有点饿，少吃一些杂粮饼干、水果，避免带着饿感入睡（因为很难睡着）。古人云：饿治百病。饭吃到7、8分饱，晚上不给胃添加过大的负担。而且我的经验证明（当然还有受我蛊惑的朋友），晚上少吃能够有效地减到肚子上的赘肉。另外，晚上少吃能够让身体的各个器官能得到充分休息，第二天醒来大脑会很清醒。而伴随着起床困难症的消逝，你会积极的起床为自己准备一份渴望了一晚上的精美早餐（当然，自己做早餐是一件美好的事情）。老饿着也不行，那我们吃些什么呢？俗话说：早上吃得向皇帝，中午吃得香平民，晚上吃得像乞丐。科学研究表明人体每天从三餐摄入的营养比例分别是40%、40%、20%，而保证这些营养的摄入，我们需要每天摄入适量的水果、蔬菜、谷物和蛋白质。以早餐为例，我们可以摄入一定量的谷物，比如面包、包子、燕麦等；以高蛋白饮食为主，比如鸡蛋、牛奶、牛肉等；配合着蔬菜，比如西蓝花、西红柿、黄瓜、青椒等；再搭配上饱含微量元素的干果类，比如核桃、开心果、腰果、松子、葡萄干等。然后饭后搭配上水果，比如猕猴桃、香蕉、苹果。如果你觉得这些东西准备起来比较麻烦，还有一种选择：代餐。比如我最近一直在吃五谷磨房的“八珍元”早餐粉，它使用了八种原材料经过高温烘焙然后研磨成粉，搭配“五谷伴侣”一起饮食，只需要10分钟就可以准备好一顿营养丰富的早餐，当然，奖励自己一个鸡蛋或一勺植物蛋白粉或几块牛肉会让早餐更加美味。我已经给身边的好几位朋友推荐了代餐，而我自己通过长时间的饮食，成功减去内脂和小肚皮上的肉！ 起居有常 日出而作，日落而息描述了淳朴农名的作息规律。记得小时候，父母9点就睡觉了，早上5点多就起床了。 而深居都市的大多数白领，喧嚣的夜生活，睡不起的懒觉，颠倒了自然法则的作息习惯。已经很少有人会去睡子午觉了。何为子午觉：子时：23:00 ~ 01：00；午时：11:00 ~ 13：00； 夜半子时为阴阳大会，水火交泰之际，称为“合阴”，它是一天中阴气最重的时候，也是睡眠的最佳时机，子时之前入睡有利于养阴；日间午时也是阴阳交会的时候，阳气最盛，称为“合阳”，此时午睡有利于养阳。 子午觉的原则是子时大睡，午时小憩，即晚上在子时之前（23:00之前）最好入睡，对于不得不从事熬夜工作的人，与其一直熬到凌晨3、4点，不如在子时这段时间睡上一会儿，因为这段时间的睡眠效率远远超过其他时间段，夸张点说一分钟等于一小时。午觉则只需在午时（11时～13时）休息30分钟左右即可，因为此时阳气盛，工作效率最好，午睡时间过长，不仅浪费宝贵的时间，而且会扰乱人体生物钟，影响晚上睡眠。但是午睡一定要睡，即便睡不着，也要闭目养神，这样有利于人体阴阳之气的正常交接。 在作息中，子午觉对健康极为重要，它还是一种不花钱的养生方法，睡好子午觉，你的身体多了一层保障了。 不妄作劳 不妄作劳，结合新时代有不一样的解读，不要忘记劳作，即要保持运动，也不要过于劳作，即不要运动过量。 回到我们文章一开始说的那封离职邮件，因为程序员的工作性质，绝大部分程序员是长时间对着电脑工作的，加上某些公司存在加班文化，久坐的时间就更加延长了。所以导致了很多诸如腰椎盘突出、颈椎病、肩周炎、腰肌劳损、圆肩驼背等职业病。 那么如何缓解这些问题？除了坐姿端正，注意休息，更要加强运动锻炼。因为运动一方面能够加强肌肉的力量和耐力，另一方面能够活动身体的各个关节，能够有效缓解一个长时间保持一个动作导致局部肌肉过劳。 那么问题来了，如何科学地运动呢？ 我平日里听到最多的是我要减肥，将身体的脂肪减掉。好，我就说一个绝对有效且简单的减脂秘方：每天45分钟动感单车。是不是很简单，只用跟着教练跑上45分钟，体脂一定能够降下来。但是有多少人能够坚持去做好这45分钟呢？所以当有人夸赞我是教练的时候，我会告诉他我如果教学员，秘诀只在于两字： 坚持!问：花钱办健身卡会不会因为不常去导致浪费？答：已经有很多徒手的运动，比如跑步、HIIT、Tabata、瑜伽、徒手胸肌训练，徒手腹肌、空手拳击、腰背拉伸等；问：缺乏专业教练的指导会不会练不好？答：已经有很多软件提供了免费且科学的指导，比如 移动健身教练：Keep、私人瑜伽教练：Wake。问：有自虐倾向，担心练过火了，身体吃不消？答：运动健身不宜过度，要以自身身体感觉为依据，不能影响正常的食欲、工作和睡眠。 运动健身无处不在，如果你也有以上三个疑问，不妨利用瑜伽垫 + 4平米 + Keep就可以在家里开创一片健身的空间。当然健身卡能提供更丰富的选择，而能否坚持完全取决于我们自己。坚持两字则包含了深不见底的学问。 习惯的力量 食饮有节，起居有常，不妄作劳 ==&gt; 故能形与神俱，而尽终其天年，度百岁乃去。 饮食、作息、运动三者息息相关，相辅相成。三分练，七分吃，充足睡眠不丢失。如果到这里，你已经对它们的认知更进一步了，接下来我么来枚举一下围绕着这三个方面的10个小习惯： 早起空腹一杯温水，减轻肠胃的负累。 按时吃饭，越忙越要好好吃饭。 吃饭只吃七、八分饱，键肠胃。 切勿暴饮暴食，晚上少吃，尤其是油腻食物。 每天揉3~8分钟足三里穴，可以健脾胃。 中午（午时）午休半小时，夜间23:00（子时）前入睡。 每工作1~2小时，起身走动倒杯水，再忙也要喝水。 将运动融入工作中，每天定时做做运动（平板支撑、颈椎操等），10~30分钟即可。 下班后适量地健身运动，越忙越要保持运动。 坚持做上面9条。将上面的事情坚持做上21天，我相信你一定可以感知到习惯的力量。重点要指出，现在大多数职业都需要久坐，尤其是程序员，要养成定时活动颈椎和腰椎的习惯，保持健身运动，而这些完全可以融入到工作和生活的间隙中。不要为了节省短暂的半小时去拼命工作，也不要吝啬花上15分钟去吃一份有营养的早餐。这些时间终究会通过提升工作效率来弥补上。不可否认，现实中那些工作忙得不可开交、却依然重视饮食且投入1~2小时到健身中的职场精英早已经养成了这些习惯。]]></content>
  </entry>
  <entry>
    <title><![CDATA[PayPal和LinkedIn创始人Reid Hoffman的ABZ理论]]></title>
    <url>%2F2017%2F09%2F26%2F2017-09-27-Career-ABZ-Plan%2F</url>
    <content type="text"><![CDATA[我们一向把创业视为一件非常有风险的事。说起来挺矛盾，创业者经常看不起那些职场金领，但是前者在后者眼中也只是一群吃了上顿没下顿的流浪汉而已。所以这里最大的挑战就是：一个人如何让自己勇于拓展机会，但同时又不要冒太大风险，乃至于丢掉饭碗血本无归？讲到成功的把这两点结合在一起的方法，Reid Hoffman应该是最有发言权的。 LinkedIn的经历让他了解了职场万象，按他的说法，渐进式的职业规划和冒险创业是可以两全的。他发明了一套独有的职业规划理论，叫做“A-B-Z 职业规划”法则。这虽然也是在做职业规划，但是却强调试验、鼓励不确定性。而且它也不仅仅适合年轻人，对于三四十岁的“职场老人”来说一样适用。所谓的A、B、和Z分别都是什么意思呢？原文：In Startups And Life, You Need Plan A, B, And Z A-B-Z 职业规划A指的是你现在正在做的事情，或者叫主业。比如说它可能是你的专业，是你优势比较集中的领域，你是喜欢它也好不喜欢它也好，现在都得靠它吃饭。用不断的、小小的进步把主业做好当然是属于“敬业”的范畴，不过，当你逐渐的发现你可能需要一个更大的改变的时候，那就是转变到B计划上的时候了。这种转变绝对不是随机的瞎选，而是根据你已经有的经验和知识去看一条新的路径，并且等待这条新的路径逐渐变得清晰。当然，一旦你变完之后，这个B计划就成为新的A计划了。 这个从A到B的过程是最微妙的地方。为了保持决策的合理性，让自己停留在一个安全的轨道上，但同时又不束缚手脚，值得鼓励的方法是去有选择的“赌”一些后果可以收回的小事。既然咱们已经决定要给自己做出些改变了，那走些小弯路是肯定的。不过最好别让他们带来比较永久的损伤。同时我们要想方设法让自己的A计划和B计划逐渐靠拢，让B计划可以帮助到主业上，别变成完全的“不务正业”。 A指的是主业，B自然就是一个潜在的可以去达到自己理想中的目标的另外路径。假如A不管用了，你可以尝试在B上面投入更多的时间。B可以是一个和A同类别的事情，这样的你的技能是可以转移的。也可以是一个新发现的、不同领域的机会。那你怎么知道什么时候应该换什么时候不应该换呢？有些改变比较小，比如说换个部门，但有些改变就比较大了，比如说换工作，甚至完全改变一个行业。说实在，在做出改变之前谁也不知道自己变得对不对。不过，起码在科技领域，一个基本的一般规律是在大潮到来之前行动要比在大潮到来之后行动好。这说明，如果你想去抓住某些机会，就必须得冒你自己很努力的去做，但是结果这个浪头没有来的风险。具体到每件事情的话，该不该跳，什么时候跳都是个人洞察力、直觉、运气等等的融合。 最后，Z是一个保底选项。也就说，假如你的冒险全部都失败了，最差能怎么样？这个问题要想好，因为对于不同年龄不同处境的人保底选项是不一样的。这就是为什么人越年轻他冒险的成本越低。毕竟，我们平常说的所有关于创业的东西，恐怕都是说起来容易做起来难，那是因为他们会带来真正的不确定性，不确定性是最让人害怕的。所以想要解决这一点的方法就是在底下垫一个非常确定的计划。那就是计划Z，计划Z会确保你就算所有其他东西都搞砸了也还不至于露宿街头。它存在的最大意义是让我们对自己能承受多大的失败有个谱，虽然说不管什么样的失败肯定都是让人痛苦的，但是没有计划Z的话可能我们根本就不敢去冒险。 从失败的婚恋网站，到PayPal，再到LinkedIn ，看看 Reid Hoffman这些年 直接启发Reid Hoffman开发出这个ABZ法则的是他自己的职业生涯。值得注意的是，Hoffman和许多硅谷的传奇人物相比恐怕是要“普通”多了。他既没有大学辍学、也不是电脑天才，但是由于他总能敏锐观察自己的职业轨迹，善于辗转腾挪，依然取得了今天的成就。 他在离开学界之后首先创立了个婚恋网站叫socialnet.com。他的朋友Peter Thiel和Max Levchin当时创办了PayPal。出于对好朋友的支持，Hoffman决定把自己的空闲时间都贡献出来，每天在自己的公司工作到半夜，然后给另外俩人打电话去处理PayPal的事情。这种同时做两个创业公司的高强度生活持续了一两年，很快，他的A计划快不行了，网站关门在即，当时他的面前有两个B计划：要不找一份比较安稳的其他的技术工作，要不在第一次创业已经失败的情况下再赌一把，加入PayPal。Hoffman想了想，选了第二个。 PayPal迅速崛起后，后来的故事咱就都知道了。值得注意的是，这个故事还影响到了Reid Hoffman人生的第二次重大决策。2002年PayPal以15亿美元被收购，员工们在发了大财之后都跑去度假了。而他估计是还没从这几年来过山车中的经历中缓过劲来，在澳大利亚的海滩上躺着晒太阳时，突然一拍大腿，发现：“不对！我这些年这么多起起落落而最终不死，就是因为我总是在寻找新机会，并能够灵活的调整方向。现在PayPal刚刚发了大财，但同时也意味着它就完事儿了，现在应该趁着这股劲，利用手上的资源，赶紧再开始一个B计划。”当天晚上他就飞回了硅谷，开始创办LinkedIn。有意思的是，PayPal的好多其他元老们在全世界旅游了一年回来以后，正闲的发慌，结果发现LinkedIn已经在蒸蒸日上了，不禁吃了一惊，后悔他们错过了这一班车… 以下是一些小Tip，让我们在探索自己的航线时尽量提高效率、降低风险： 开始一个兼职小项目（side project）。除非你需要立刻做出一个决定，否则的话一个非常好的开始B计划的方法是给自己一份空闲时间干的事情。比如说，利用晚上和周末的时间来学一个技能，做一份兼职的实习，开一个兼职的咨询服务，等等。我们讲的这个兼职计划和业余爱好等这种完全陶冶情操的活动不一样，它指的是一个有着成为全职工作潜力的事情，只要在时机成熟，你就可以做出转变。就跟Google和3M这样的公司让员工每周花一天的时间在自己觉得有意思的项目上一样，我们完全可以自己个自己也制定一个这样的计划。 人一辈子不管在哪个阶段，都应该把学习作为是对自己最重要的事情。一般来说，世界上大部分人的教育在从学校出来以后就基本上停止了。可能逐渐的他们看电视剧的时间会远远超过充实自己的头脑的时间，人们会投资股票，不会去投资自己。在这个问题上大家可能有不同看法，毕竟人们还是要生活的，钱财也是需要管理的。不过Reid Hoffman建议大家在不管什么时候，应该永远优先选择那些能提高自己能力的活动。（我插一句，这个确实反映了从富兰克林时代就开始的那种美国式的、完全实用主义的勤学价值观） 给自己两个身份，一个人拥有双重身份能带来哪些好处？我见过很多人在做自己的全职商业工作的同时还做一份非营利组织的工作，这两件事情经常能够相互促进。比如说你在一家创业公司工作，然后在空闲时间再组织一个行业协会，协会里遇到的人经常可以给自己的全职工作也带来发展，这是直接第一点比较“有用”的好处。另外，我们也知道这种跨领域的经历是创造力最容易迸发的地方。 还有一个做法，就是试图把完全的“被工作定义的自己”和自己区分开。也就是说，不要用一个工作简历上的描述把自己给定死。比如说，在自己的LinkedIn主页上，大标题一栏可以不要写一个具体的公司的工作，而写自己的职业总体方向和追求。这是因为，如果你只关注某个人现在在做什么工作，那你可能会漏过很多这个人身上其他的价值。比如说某人是大公司高管，但他同时也很有可能是一个天使投资人。自然，我们在对外展示自己的时候也应该努力展示多个方面，因为人们会用同样的方式来看我们。]]></content>
  </entry>
  <entry>
    <title><![CDATA[python for else]]></title>
    <url>%2F2017%2F09%2F12%2F2017-09-12-python-for-else%2F</url>
    <content type="text"><![CDATA[1234567891011121314&gt;&gt;&gt; for i in range(0,10): if i &gt; 10: break; else: print "hello world";输出：hello world&gt;&gt;&gt; for i in range(0,10): if i &gt; 5: break; else: print "hello world"; 没有输出------------------- 即在for 循环中，如果没有从任何一个break中退出，则会执行和for对应的else只要从break中退出了，则else部分不执行。]]></content>
  </entry>
  <entry>
    <title><![CDATA[CentOS7设置ss开机启动]]></title>
    <url>%2F2017%2F08%2F03%2F2017-08-03-CentOS7-shadowsocks-set-start%2F</url>
    <content type="text"><![CDATA[CentOS7设置ss开机启动 配置自启动新建启动脚本文件/etc/systemd/system/shadowsocks.service，内容如下： 123456789[Unit]Description=Shadowsocks[Service]TimeoutStartSec=0ExecStart=/usr/bin/ssserver -c /etc/shadowsocks.json[Install]WantedBy=multi-user.target 执行以下命令启动 shadowsocks 服务： 12$ systemctl enable shadowsocks$ systemctl start shadowsocks 为了检查 shadowsocks 服务是否已成功启动，可以执行以下命令查看服务的状态： 123456789101112[root@kevin ~]# systemctl status ssserver -l* ssserver.service - Ssserver Loaded: loaded (/etc/systemd/system/ssserver.service; enabled; vendor preset: disabled) Active: active (running) since Thu 2017-08-03 05:56:09 UTC; 23s ago Main PID: 691 (ssserver) CGroup: /system.slice/ssserver.service `-691 /usr/bin/python2 /usr/bin/ssserver -c /etc/shadowsocks.json --log-file /var/log/shadowsocks.log startAug 03 05:56:09 kevin systemd[1]: Started Ssserver.Aug 03 05:56:09 kevin systemd[1]: Starting Ssserver...Aug 03 05:56:09 kevin ssserver[691]: INFO: loading config from /etc/shadowsocks.jsonAug 03 05:56:09 kevin ssserver[691]: 2017-08-03 05:56:09 INFO loading libcrypto from libcrypto.so.10]]></content>
      <categories>
        <category>centos7</category>
        <category>ss</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[google开源python代码规范]]></title>
    <url>%2F2017%2F07%2F31%2F2017-07-31-google-opensourse-python-code-standard%2F</url>
    <content type="text"><![CDATA[1. 行长度 每行不超过80个字符(例外 a.长的导入模块语句; b. 注释里的url) Python会将 圆括号, 中括号和花括号中的行隐式的连接起来 ：123In [2]: print('hello' ...: 'world')helloworld 2. 文件和sockets 在文件和sockets结束时, 显式的关闭它. 推荐使用 “with”语句 以管理文件; 对于不支持使用”with”语句的类似文件的对象,使用 contextlib.closing():1234import contextlibwith contextlib.closing(urllib.urlopen("http://www.python.org/")) as front_page: for line in front_page: print line 3. todo注释 为临时代码使用TODO注释, 它是一种短期解决方案. 不算完美, 但够好了. 4. 导入格式 每个导入应该独占一行 导入顺序： 标准库导入 第三方库导入 应用程序指定导入 5. 命名约定 所谓”内部(Internal)”表示仅模块内可用, 或者, 在类内是保护或私有的. 用单下划线(_)开头表示模块变量或函数是protected的(使用import * from时不会包含). 用双下划线(__)开头的实例变量或方法表示类内私有. 将相关的类和顶级函数放在同一个模块里. 不像Java, 没必要限制一个类一个模块. 对类名使用大写字母开头的单词(如CapWords, 即Pascal风格), 但是模块名应该用小写加下划线的方式(如lower_with_under.py). 尽管已经有很多现存的模块使用类似于CapWords.py这样的命名, 但现在已经不鼓励这样做, 因为如果模块名碰巧和类名一致, 这会让人困扰.]]></content>
  </entry>
  <entry>
    <title><![CDATA[docker学习总结]]></title>
    <url>%2F2017%2F07%2F06%2F2017-07-06-docker-learn%2F</url>
    <content type="text"><![CDATA[后台守护进程启动docker 12docker run --name uc -p 8001:8001 -tdi python-jlb /bin/bash 进入后台运行的docker 12docker attach docker-name]]></content>
      <categories>
        <category>其它</category>
      </categories>
      <tags>
        <tag>docker</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[生成PDF文档]]></title>
    <url>%2F2017%2F07%2F05%2F2017-07-05-generate-pdf-doc%2F</url>
    <content type="text"><![CDATA[主要使用pdfkit模块：1.安装pdfkit： 123$ pip install pdfkit$ sudo apt-get install wkhtmltopdf 使用pdfkit的一些高级功能需要研究wkhtmltopdf的一些功能：Warning! Version in debian/ubuntu repos have reduced functionality (because it compiled without the wkhtmltopdf QT patches), such as adding outlines, headers, footers, TOC etc. To use this options you should install static binary from wkhtmltopdf site or you can use this script. 使用高级功能需要执行以下脚本： 123456#!/bin/shsudo apt-get install -y openssl build-essential xorg libssl-devwget http://wkhtmltopdf.googlecode.com/files/wkhtmltopdf-0.10.0_rc2-static-amd64.tar.bz2tar xvjf wkhtmltopdf-0.10.0_rc2-static-amd64.tar.bz2sudo chown root:root wkhtmltopdf-amd64 2.基本原理功能：Pdfkit文档链接：https://pypi.python.org/pypi/pdfkitPdfkit可以渲染url，file，string 成pdf文档，也支持多个file生产一个pdf文档 Notices： pdf正文部分字体调整： css部分：@font-face { }中添加font-family等字体属性； 页脚的添加： views.py中 print_entrust()函数中options{}字典里边添加footer-center等属性；]]></content>
      <categories>
        <category>其它</category>
      </categories>
      <tags>
        <tag>PDF</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[web站点相关解决方案]]></title>
    <url>%2F2017%2F06%2F22%2F2017-06-22-website-some-solution%2F</url>
    <content type="text"><![CDATA[邮箱或手机验证码存储解决方案： 使用web框架自带的缓存系统，比如django中自带的cache 1234from django.core import cachecache.set(&apos;key&apos;, &apos;value&apos;, 10) #键,值和过期时间cache.get(&apos;key&apos;, &apos;not fount or has expired&apos;) 使用redis存储: 123redis_db = RedisDB()redis_db.set(phone=username, val=code, ex=60*10)]]></content>
      <categories>
        <category>django</category>
        <category>python</category>
      </categories>
      <tags>
        <tag>python</tag>
        <tag>django rest framework</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Python LEGN作用域总结]]></title>
    <url>%2F2017%2F06%2F19%2F2017-06-19-python-LEGN-summary%2F</url>
    <content type="text"><![CDATA[LEGB规则 Python2.2开始引入嵌套函数，嵌套函数为python提供了闭包实现。 1234567891011a = 1def foo(): a = 2 def bar(): print a //[1] return bar func = foo()func() 函数bar和a=2捆包在一起组成一个闭包，因此这里a=2即使脱离了foo所在的local作用域，但调用func的时候（其实就是调用bar）查找名字a的顺序是LEGB规则，这里的E就是enclosing的缩写，代表的“直接外围作用域”这个概念。查找a时，在bar对应的local作用域中没有时，然后在它外围的作用域中查找a。LEGB规定了查找一个名称的顺序为：local–&gt;enclosing–&gt;global–&gt;builtin。]]></content>
      <categories>
        <category>python</category>
        <category>其它</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[matplotlib RuntimeError: Python is not installed as a framework 错误解决方案]]></title>
    <url>%2F2017%2F05%2F25%2F2017-05-25-matplotlib-runtimeerror-python-is-not-installed-as-a-framework-error%2F</url>
    <content type="text"><![CDATA[在virtualenv环境下使用matplotlib绘图时遇到了这样的问题： import matplotlib.pyplot as pltTraceback (most recent call last):File “”, line 1, in… infrom matplotlib.backends import _macosxRuntimeError: Python is not installed as a framework. The Mac OS X backend will not be able to function correctly if Python is not installed as a framework. See the Python documentation for more information on installing Python as a framework on Mac OS X. Please either reinstall Python as a framework, or try one of the other backends. If you are Working with Matplotlib in a virtual enviroment see ‘Working with Matplotlib in Virtual environments’ in the Matplotlib FAQ 似乎是因为虚拟环境与默认环境的安装配置不同造成的。 搜索错误信息之后，在STO上找到了解决方案： 1、pip安装matplotlib之后，会在根目录下产生一个.matplotlib的目录: ➜ bin ll ~/.matplotlibtotal 280-rw-r–r– 1 me staff 78K 10 4 2015 fontList.cache-rw-r–r– 1 me staff 59K 1 17 15:56 fontList.py3k.cachedrwxr-xr-x 2 me staff 68B 10 4 2015 tex.cache 2、在这个目录下创建一个名为matplotlibrc的文件，内容是： backend: TkAgg 然后保存退出，重启Python交互界面或重新运行脚本，import正常执行。 STO答案地址：http://stackoverflow.com/questions/21784641/installation-issue-with-matplotlib-python]]></content>
      <categories>
        <category>python</category>
      </categories>
      <tags>
        <tag>python</tag>
        <tag>framework</tag>
        <tag>RuntimeError</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[casperjs传参]]></title>
    <url>%2F2017%2F04%2F18%2F2017-04-18-casperjs-pass-args%2F</url>
    <content type="text"><![CDATA[casperjs传递动态参数： 12345678910111213141516171819var casper = require(&apos;casper&apos;).create(&#123; pageSettings: &#123; javascriptEnabled: true , loadImages: true, loadPlugins: true, userAgent: &apos;Mozilla/5.0 (Macintosh; Intel Mac OS X 10_12_1) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/56.0.2924.87 Safari/537.36&apos; &#125;, // logLevel: &quot;debug&quot;,//日志等级 // verbose: true, // 记录日志到控制台 viewportSize: &#123;width: 1024, height: 768&#125;&#125;);var args2 = casper.cli.args;var NET_SessionId = args2[0];var EhireGuid = args2[1];var AccessKey = args2[2];var HRUSERINFO = args2[3];]]></content>
      <categories>
        <category>爬虫</category>
      </categories>
      <tags>
        <tag>casperjs</tag>
        <tag>爬虫</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[casperjs截取验证码图片和设置cookies，headers，模拟鼠标点击selected元素]]></title>
    <url>%2F2017%2F04%2F14%2F2017-04-14-casperjs-get-Verification-code-pic%2F</url>
    <content type="text"><![CDATA[casperjs设置headers： 123456789101112131415161718192021222324252627282930313233var casper = require(&apos;casper&apos;).create(&#123; pageSettings: &#123; loadImages: true, loadPlugins: true, // userAgent: &apos;Mozilla/5.0 (Windows NT 6.1) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/34.0.1847.137 Safari/537.36 LBBROWSER&apos; userAgent: &apos;Mozilla/5.0 (Macintosh; Intel Mac OS X 10_12_1) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/56.0.2924.87 Safari/537.36&apos;, &#125; logLevel: &quot;debug&quot;,//日志等级 verbose: true // 记录日志到控制台&#125;);var mouse = require(&quot;mouse&quot;).create(casper);var url = &apos;http://baidu.com/&apos;;casper.start(url);// casper.thenClick(&apos;#verify-state&apos;); //鼠标点击casper.thenClick(&apos;#btnBeginValidate&apos;);casper.thenClick(&apos;#btnVRefresh&apos;,function(response)&#123; this.echo((response.headers.get(&apos;Set-Cookie&apos;)).split(&apos;;&apos;)[0]); #获取响应的Set-Cookie信息&#125;);casper.then(function () &#123; // this.echo(this.) // this.querySelector(&apos;img[id=&quot;imgPhrase&quot;]&apos;).setAttribute(&apos;style&apos;, &quot;display: block&quot;); this.wait(1000, function () &#123; img_guid = this.getElementAttribute(&apos;img[id=&quot;imgPhrase&quot;]&apos;, &apos;src&apos;); //获取元素属性值 // img_name = img_guid + &apos;.png&apos;; img_name = &apos;2001.png&apos;; this.captureSelector(img_name, &apos;.yz-main&apos;); # 根据元素属性截取图片&#125;); casperjs设置cookies： 1234567891011121314151617181920212223242526272829303132333435var webPage = require(&apos;webpage&apos;);var page = webPage.create();page.customHeaders = &#123; &apos;User-Agent&apos;: &apos;Mozilla/5.0 (Macintosh; Intel Mac OS X 10_12_1) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/56.0.2924.87 Safari/537.36&apos;, &apos;Content-Type&apos;: &apos;application/x-www-form-urlencoded&apos;&#125;;if (phantom.addCookie(&#123; &apos;name&apos;: &apos;EhireGuid&apos;, &apos;value&apos;: &apos;5662e8a3df3c4062aa9edd9ee3e2e36f&apos;, &apos;path&apos;: &apos;/&apos;, //必须 &apos;domain&apos;: &apos;baidu.com&apos; //必须&#125;)) &#123;console.log(&apos;cookie EhireGuid success&apos;)&#125; else &#123; console.log(&apos;cookie EhireGuid fail&apos;) //一直返回失败，但是实际上是成功了，感觉这个是phantomjs的bug 有空提交一下bug&#125;var selector = &quot;#dropPutDateRange&quot;; // use proper selectorcasper.then(function()&#123; // check selectd value var selected = this.evaluate(function(selector)&#123; var s = document.querySelector(selector); var o = s.children[s.selectedIndex]; return &#123;value: o.value, text: o.innerHTML&#125;; &#125;, selector); this.echo(&quot;result: &quot; + JSON.stringify(selected, undefined, 4)); //打印selected的值 this.evaluate(function() &#123; $(&apos;#dropPutDateRange &apos;).val(&apos;value&apos;).change(); //改变selected的值 &#125;);&#125;);casper.run();]]></content>
      <categories>
        <category>爬虫</category>
      </categories>
      <tags>
        <tag>casperjs</tag>
        <tag>cookie</tag>
        <tag>截图</tag>
        <tag>验证码</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Python中的一些魔法]]></title>
    <url>%2F2017%2F01%2F23%2F2017-01-23-python-methods%2F</url>
    <content type="text"><![CDATA[1.将多个序列串放在一起遍历： 1234567&gt;&gt;&gt; from itertools import chain &gt;&gt;&gt; a = [1, 2, 3, 4] &gt;&gt;&gt; b = [&apos;a&apos;, &apos;b&apos;, &apos;c&apos;] &gt;&gt;&gt; for x in chain(a, b): ... print(x) ... 2.python表示昨天的日期： 123456789#-*-coding:utf-8-*- import datetimedef getYesterday(): # today=datetime.date.today() oneday=datetime.timedelta(days=1) yesterday=today-oneday return yesterday 3.打印代码出错信息： 123import tracebacktraceback.format_exc() traceback.print_exc()跟traceback.format_exc()有什么区别呢？format_exc()返回字符串，print_exc()则直接给打印出来。]]></content>
      <categories>
        <category>python</category>
      </categories>
      <tags>
        <tag>python</tag>
        <tag>Magic</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[js提交数据的headers设置]]></title>
    <url>%2F2017%2F01%2F03%2F2017-01-03-js-submit-headers-config%2F</url>
    <content type="text"><![CDATA[JS通过ajax提交post数据有两种方式：Request Payload 和 Form Data，具体的区分可以通过设置请求头的Content-Type来确定： 需要Form Data方式提交数据可以设置headers = {‘Content-Type’:’application/x-www-form-urlencoded’} 需要Request Payload方式提交数据可以设置headers = {‘contentType’:’text/plain;charset=UTF-8’}]]></content>
      <categories>
        <category>django</category>
        <category>python</category>
      </categories>
      <tags>
        <tag>python</tag>
        <tag>前端js</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[试着去做一些事儿，让自己成为一个有趣儿的人]]></title>
    <url>%2F2016%2F12%2F28%2F2016-12-28-try-do-something%2F</url>
    <content type="text"><![CDATA[不知道从什么时候开始，大家喜欢以是否有趣来评价自己对一个人的印象。在整容风靡，美的价值观判断被颠覆之后，能恒久留存下来的，必定是你读过的书，走过的路，写在脸上的气质和刻在骨子里的趣味。 正如那句话所说： 你现在的气质里，藏着你走过的路，读过的书和爱过的人。 时光流逝之后，你就会知道，一个有趣的人比一个外表美丽的人更讨人喜欢。 有人说，不要把自己置身在模式化的幸福和大规模生产的生活之中，你过着怎样的人生，取决于你用什么角度看待生活。 努力做一些不一样的事儿，让自己成为一个有趣儿的人吧！ ### 挑战自己：做不敢做的事儿 特别喜欢陈意涵，30岁生日的时候，她和闺蜜张钧甯，一起做了好多非常有趣的事儿。到海里裸泳、扎辫子、全世界倒立…… 有时候，尝试着去做一些曾经不敢做的事儿，不仅会终身难忘，更会让生活变得有趣。 如果你胆子小，就试着蹦极，到飞机上跳伞；如果你性格腼腆，试着在地铁上，冲着外国人微笑；如果你五音不全，就选择一个空旷的下午，尽情享受一个人的ktv；如果你害怕在大庭广众下演讲，就对着镜子背熟一篇演讲稿，然后跑到无人的地方勇敢演讲一次吧！要知道，你是自己最忠实的观众！ 如果你害怕一个人旅行，就随便找个地方，背起行囊，查好攻略，上路吧，相信，你这一路，必定精彩！ 还有什么是你害怕做的呢？试着去做做看吧！ ### 为自己买花 认识一个男孩，每周都会为自己订一束花，当黑色的周一来临，黑压压的办公室里充斥着紧张的氛围时，一束鲜花，在角落里散发着暗香，无论寒冷的冬日还是燥热的夏日，都能让心情晴朗起来。 有位姐姐告诉我，真正有魅力的女人，是会为自己买花的女人。一束花，带给你的不仅仅是一周的好心情和美丽的惊喜，更是在漫长的工作日里，你对它的那份呵护、关注和照顾，修剪花枝，换水，清理杂物，这个用心的过程，不仅让生活充实，更让精神富足，这是个很动人的过程。 ### 幽默有时，欢笑有时 幽默的人有多大的魅力？看黄渤就知道。林志玲曾多次说过，黄渤是她的理想型。幽默的人身上有种天然的吸引力，幽默感，让彼此相处变得容易，用幽默化解尴尬，用幽默化解别人的恶意，是高情商的表现，更是一种宽容。 萧伯纳曾说，幽默就像马车上的弹簧，没有它，一块小石子就让你很颠簸。 幽默是一种达观的生活态度，学着做个幽默的人，因为幽默的人真的很美。与人 ### 欣赏古典音乐 到音乐厅欣赏一场音乐会，无论是小提琴的轻快，大提琴的低沉，钢琴的律动，还是琵琶的婉转，都能让心灵接受一次美的洗礼。站在台上高歌一首流行歌曲，会让人觉得你很帅，如果愿意欣赏一曲古典音乐，还能将心得与人分享，那别人眼睛里的你，必定是高雅和值得尊敬的。 ### 学一门乐器 去年学习了琵琶才知道，琵琶是一门神奇的乐器，有着极其广泛的音域，可以弹出所有乐器能弹奏的音节，甚至夸张一点，一把琵琶可以自成一个演唱会。渐渐地爱上了这门古典民乐，叮咚泉水般的音色，有着天籁般的音乐质感，看着艺术大师们酣畅淋漓的一曲《十面埋伏》，一曲缠绵婉转的《红尘客栈》，才不禁慨叹，白居易所说的”大弦嘈嘈如急雨，小弦切切如私语，嘈嘈切切错杂弹，大珠小珠落玉盘”的壮观，才感受到”千呼万唤始出来，犹抱琵琶半遮面”的美。 尝试着学一门乐器吧，下次一个人到海边，吹着海风，抱着吉他，独自弹唱一曲，你就是浪迹天涯的侠客。 ### 运动会让你很有魅力 曾看过一个女孩分享，过去一年对自己最大的投资，便是办了一张健身卡，经过大半年之后，秀出了棱角分明的马甲线和深深的腰窝，皮肤也变得紧致有型，人也更自信了。 如果健身房让你感觉枯燥，那就试着去骑车、爬山、徒步，在这个过程中，不仅能认识新朋友，更能让自己的身体越来越棒。 ### 读书是最不徒劳无功的事 博尔赫斯曾说，如果有天堂，那应该是图书馆的模样。 某位时尚博主曾说，如果实在不知道做什么，那就读书吧。 在名人传记里，体验不同的人生；在历史中，感受时代的变迁，在文学书籍里，修身养性，在心理学的书里，让自己身心更加健康。当然，还可以阅读一些关于建筑、房屋收纳、宗教等方面的书，无论是旅行还是与朋友聊天，能把这些冷知识头头是道地说出来，还是很洋气的！ ### 来一场说走就走的旅行 旅行的意义，可能就是让原本不耐寒的四肢还能轻易感触空气的细微变化。歌德在《致卡罗琳·冯·赫尔德》里，对旅行有一番解读：人之所以爱旅行，不是为了抵达目的地，而是为了享受旅途中的种种乐趣。 有多少人是看了切·格瓦拉的《摩托车日记》追随他一路到了南美洲？说走就走的旅行不是从你待腻的地方到别人待腻的地方去，而是一个寻找自我，发现自我，探索内心的过程。 走在异国他乡的街头，感受不同的人文，不同的笑脸，不同的饮食，不同的建筑，看着与你擦家而过的背包客们匆匆赶路，看着热衷于享受生活的欧美人们无论到哪里，都一定要在咖啡馆里发个呆，到酒吧狂欢整晚，某片海上的某个游轮里，与来自世界各地的人们，聊聊你我的行程，聊聊彼此国家的风俗习惯，那种独特的人生的体验，会让你更加感恩生命的广阔，自己的渺小。旅途中，你会震撼于不同地方的日出日落，一路跋山涉水，你既能在遥远的北国邂逅鹅毛般的雪片飘飞，也能在南国的暖阳里欣赏凤凰花开两季，旅途中有几米笔下的红色沙漠，有电影里金色的海洋。 所以，去旅行吧，让自己在旅行中成长吧。 ### 不要忽略了你所居住的城市 有多少人，在一个城市工作生活了十几年，活动的空间永远是家和公司附近的地方？给自己一些时间，去感受你所在的那座城市。来到上海一年半的我，很幸运地通过参加city walk ，基本走遍了这座城市最有韵味，最有历史的角角落落。我可以告诉你，上海多伦路上左联名人的故事，跟你讲讲苏州河畔的张爱玲故居；向你推荐武康路上的网红小店；法租界里“流动的盛宴”…… 所以，不要忽略你所居住生活的城市，角落里，都是历史留下的瑰宝。 ### 解锁一项新技能 彭于晏是不少人心中的绝对偶像。不仅仅是因为他永远在线的超高颜值，和体脂率3%的完美身材，更重要的是永远在努力的彭于晏，几乎每拍一部电影就解锁一项新技能。现在他体操、手语、泰拳、骑行、海豚训练、冲浪……可谓十八般武艺俱全。 解锁一项新技能，不需要很难，却可以让你更有趣。比如学一些手语、学习下占卜、塔罗，学游泳，学着唱好一首歌，甚至学习魔方也可以哦。 ### 学习一门新语言 语言是一种神奇的东西。掌握一门新语言，不仅可以为技能加分，也是找工作跳槽时闪亮的一点。可以利用闲暇时间试着自学日语五十音图，法语字母发音，或者干脆选一门一直喜欢的语言报个班，但是一定要坚持哦！ ### 跟着电影游世界 大学时代的电影课上，认识了侯孝贤，认识了眷村，迷恋上胡德夫的歌声，吴念真的故事。自此便爱上了台湾。虽然到现在一直未曾去过，但每次打开一部部关于太平洋彼岸那座小岛的电影，心便跟着跳动。 在《一夜台北》里，逛逛24小时的诚品书店；跟着《艋胛》感受那个年代的台湾黑帮；在《练习曲》里欣赏太平洋的绝美风光；在《不能说的秘密》里，跟着周董回到他的学生时代…… 跟着电影漫游世界，是件超有趣的事情。在《午夜巴黎》里，跟着主人公的脚步，会晤巴黎名流，沉醉于浪漫巴黎的灯红酒绿；在《午夜巴塞罗那》里，聆听达利的艺术；在《天堂的孩子》里，走进伊朗这个贫穷但却轻声吟唱着美丽故事的国家；在《天空之城》里感受最真实的里约热内卢的贫民窟…… 给自己两个小时，打开一部电影，世界就在你眼前了！ ### 爱上听讲座 听讲座是最能赚到的事情。各个行业领域的精英和领袖们，将自己数十年的研究成果，在短短2个小时里，通过一场讲座与你分享。浓缩的全部是知识里最精华的部分。 而很多讲座往往有意料之外的惊喜，比如你苦苦寻找的一些资料，在讲座里恰好可以听到。 ### 到城市看几场展览 2016年，看过最震撼的展览，是10月份上海展览中心的世界摄影展。来自全世界的知名画廊齐聚上海，在这里，我第一次完整地看到了肖全的作品和他镜头之下的窦唯、三毛。一场展览，看到的是整个世界。 在上海博物馆里一场关于日本醍醐寺的展览上，又了解了不为人知的日本文化的另一面。 如果周末无所事事，记得到博物馆里看场展览，它会深入你的气质。 ### 泡泡英语角 虽然我还没有泡过，但是想把它列为今年的梦想清单。英语角里与有趣的外国人交流，自己也会变得有趣。 ### 做志愿者，享受给予的快乐 赠人玫瑰，手留余香。好像自从上大学开始，就一直在尝试着做志愿者。去年，曾在两场公益性心灵课程里做过志愿者，当你敞开心扉，将温暖和爱传递给大家的时候，你收获的信任是一种巨大的能量，那种能量足以温暖你整个人生。 刚刚结束了一场旅行活动的志愿者，虽然天气寒冷，但是想到自己是传递快乐的使者，想到被别人需要着，心就暖暖的。 去做一次志愿者吧，这个世界是这样深深地需要着你。 ### 到咖啡馆里做一次体验店长 如果你和我一样分不清卡布奇诺和拿铁，就试着了解一些吧！豆瓣上常常会有类似的活动哦，选择一天的时间，到咖啡馆里尝试一天的体验店长，感受手作的温度，让咖啡豆在自己的手中慢慢磨成粉末，亲手把牛奶画成一颗心，享受体验不一样的快乐。 ### 给自己放个假，刷一部优质日剧 一直喜欢日剧，因为日剧里总会蕴藏一股特别的能量。有时候看来是一锅浓浓的鸡汤，有时候又是一场热血的战争，但总能让你从中读出一些人生的哲理。周末不妨给自己放个假，刷剧也是一件有趣的事儿。 听广播 夜晚临睡前，听听音乐广播，主播温暖的声线，精心安排的好歌，伴你入眠。还可以在喜马拉雅听一些有意思的课程。感受声音的力量。 教给别人一个你擅长的小技能 这是培养耐心的很好的方法。如果你可以玩转魔方，记得将这门小技能分享出来哦，教会了别人，是一件超有成就感的事情。 如果你对塔罗深有研究，对写作有心得，或者是个健身达人，记得分享出来，相信会有一大波人来喜欢你。 ### 每天坚持做几件无用的事 每天折一颗小星星，每天折一只千纸鹤，每天抄写一首古诗，每天抄写一首心经，坚持每天拍同一片天空……你还能想到哪些无用的事？ ### 坚持每天写下三件感恩的事 坚持了，就会发现生活是那么地不一样。 ### 在网络上听几次课程 知乎、荔枝微课等有各个行业的大师们愿意与你分享，选择一些课程来听，可以是提升自己专业知识的课程，帮助心灵成长的课程。会有特别的收获。 ### 看话剧 话剧的舞台上，有着别的表演形式没有的仪式感和代入感。做个看客，也做个表演者。 ### 留宿在别处 可以试着在城市里住住民宿，感受主人悉心准备的精致餐具，用心布置的精美壁画，感受精致的生活。也可以到别的城市住青旅，认识一些来自世界各地的新朋友，你会发现生活中的无限可能。 ### 看演唱会 如果有你特别喜欢的歌手，可以试着去听几场他的演唱会。感受在每场演唱会上，他唱的歌的变化，造型的变化，看着他成长，你自己也在其中感悟和成长。 ### 享受一个人的时光 当亚当和夏娃偷吃禁果之后，便懂得了羞耻，穿上了衣服，而从这时候开始，人就开始变得孤独了。蒋勋在《孤独六讲》里曾讲到，孤独不是一个贬义词，我们总是害怕承认，我很孤独。 孤独是一种心境，而孤独沉淀后的思维一种清明。所以要学会享受一个人的时光。一个人也要把日子过成诗。 ### 睡前仪式：与自己对话 如果这个仪式成为一种习惯，那相信你可以驾驭生活中的一切困难。在与自己对话中，三省吾身，总结成长。 ### 学习冥想，学习瑜伽 这是一门值得深究的学问。 ### 下厨，为自己做一顿精致的餐点 如果不知道想学习什么，那就学着做饭吧！这绝对是一门受益终身的技能。闲暇时，为自己做一餐精致的餐点，美味和成就感，会让你爱上如此有趣的自己。 ### 学习烘焙 认识一位电台主播，做了妈妈之后，为了能让小孩吃上不含防腐剂的食品，便自己学着做烘焙。看着她做出美丽图案的饼干、蛋糕，真的是非常羡慕，能做出如此美貌烘焙的你，怎么能不美呢？ ### 为父母做几件事儿 陪父母聊天，带父母旅行，常常回家，陪伴父母。对他们来说，你在身边，就是幸福。 ### 去看海 每当你感受孤独和无助的时候，遥望大自然，就会拥有无穷的力量。大海，是无论你快乐还是悲伤的时候都会无比震撼的存在。蒋勋曾说，他非常享受一个人孤独的时光，甚至常常自己一个人到台湾东部的海岸边，吹着太平洋的风，看着激浪拍岸，忍不住唱起歌来。 去看海吧，无论你快乐或者悲伤。 ### 努力去一次西藏 曾经听过lonely planet 中华区品牌总裁李沐泽的一次分享，他有讲到一个细节，你在西藏看到的是珠峰的这一边，当到尼泊尔，看到的是珠峰的另一边。而不少驴友当见识到这宿命般的美景时，竟忍不住泪流满面。 不知道什么时候开始，骑行西藏成了时尚酷炫的潜台词，不知道什么时候开始，墨脱不再是安妮宝贝笔下的莲花秘境，而成了一生追寻的信仰之地。 林夕在《富士山下》写道：爱情就像富士山，你不能期望它走过来，只能自己走过去，而西藏亦是富士山一般的所在。 这辈子一定要去一次西藏，感受雪山下的藏民匍匐朝拜的虔诚和信仰，感受仓央嘉措口中：前世，我翻越十座大山，不为修来世，只为途中与你相见”的诗意与坚持，到拉萨转一次经，在转经中，遗忘了所有的苦难和尘缘，用最纯净的心 张开双臂，去迎接这个纯净的世界。 ### 交换阅读，交换想法 记得把读过的书与朋友分享，在分享的过程中，会有不一样的成长。 ### 跑步，是一件很酷炫的事情 陈意涵每天，持續晨跑，持續倒立，每天十公里，前一段时间，她在微博上po出跑马得奖的奖牌，配文：跑步很像談戀愛，你不知道你的身體什麼時候會背叛你，但你永遠不能放棄他，用耐心，包容，痛苦，來成就最後的美好。 村上春树的标准生活就是，基本凌晨四点左右起床，从来不用闹钟，泡咖啡，吃点心，就立即开始工作。然后，写五、六个小时，到上午十点为止。每天跑步一个小时，村上说，对他来说，每天只有二十三个小时，因为有一个小时给了运动，雷打不动。 ### “要把自己融入节奏中去，把自己培养成一种习惯动物。” “决定了就做。不说泄气话，不发牢骚，不找借口。” “早睡早起，每天跑十公里，坚持每天写十页，要像个傻瓜似的。” “天黑了就不工作。早晨起来写小说跑步做翻译，下午两点左右结束，接着就随心所欲。” 村上春树称自己是长距离跑者，“今天不想跑，所以才去跑，这才是长距离跑者的思维方式。” 所以，不用花錢的日常，就是一起來運動～大家来跑步吧！ ### 坚持记日记\写博客 记录每天的生活。天长日久，重新看过，曾经生活里的点点滴滴，都像散落在记忆海滩的美丽贝壳，被串成晶莹的项链，闪烁着耀眼的光芒。 ### 为爱付出，不再惧怕 无论你几岁，都要相信爱情。如果此时你还没有等到那个人，就在等待的过程中，努力变成更好的自己吧，相信会有更好的那个人，也在寻找你。 ### 爱自己，是终身要学习的课程 好好吃饭，好好睡觉，好好运动，做自己想做的事，见自己想见的人，走自己想走的路，只有真正爱好了自己，才会去爱别人。 ### 喜欢一个特别优秀的男孩（女孩) 要相信，在喜欢Ta的过程中，你会成为更好的自己。努力追到TA。 前提是，你是真的喜欢他哦！ 而追到了他，你就已然成为一个有趣、优秀、美好的人啦！]]></content>
      <categories>
        <category>生活</category>
      </categories>
      <tags>
        <tag>life</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Django中url路径的问题]]></title>
    <url>%2F2016%2F12%2F21%2F2016-12-21-django-url%2F</url>
    <content type="text"><![CDATA[Django url路径的问题： 123url(r&apos;courses$&apos;, views.CourseListView.as_view()), url(r&apos;trainers/(?P[\d]+)/courses$&apos;, views.TrainerCourseListView.as_view()), 匹配第二条url的时候会匹配到第一条的url，然后直接返回第一条url对应视图的数据 解决方法： 第二条调整到第一条之前； 第二条修改courses为course；]]></content>
      <categories>
        <category>django</category>
        <category>python</category>
      </categories>
      <tags>
        <tag>django</tag>
        <tag>python</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[django中主外键允许为空]]></title>
    <url>%2F2016%2F12%2F12%2F2016-12-12-django-foreignkey%2F</url>
    <content type="text"><![CDATA[django model设计中必不可少一对多和多对多的关系：关系中有允许为空的情况，实用django rest framework时多对多的情况有所不同： 1questions = models.ManyToManyField(Question, help_text=u&apos;试卷关联的问题&apos;, blank=True) 12project = models.ForeignKey(Project, related_name=&apos;courses&apos;, null=True)多对多必须指定blank字段为True否则创建的时候会报错。 12 `]]></content>
      <categories>
        <category>django</category>
      </categories>
      <tags>
        <tag>django</tag>
        <tag>python</tag>
        <tag>django rest framework</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[mysql命令行数据库的导出和导入]]></title>
    <url>%2F2016%2F11%2F16%2F2016-11-16-mysql-import-and-export%2F</url>
    <content type="text"><![CDATA[MAC下用brew安装的mysql，创建my.cnf文件，用以前的linux下的配置总是各种报错： 12... ERROR! The server quit without updating PID file (/usr/local/var/mysql/higgsdeMacBook-Pro.local.pid). 解决方法： 用mac下默认的配置文件作为my.cnf的内容，然后修改才会生效： 12cp /usr/local/opt/mysql/support-files/my-default.cnf /etc/my.cnf MySQL数据库的导出和导入：导出：12mysqldump -u root -p news &gt; news.sql 导入：12mysql -u root -p voice&lt;voice.sql]]></content>
      <categories>
        <category>mac</category>
        <category>python</category>
      </categories>
      <tags>
        <tag>mysql</tag>
        <tag>mac</tag>
        <tag>数据库导出</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Mac下安装python连接mysql工具MySQLdb]]></title>
    <url>%2F2016%2F10%2F25%2F2016-10-25-mac-install-MySQLdb%2F</url>
    <content type="text"><![CDATA[解决mac升级10.11后，出现的 xcrun: error: invalid active developer path, missing xcrun 错误前天把小mac升级到了10.11，结果今天在终端里使用git的时候，弹出一行莫名其妙的错误： 1xcrun: error: invalid active developer path (/Library/Developer/CommandLineTools), missing xcrun at: /Library/Developer/CommandLineTools/usr/bin/xcrun 12去google了一圈，找到了一个github上homebrew issues里[很老的帖子](https://github.com/Homebrew/homebrew/issues/23500)，按着里面说的，重装了一下xcode command line，结果就正常了…… xcode-select –install`]]></content>
      <categories>
        <category>其它</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[Python中装饰器，迭代器和生成器]]></title>
    <url>%2F2016%2F10%2F11%2F2016-10-11-python-use-decrator-generator%2F</url>
    <content type="text"><![CDATA[Python中的装饰器被用于有切面（AOP）需求的场景，如插入日志、性能测试、事务处理等测试函数的执行时间： 123456789101112131415def test_runtime(func): def _deco(): start = time.time() func() end = time.time() print &apos;time:&apos;, end-start return _deco @test_runtimedef gen(): for i in range(100000000): pass print &apos;AAAAAAAAAAAAAAAA&apos;gen()]]></content>
      <categories>
        <category>其它</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[restful api设计规则]]></title>
    <url>%2F2016%2F10%2F11%2F2016-10-11-restful-api%2F</url>
    <content type="text"><![CDATA[网络应用程序，分为前端和后端两个部分。当前的发展趋势，就是前端设备层出不穷（手机、平板、桌面电脑、其他专用设备……）。 因此，必须有一种统一的机制，方便不同的前端设备与后端进行通信。这导致API构架的流行，甚至出现“API First”的设计思想。RESTful API是目前比较成熟的一套互联网应用程序的API设计理论。我以前写过一篇《理解RESTful架构》，探讨如何理解这个概念。 今天，我将介绍RESTful API的设计细节，探讨如何设计一套合理、好用的API。我的主要参考了两篇文章（1，2）。 一、协议API与用户的通信协议，总是使用HTTPs协议。 二、域名应该尽量将API部署在专用域名之下。 1234``` language-javascript https://api.example.com12345678910111213&lt;/blockquote&gt;如果确定API很简单，不会有进一步扩展，可以考虑放在主域名下。&lt;blockquote&gt;12https://example.org/api/12345678910111213141516171819&lt;/blockquote&gt;## 三、版本（Versioning）应该将API的版本号放入URL。&lt;blockquote&gt;12https://api.example.com/v1/123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188189190191192193194195196197198199200201202203204205206207208209210211212213214215216217218219220221222223224225226227228229230231232233234235236237238239240241242243244245246247248249250251252253254255256257258259260261262263264265266267268269270271272273274275276277278279280281282283284285286287288289290291292&lt;/blockquote&gt;另一种做法是，将版本号放在HTTP头信息中，但不如放入URL方便和直观。[Github](https://developer.github.com/v3/media/#request-specific-version)采用这种做法。## 四、路径（Endpoint）路径又称&quot;终点&quot;（endpoint），表示API的具体网址。在RESTful架构中，每个网址代表一种资源（resource），所以网址中不能有动词，只能有名词，而且所用的名词往往与数据库的表格名对应。一般来说，数据库中的表都是同种记录的&quot;集合&quot;（collection），所以API中的名词也应该使用复数。举例来说，有一个API提供动物园（zoo）的信息，还包括各种动物和雇员的信息，则它的路径应该设计成下面这样。&lt;blockquote&gt; &gt; &gt; &gt; * https://api.example.com/v1/zoos&gt; &gt; * https://api.example.com/v1/animals&gt; &gt; * https://api.example.com/v1/employees&gt; &lt;/blockquote&gt;## 五、HTTP动词对于资源的具体操作类型，由HTTP动词表示。常用的HTTP动词有下面五个（括号里是对应的SQL命令）。&lt;blockquote&gt; &gt; &gt; &gt; * GET（SELECT）：从服务器取出资源（一项或多项）。&gt; &gt; * POST（CREATE）：在服务器新建一个资源。&gt; &gt; * PUT（UPDATE）：在服务器更新资源（客户端提供改变后的完整资源）。&gt; &gt; * PATCH（UPDATE）：在服务器更新资源（客户端提供改变的属性）。&gt; &gt; * DELETE（DELETE）：从服务器删除资源。&gt; &lt;/blockquote&gt;还有两个不常用的HTTP动词。&lt;blockquote&gt; &gt; &gt; &gt; * HEAD：获取资源的元数据。&gt; &gt; * OPTIONS：获取信息，关于资源的哪些属性是客户端可以改变的。&gt; &lt;/blockquote&gt;下面是一些例子。&lt;blockquote&gt; &gt; &gt; &gt; * GET /zoos：列出所有动物园&gt; &gt; * POST /zoos：新建一个动物园&gt; &gt; * GET /zoos/ID：获取某个指定动物园的信息&gt; &gt; * PUT /zoos/ID：更新某个指定动物园的信息（提供该动物园的全部信息）&gt; &gt; * PATCH /zoos/ID：更新某个指定动物园的信息（提供该动物园的部分信息）&gt; &gt; * DELETE /zoos/ID：删除某个动物园&gt; &gt; * GET /zoos/ID/animals：列出某个指定动物园的所有动物&gt; &gt; * DELETE /zoos/ID/animals/ID：删除某个指定动物园的指定动物&gt; &lt;/blockquote&gt;## 六、过滤信息（Filtering）如果记录数量很多，服务器不可能都将它们返回给用户。API应该提供参数，过滤返回结果。下面是一些常见的参数。&lt;blockquote&gt; &gt; &gt; &gt; * ?limit=10：指定返回记录的数量&gt; &gt; * ?offset=10：指定返回记录的开始位置。&gt; &gt; * ?page=2&amp;per_page=100：指定第几页，以及每页的记录数。&gt; &gt; * ?sortby=name&amp;order=asc：指定返回结果按照哪个属性排序，以及排序顺序。&gt; &gt; * ?animal_type_id=1：指定筛选条件&gt; &lt;/blockquote&gt;参数的设计允许存在冗余，即允许API路径和URL参数偶尔有重复。比如，GET /zoo/ID/animals 与 GET /animals?zoo_id=ID 的含义是相同的。## 七、状态码（Status Codes）服务器向用户返回的状态码和提示信息，常见的有以下一些（方括号中是该状态码对应的HTTP动词）。&lt;blockquote&gt; &gt; &gt; &gt; * 200 OK - [GET]：服务器成功返回用户请求的数据，该操作是幂等的（Idempotent）。&gt; &gt; * 201 CREATED - [POST/PUT/PATCH]：用户新建或修改数据成功。&gt; &gt; * 202 Accepted - [*]：表示一个请求已经进入后台排队（异步任务）&gt; &gt; * 204 NO CONTENT - [DELETE]：用户删除数据成功。&gt; &gt; * 400 INVALID REQUEST - [POST/PUT/PATCH]：用户发出的请求有错误，服务器没有进行新建或修改数据的操作，该操作是幂等的。&gt; &gt; * 401 Unauthorized - [*]：表示用户没有权限（令牌、用户名、密码错误）。&gt; &gt; * 403 Forbidden - [*] 表示用户得到授权（与401错误相对），但是访问是被禁止的。&gt; &gt; * 404 NOT FOUND - [*]：用户发出的请求针对的是不存在的记录，服务器没有进行操作，该操作是幂等的。&gt; &gt; * 406 Not Acceptable - [GET]：用户请求的格式不可得（比如用户请求JSON格式，但是只有XML格式）。&gt; &gt; * 410 Gone -[GET]：用户请求的资源被永久删除，且不会再得到的。&gt; &gt; * 422 Unprocesable entity - [POST/PUT/PATCH] 当创建一个对象时，发生一个验证错误。&gt; &gt; * 500 INTERNAL SERVER ERROR - [*]：服务器发生错误，用户将无法判断发出的请求是否成功。&gt; &lt;/blockquote&gt;状态码的完全列表参见[这里](http://www.w3.org/Protocols/rfc2616/rfc2616-sec10.html)。## 八、错误处理（Error handling）如果状态码是4xx，就应该向用户返回出错信息。一般来说，返回的信息中将error作为键名，出错信息作为键值即可。&lt;blockquote&gt;1234&#123; error: &quot;Invalid API key&quot;&#125;123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566&lt;/blockquote&gt;## 九、返回结果针对不同操作，服务器向用户返回的结果应该符合以下规范。&lt;blockquote&gt; &gt; &gt; &gt; * GET /collection：返回资源对象的列表（数组）&gt; &gt; * GET /collection/resource：返回单个资源对象&gt; &gt; * POST /collection：返回新生成的资源对象&gt; &gt; * PUT /collection/resource：返回完整的资源对象&gt; &gt; * PATCH /collection/resource：返回完整的资源对象&gt; &gt; * DELETE /collection/resource：返回一个空文档&gt; &lt;/blockquote&gt;## 十、Hypermedia APIRESTful API最好做到Hypermedia，即返回结果中提供链接，连向其他API方法，使得用户不查文档，也知道下一步应该做什么。比如，当用户向api.example.com的根目录发出请求，会得到这样一个文档。&lt;blockquote&gt;1234567&#123;&quot;link&quot;: &#123; &quot;rel&quot;: &quot;collection [https://www.example.com/zoos](https://www.example.com/zoos)&quot;, &quot;href&quot;: &quot;[https://api.example.com/zoos](https://api.example.com/zoos)&quot;, &quot;title&quot;: &quot;List of zoos&quot;, &quot;type&quot;: &quot;application/vnd.yourformat+json&quot;&#125;&#125;12345678910111213141516171819&lt;/blockquote&gt;上面代码表示，文档中有一个link属性，用户读取这个属性就知道下一步该调用什么API了。rel表示这个API与当前网址的关系（collection关系，并给出该collection的网址），href表示API的路径，title表示API的标题，type表示返回类型。Hypermedia API的设计被称为[HATEOAS](http://en.wikipedia.org/wiki/HATEOAS)。Github的API就是这种设计，访问[api.github.com](https://api.github.com/)会得到一个所有可用API的网址列表。&lt;blockquote&gt;123456&#123; &quot;current_user_url&quot;: &quot;[https://api.github.com/user](https://api.github.com/user)&quot;, &quot;authorizations_url&quot;: &quot;[https://api.github.com/authorizations](https://api.github.com/authorizations)&quot;, // ...&#125;12345678910111213&lt;/blockquote&gt;从上面可以看到，如果想获取当前用户的信息，应该去访问[api.github.com/user](https://api.github.com/user)，然后就得到了下面结果。&lt;blockquote&gt;12345&#123; &quot;message&quot;: &quot;Requires authentication&quot;, &quot;documentation_url&quot;: &quot;[https://developer.github.com/v3](https://developer.github.com/v3)&quot;&#125;` 上面代码表示，服务器给出了提示信息，以及文档的网址。 十一、其他（1）API的身份认证应该使用OAuth 2.0框架。 （2）服务器返回的数据格式，应该尽量使用JSON，避免使用XML。 （完）]]></content>
      <categories>
        <category>其它</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[python类中的__slots__属性]]></title>
    <url>%2F2016%2F09%2F21%2F2016-09-21-python-use-__slots__%2F</url>
    <content type="text"><![CDATA[一句话说明`slots1是用来限制实例的属性的， `__slots__ 可以规定实例是否应该有 `dict1属性； `__slots__ 不能限制类的属性。 只有slots列表内的这些变量名可赋值为实例属性。123456class A: __slots__=[&apos;name&apos;] def __init__(self): self.name=&apos;js&apos; self.age=22a=A() 运行结果： 123456Traceback (most recent call last): File &quot;a.py&quot;, line 6, in a=A() File &quot;a.py&quot;, line 5, in __init__ self.age=22AttributeError: &apos;A&apos; object has no attribute &apos;age&apos; slots只是限制实例，对类对象没有影响12345678910class A: __slots__=[&apos;name&apos;,&apos;city&apos;] age=22 def __init__(self): self.name=&apos;js&apos;a=A()print(&apos;A __slots__: &apos;, A.__slots__)print(&apos;a __slots__: &apos;, a.__slots__)print(&apos;A __dict__: &apos;, A.__dict__)print(&apos;a __dict__: &apos;, a.__dict__) 运行结果如下： 1234567891011A __slots__: [&apos;name&apos;, &apos;city&apos;]a __slots__: [&apos;name&apos;, &apos;city&apos;]#事实上，所有定义在__slots__中的属性都会放置在类的__dict__当中，即使没有使用的属性(city)也是如此。#而当实例需要取对象时，总是会先到类的__dict__中进行检查，如果类的__dict__中的属性是一个对象且该对象对属性的读取做了一些限制，那么就会直接影响到实例是否能够调用该属性。__slots__的工作原理是如此，后面介绍的描述符类亦是如此。#在类的__dict__中，也会存入__slots__属性。A __dict__: &#123;&apos;age&apos;: 22, &apos;__init__&apos;: , &apos;name&apos;: &lt;member &apos;name&apos; of &apos;A&apos; objects&gt;, &apos;city&apos;: &lt;member &apos;city&apos; of &apos;A&apos; objects&gt;, &apos;__slots__&apos;: [&apos;name&apos;, &apos;city&apos;], &apos;__module__&apos;: &apos;__main__&apos;, &apos;__doc__&apos;: None&#125;#当我们试图调用a.__dict__时，出现错误，因为该属性没有出现在__slots__中，所以禁止赋值或者访问。Traceback (most recent call last): File &quot;a.py&quot;, line 10, in print(&apos;a __dict__: &apos;, a.__dict__)AttributeError: &apos;A&apos; object has no attribute &apos;__dict__&apos; 可以同时存在slots和dict吗？可以，如果把 `dict1属性存入 `__slots__ 中，那么就允许使用 `dict123属性了。这时，如果所有 `__slots__ 中定义的属性存在 `slots1中，如果没有定义的属性，那么存在 `__dict__ 中，从而实现属性的分别管理。 dir函数获取所有定义在 `slots1和 `__dict__ 中的属性。或者通过list(getattr(X, ‘ dict ‘, [])) + getattr(X, ‘ slots ‘, [])来得到所有的属性。 12345678910class A: __slots__=(&apos;name&apos;,&apos;city&apos;,&apos;__dict__&apos;) def __init__(self): self.name=&apos;js&apos; self.age=22a=A()print(&apos;A __slots__: &apos;, A.__slots__)print(&apos;a __slots__: &apos;, a.__slots__)print(&apos;A __dict__: &apos;, A.__dict__)print(&apos;a __dict__: &apos;, a.__dict__) 运行结果如下： 123456A __slots__: (&apos;name&apos;, &apos;city&apos;, &apos;__dict__&apos;)a __slots__: (&apos;name&apos;, &apos;city&apos;, &apos;__dict__&apos;)#连__dict__都会保存在类的__dict__中，且属性值是一个object。A __dict__: &#123;&apos;city&apos;: &lt;member &apos;city&apos; of &apos;A&apos; objects&gt;, &apos;name&apos;: &lt;member &apos;name&apos; of &apos;A&apos; objects&gt;, &apos;__module__&apos;: &apos;__main__&apos;, &apos;__doc__&apos;: None, &apos;__init__&apos;: , &apos;__slots__&apos;: (&apos;name&apos;, &apos;city&apos;, &apos;__dict__&apos;), &apos;__dict__&apos;: &lt;attribute &apos;__dict__&apos; of &apos;A&apos; objects&gt;&#125;#由于现在age没有出现在__slots__中，且允许存在__dict__，所以属性age出现在实例本身的__dict__中。a __dict__: &#123;&apos;age&apos;: 22&#125; 如果子类中没有slots，但是超类中有 123456789101112class Super:__slots__=[&apos;name&apos;]passclass Sub(Super):def __init__(self):self.name=&apos;js&apos;self.age=22a=Sub()print(&apos;Sub __slots__: &apos;, Sub.__slots__)print(&apos;a __slots__: &apos;, a.__slots__)print(&apos;Sub __dict__: &apos;, Sub.__dict__)print(&apos;a __dict__: &apos;, a.__dict__) 运行结果如下： 1234567#顺利继承到了Super的__slots__属性Sub __slots__: [&apos;name&apos;]a __slots__: [&apos;name&apos;]#此时Python用了大量的黑暗魔法，这时我们看到Sub的__dict__中居然出现了__dict__属性，且值为特殊的对象，相当于Sub.__slots__=Super.__slots__+[&apos;__dict__&apos;]，从而实现如果在__slots__中出现的属性存在__slots__中，没有出现的存在Sub的实例的__dict__中。Sub __dict__: &#123;&apos;__module__&apos;: &apos;__main__&apos;, &apos;__dict__&apos;: &lt;attribute &apos;__dict__&apos; of &apos;Sub&apos; objects&gt;, &apos;__weakref__&apos;: &lt;attribute &apos;__weakref__&apos; of &apos;Sub&apos; objects&gt;, &apos;__doc__&apos;: None, &apos;__init__&apos;: &#125;#我们确实看到了age存在了子类的实例的__dict__中。a __dict__: &#123;&apos;age&apos;: 22&#125; 如果子类和父类都有slots…1234567891011class Super: __slots__=[&apos;name&apos;,&apos;age&apos;]class Sub(Super): __slots__=[&apos;city&apos;]print(&apos;Sub __slots__: &apos;, Sub.__slots__)print(&apos;Sub __dict__: &apos;, Sub.__dict__)#父类中的__slots__没有对子类产生影响Sub __slots__: [&apos;city&apos;]#再次证明了上面的说法，如果一定需要父类的__slots__进行叠加，那么需要手动设置为__slots__=Super.__slots__ + [&apos;city&apos;]，所以可以看出Python通过了大量的黑暗魔法，从而达到__slots__不具有常规的继承特性。Sub __dict__: &#123;&apos;__slots__&apos;: [&apos;city&apos;], &apos;__module__&apos;: &apos;__main__&apos;, &apos;city&apos;: &lt;member &apos;city&apos; of &apos;Sub&apos; objects&gt;, &apos;__doc__&apos;: None&#125; 如果一个子类继承自一个没有slots的超类…如果一个子类继承自一个没有slots 的超类，那么超类的 dict 属性总是可以访问的，使得子类中的一个 slots无意义。 留给你自己验证一下吧。 总结 `slots 1用来设计成对实例的 `__dict__ 的限制，只有 `dict 1出现在 `__slots__ 中，实例才会有 `dict 12 属性。否则，只有出现在 `__slots__ 中的属性才可以被使用。 Python特意设计成 `slots 1没有常规的继承特性，所以只有超类具有 `__slots__ 且其 `dict 1属性没有出现在其中，这时子类的 `__slots__ 才有意义，且子类的 `slots 1不继承父类的 `__slots__ 。]]></content>
      <categories>
        <category>python</category>
      </categories>
      <tags>
        <tag>python</tag>
        <tag>面向对象</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[数据库相关技巧]]></title>
    <url>%2F2016%2F09%2F20%2F2016-09-20-mysql-methods%2F</url>
    <content type="text"><![CDATA[mysql中存储表情符号:聊天的业务中表情的支持比较重要，mysql对表情符号的支持貌似没有postgresql的好，但是历史遗留问题，换库太麻烦，新版本的mysql已经对表情符号支持了，只是需要服务器和客户端设置一下：数据库服务器设置utf8mb4 ： 123456789101112131415161718192021222324252627282930313233[client]port = 3306socket = /var/run/mysqld/mysqld.sockdefault-character-set = utf8mb4# Here is entries for some specific programs# The following values assume you have at least 32M ram# This was formally known as [safe_mysqld]. Both versions are currently parsed.[mysqld_safe]socket = /var/run/mysqld/mysqld.socknice = 0[mysqld]## * Basic Settings#user = mysqlpid-file = /var/run/mysqld/mysqld.pidsocket = /var/run/mysqld/mysqld.sockport = 3306basedir = /usrdatadir = /var/lib/mysqltmpdir = /tmplc-messages-dir = /usr/share/mysqlskip-external-lockingdefault-storage-engine = innodbinnodb_file_per_tablecollation-server = utf8mb4_general_ciinit-connect = &apos;SET NAMES utf8mb4&apos;character-set-server = utf8mb4 客户端设置字符编码：mysql connector设置 1234mysql_con = &apos;mysql+mysqlconnector://%s:%s@%s:%s/%s?charset=utf8mb4&apos; % (mysql_user, mysql_password, mysql_ip, mysql_port, db_name)Engine = create_engine(mysql_con, echo=False) mysql中批量修改指定字段后缀： 12update rp_main set alias=replace(alias, &apos;.files&apos;, &apos;.html&apos;) where alias like &apos;%.files&apos;;]]></content>
      <categories>
        <category>python</category>
      </categories>
      <tags>
        <tag>linux</tag>
        <tag>mysql</tag>
        <tag>python</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[python format用法]]></title>
    <url>%2F2016%2F09%2F07%2F2016-09-07-python-format%2F</url>
    <content type="text"><![CDATA[阅读目录 语法 通过位置 通过关键字 通过对象属性 通过下标 填充和对齐 精度和类型f 进制转化 千位分隔符 python自2.6后，新增了一种格式化字符串函数str.format()，威力十足，可以替换掉原来的% 注：以下操作版本是python2.7 映射示例语法通过{} 和 : 替换 % 通过位置1234&gt;&gt;&gt; &apos;&#123;0&#125; is &#123;1&#125;&apos;.format(&apos;jihite&apos;, &apos;4 years old&apos;)&apos;jihite is 4 years old&apos;&gt;&gt;&gt; &apos;&#123;0&#125; is &#123;1&#125; &#123;0&#125;&apos;.format(&apos;jihite&apos;, &apos;4 years old&apos;)&apos;jihite is 4 years old jihite&apos; 通过format函数可以接受不限参数个数、不限顺序 通过关键字1234&gt;&gt;&gt; &apos;&#123;name&#125;:&#123;age&#125;&apos;.format(age=4,name=&apos;jihite&apos;)&apos;jihite:4&apos;&gt;&gt;&gt; &apos;&#123;name&#125;:&#123;age&#125;&apos;.format(age=4,name=&apos;jihite&apos;,locate=&apos;Beijing&apos;)&apos;jihite:4&apos; format括号内用=给变量赋值 通过对象属性123456789&gt;&gt;&gt; class Person:... def __init__(self, name, age):... self.name,self.age = name, age... def __func__(self):... return &quot;This guy is &#123;self.name&#125;, is &#123;self.age&#125; old&quot;.format(self=self)... &gt;&gt;&gt; s =Person(&apos;jihite&apos;, 4)&gt;&gt;&gt; s.__func__()&apos;This guy is jihite, is 4 old&apos; 通过下标1234&gt;&gt;&gt; &apos;&#123;0[0]&#125; is &#123;0[1]&#125; years old!&apos;.format([&apos;jihite&apos;, 4])&apos;jihite is 4 years old!&apos;&gt;&gt;&gt; &apos;&#123;0&#125; is &#123;1&#125; years old!&apos;.format(&apos;jihite&apos;, 4)&apos;jihite is 4 years old!&apos; 其实就是通过位置 格式限定符通过{} : 符号 填充和对齐^&lt;&gt;分别表示居中、左对齐、右对齐，后面带宽度 123456&gt;&gt;&gt; &apos;&#123;:&gt;10&#125;&apos;.format(&apos;jihite&apos;)&apos; jihite&apos;&gt;&gt;&gt; &apos;&#123;:&lt;10&#125;&apos;.format(&apos;jihite&apos;)&apos;jihite &apos;&gt;&gt;&gt; &apos;&#123;:^10&#125;&apos;.format(&apos;jihite&apos;)&apos; jihite &apos; 精度和类型f精度常和f一起使用 1234&gt;&gt;&gt; &apos;&#123;:.2f&#125;&apos;.format(3.1415)&apos;3.14&apos;&gt;&gt;&gt; &apos;&#123;:.4f&#125;&apos;.format(3.1)&apos;3.1000&apos; 进制转化12345678&gt;&gt;&gt; &apos;&#123;:b&#125;&apos;.format(10)&apos;1010&apos;&gt;&gt;&gt; &apos;&#123;:o&#125;&apos;.format(10)&apos;12&apos;&gt;&gt;&gt; &apos;&#123;:d&#125;&apos;.format(10)&apos;10&apos;&gt;&gt;&gt; &apos;&#123;:x&#125;&apos;.format(10)&apos;a&apos; 其中b o d x分别表示二、八、十、十六进制 千位分隔符12&gt;&gt;&gt; &apos;&#123;:,&#125;&apos;.format(1000000)&apos;1,000,000&apos; ‘{:,}’.format(100000.23433)‘100,000.23433’ 1234&gt;&gt;&gt; &apos;&#123;:,&#125;&apos;.format(&apos;abcedef&apos;)Traceback (most recent call last): File &quot;&lt;stdin&gt;&quot;, line 1, in &lt;module&gt;ValueError: Cannot specify &apos;,&apos; with &apos;s&apos;. 这种情况只针对数字]]></content>
      <categories>
        <category>python</category>
      </categories>
      <tags>
        <tag>python</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[python下排序总结]]></title>
    <url>%2F2016%2F09%2F06%2F2016-09-06-python-sort%2F</url>
    <content type="text"><![CDATA[对字典组成的列表进行排序： 12345my_list = [&#123;&apos;a&apos;:1, &apos;b&apos;:&apos;ccc&apos;&#125;, &#123;&apos;a&apos;:-1, &apos;b&apos;:&apos;zzz&apos;&#125;]my_list.sort(key=lambda x: x[&apos;a&apos;], reverse=False)print my_listIn [9]: [&#123;&apos;a&apos;: -1, &apos;b&apos;: &apos;zzz&apos;&#125;, &#123;&apos;a&apos;: 1, &apos;b&apos;: &apos;ccc&apos;&#125;] python标准库中的有序字典可以对字典进行排序：class collections.OrderedDict([items]) 注意顺序以添加顺序为准，和修改的顺序无关。 特殊方法：OrderedDict.popitem(last=True) 。last为True是LIFO,即为堆栈，反之是FIFO，即为队列。还支持排序： reversed() .]]></content>
      <categories>
        <category>python</category>
      </categories>
      <tags>
        <tag>python</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[iptables详解]]></title>
    <url>%2F2016%2F09%2F06%2F2016-09-06-iptables-content%2F</url>
    <content type="text"><![CDATA[一：前言 防 火墙，其实说白了讲，就是用于实现Linux下访问控制的功能的，它分为硬件的或者软件的防火墙两种。无论是在哪个网络中，防火墙工作的地方一定是在网络 的边缘。而我们的任务就是需要去定义到底防火墙如何工作，这就是防火墙的策略，规则，以达到让它对出入网络的IP、数据进行检测。 目前市面上比较常见的有3、4层的防火墙，叫网络层的防火墙，还有7层的防火墙，其实是代理层的网关。 对于TCP/IP的七层模型来讲，我们知道第三层是网络层，三层的防火墙会在这层对源地址和目标地址进行检测。但是对于七层的防火墙，不管你源端口或者目标端口，源地址或者目标地址是什么，都将对你所有的东西进行检查。 所以，对于设计原理来讲，七层防火墙更加安全，但是这却带来了效率更低。所以市面上通常的防火墙方案，都是两者结合的。而又由于我们都需要从防火墙所控制 的这个口来访问，所以防火墙的工作效率就成了用户能够访问数据多少的一个最重要的控制，配置的不好甚至有可能成为流量的瓶颈。 二：iptables 的历史以及工作原理 1.iptables的发展: iptables 的前身叫ipfirewall （内核1.x时代）,这是一个作者从freeBSD上移植过来的，能够工作在内核当中的，对数据包进行检测的一款简易访问控制工具。但是 ipfirewall工作功能极其有限(它需要将所有的规则都放进内核当中，这样规则才能够运行起来，而放进内核，这个做法一般是极其困难的)。当内核发 展到2.x系列的时候，软件更名为ipchains，它可以定义多条规则，将他们串起来，共同发挥作用，而现在，它叫做iptables，可以将规则组成一个列表，实现绝对详细的访问控制功能。 他们都是工作在用户空间中，定义规则的工具，本身并不算是防火墙。它们定义的规则，可以让在内核空间当中的netfilter来读取，并且实现让防火墙工作。而放入内核的地方必须要是特定的位置，必须是tcp/ip的协议栈经过的地方。而这个tcp/ip协议栈必须经过的地方，可以实现读取规则的地方就叫做 netfilter.(网络过滤器) 作者一共在内核空间中选择了5个位置， 1.内核空间中：从一个网络接口进来，到另一个网络接口去的 2.数据包从内核流入用户空间的 3.数据包从用户空间流出的 4.进入/离开本机的外网接口 5.进入/离开本机的内网接口 2.iptables的工作机制 从 上面的发展我们知道了作者选择了5个位置，来作为控制的地方，但是你有没有发现，其实前三个位置已经基本上能将路径彻底封锁了，但是为什么已经在进出的口 设置了关卡之后还要在内部卡呢？ 由于数据包尚未进行路由决策，还不知道数据要走向哪里，所以在进出口是没办法实现数据过滤的。所以要在内核空间里设置转发的关卡，进入用户空间的关卡，从 用户空间出去的关卡。那么，既然他们没什么用，那我们为什么还要放置他们呢？因为我们在做NAT和DNAT的时候，目标地址转换必须在路由之前转换。所以我们必须在外网而后内网的接口处进行设置关卡。 这五个位置也被称为五个钩子函数（hook functions）,也叫五个规则链。 1.PREROUTING (路由前) 2.INPUT (数据包流入口) 3.FORWARD (转发管卡) 4.OUTPUT(数据包出口) 5.POSTROUTING（路由后） 这是NetFilter规定的五个规则链，任何一个数据包，只要经过本机，必将经过这五个链中的其中一个链。 3.防火墙的策略 防火墙策略一般分为两种，一种叫“通”策略，一种叫“堵”策略，通策略，默认门是关着的，必须要定义谁能进。堵策略则是，大门是洞开的，但是你必须有身份认证，否则不能进。所以我们要定义，让进来的进来，让出去的出去，所以通，是要全通，而堵，则是要选择。当我们定义的策略的时候，要分别定义多条功能，其中：定义数据包中允许或者不允许的策略，filter过滤的功能，而定义地址转换的功能的则是nat选项。为了让这些功能交替工作，我们制定出了“表”这个定义，来定义、区分各种不同的工作功能和处理方式。 我们现在用的比较多个功能有3个： 1.filter 定义允许或者不允许的 2.nat 定义地址转换的 3.mangle功能:修改报文原数据 我们修改报文原数据就是来修改TTL的。能够实现将数据包的元数据拆开，在里面做标记/修改内容的。而防火墙标记，其实就是靠mangle来实现的。 小扩展: 对于filter来讲一般只能做在3个链上：INPUT ，FORWARD ，OUTPUT 对于nat来讲一般也只能做在3个链上：PREROUTING ，OUTPUT ，POSTROUTING 而mangle则是5个链都可以做：PREROUTING，INPUT，FORWARD，OUTPUT，POSTROUTING iptables/netfilter（这款软件）是工作在用户空间的，它可以让规则进行生效的，本身不是一种服务，而且规则是立即生效的。而我们iptables现在被做成了一个服务，可以进行启动，停止的。启动，则将规则直接生效，停止，则将规则撤销。 iptables还支持自己定义链。但是自己定义的链，必须是跟某种特定的链关联起来的。在一个关卡设定，指定当有数据的时候专门去找某个特定的链来处理，当那个链处理完之后，再返回。接着在特定的链中继续检查。 注意：规则的次序非常关键，谁的规则越严格，应该放的越靠前，而检查规则的时候，是按照从上往下的方式进行检查的。 三．规则的写法: iptables定义规则的方式比较复杂: 格式：iptables [-t table] COMMAND chain CRETIRIA -j ACTION -t table ：3个filter nat mangle COMMAND：定义如何对规则进行管理 chain：指定你接下来的规则到底是在哪个链上操作的，当定义策略的时候，是可以省略的 CRETIRIA:指定匹配标准 -j ACTION :指定如何进行处理 比如：不允许172.16.0.0/24的进行访问。 iptables -t filter -A INPUT -s 172.16.0.0/16 -p udp –dport 53 -j DROP 当然你如果想拒绝的更彻底： iptables -t filter -R INPUT 1 -s 172.16.0.0/16 -p udp –dport 53 -j REJECT iptables -L -n -v #查看定义规则的详细信息 四：详解COMMAND: 1.链管理命令（这都是立即生效的） -P :设置默认策略的（设定默认门是关着的还是开着的） 默认策略一般只有两种 iptables -P INPUT (DROP|ACCEPT) 默认是关的/默认是开的 比如： iptables -P INPUT DROP 这就把默认规则给拒绝了。并且没有定义哪个动作，所以关于外界连接的所有规则包括Xshell连接之类的，远程连接都被拒绝了。 -F: FLASH，清空规则链的(注意每个链的管理权限) iptables -t nat -F PREROUTING iptables -t nat -F 清空nat表的所有链 -N:NEW 支持用户新建一个链 iptables -N inbound_tcp_web 表示附在tcp表上用于检查web的。 -X: 用于删除用户自定义的空链 使用方法跟-N相同，但是在删除之前必须要将里面的链给清空昂了 -E：用来Rename chain主要是用来给用户自定义的链重命名 -E oldname newname -Z：清空链，及链中默认规则的计数器的（有两个计数器，被匹配到多少个数据包，多少个字节） iptables -Z :清空 2.规则管理命令 -A：追加，在当前链的最后新增一个规则 -I num : 插入，把当前规则插入为第几条。 -I 3 :插入为第三条 -R num：Replays替换/修改第几条规则 格式：iptables -R 3 ………… -D num：删除，明确指定删除第几条规则 3.查看管理命令 “-L” 附加子命令 -n：以数字的方式显示ip，它会将ip直接显示出来，如果不加-n，则会将ip反向解析成主机名。 -v：显示详细信息 -vv -vvv :越多越详细 -x：在计数器上显示精确值，不做单位换算 –line-numbers : 显示规则的行号 -t nat：显示所有的关卡的信息 五：详解匹配标准 1.通用匹配：源地址目标地址的匹配 -s：指定作为源地址匹配，这里不能指定主机名称，必须是IP IP | IP/MASK | 0.0.0.0/0.0.0.0 而且地址可以取反，加一个“!”表示除了哪个IP之外 -d：表示匹配目标地址 -p：用于匹配协议的（这里的协议通常有3种，TCP/UDP/ICMP） -i eth0：从这块网卡流入的数据 流入一般用在INPUT和PREROUTING上 -o eth0：从这块网卡流出的数据 流出一般在OUTPUT和POSTROUTING上 2.扩展匹配 2.1隐含扩展：对协议的扩展 -p tcp :TCP协议的扩展。一般有三种扩展 –dport XX-XX：指定目标端口,不能指定多个非连续端口,只能指定单个端口，比如 –dport 21 或者 –dport 21-23 (此时表示21,22,23) –sport：指定源端口 –tcp-fiags：TCP的标志位（SYN,ACK，FIN,PSH，RST,URG） 对于它，一般要跟两个参数： 1.检查的标志位 2.必须为1的标志位 –tcpflags syn,ack,fin,rst syn = –syn 表示检查这4个位，这4个位中syn必须为1，其他的必须为0。所以这个意思就是用于检测三次握手的第一次包的。对于这种专门匹配第一包的SYN为1的包，还有一种简写方式，叫做–syn -p udp：UDP协议的扩展 --dport --sport -p icmp：icmp数据报文的扩展 --icmp-type： echo-request(请求回显)，一般用8 来表示 所以 –icmp-type 8 匹配请求回显数据包 echo-reply （响应的数据包）一般用0来表示 2.2显式扩展（-m） 扩展各种模块 -m multiport：表示启用多端口扩展 之后我们就可以启用比如 --dports 21,23,80 六：详解-j ACTION 常用的ACTION： DROP：悄悄丢弃 一般我们多用DROP来隐藏我们的身份，以及隐藏我们的链表 REJECT：明示拒绝 ACCEPT：接受 custom_chain：转向一个自定义的链 DNAT SNAT MASQUERADE：源地址伪装 REDIRECT：重定向：主要用于实现端口重定向 MARK：打防火墙标记的 RETURN：返回 在自定义链执行完毕后使用返回，来返回原规则链。 练习题1： 只要是来自于172.16.0.0/16网段的都允许访问我本机的172.16.100.1的SSHD服务 分析：首先肯定是在允许表中定义的。因为不需要做NAT地址转换之类的，然后查看我们SSHD服务，在22号端口上，处理机制是接受，对于这个表，需要 有一来一回两个规则，如果我们允许也好，拒绝也好，对于访问本机服务，我们最好是定义在INPUT链上，而OUTPUT再予以定义就好。(会话的初始端先 定义)，所以加规则就是： 定义进来的： iptables -t filter -A INPUT -s 172.16.0.0/16 -d 172.16.100.1 -p tcp --dport 22 -j ACCEPT 定义出去的： iptables -t filter -A OUTPUT -s 172.16.100.1 -d 172.16.0.0/16 -p tcp --dport 22 -j ACCEPT 将默认策略改成DROP: iptables -P INPUT DROP iptables -P OUTPUT DROP iptables -P FORWARD DROP 七：状态检测： 是一种显式扩展，用于检测会话之间的连接关系的，有了检测我们可以实现会话间功能的扩展 什么是状态检测？对于整个TCP协议来讲，它是一个有连接的协议，三次握手中，第一次握手，我们就叫NEW连接，而从第二次握手以后的，ack都为1，这 是正常的数据传输，和tcp的第二次第三次握手，叫做已建立的连接（ESTABLISHED）,还有一种状态，比较诡异的，比如：SYN=1 ACK=1 RST=1,对于这种我们无法识别的，我们都称之为INVALID无法识别的。还有第四种，FTP这种古老的拥有的特征，每个端口都是独立的，21号和 20号端口都是一去一回，他们之间是有关系的，这种关系我们称之为RELATED。 所以我们的状态一共有四种： NEW ESTABLISHED RELATED INVALID 所以我们对于刚才的练习题，可以增加状态检测。比如进来的只允许状态为NEW和ESTABLISHED的进来，出去只允许ESTABLISHED的状态出去，这就可以将比较常见的反弹式木马有很好的控制机制。 对于练习题的扩展： 进来的拒绝出去的允许，进来的只允许ESTABLISHED进来，出去只允许ESTABLISHED出去。默认规则都使用拒绝 iptables -L -n –line-number ：查看之前的规则位于第几行 改写INPUT iptables -R INPUT 2 -s 172.16.0.0/16 -d 172.16.100.1 -p tcp --dport 22 -m state --state NEW,ESTABLISHED -j ACCEPT iptables -R OUTPUT 1 -m state --state ESTABLISHED -j ACCEPT 此时如果想再放行一个80端口如何放行呢？ iptables -A INPUT -d 172.16.100.1 -p tcp --dport 80 -m state --state NEW,ESTABLISHED -j ACCEPT iptables -R INPUT 1 -d 172.16.100.1 -p udp --dport 53 -j ACCEPT 练习题2： 假如我们允许自己ping别人，但是别人ping自己ping不通如何实现呢？ 分析：对于ping这个协议，进来的为8（ping），出去的为0(响应).我们为了达到目的，需要8出去,允许0进来 在出去的端口上：iptables -A OUTPUT -p icmp –icmp-type 8 -j ACCEPT 在进来的端口上：iptables -A INPUT -p icmp –icmp-type 0 -j ACCEPT 小扩展：对于127.0.0.1比较特殊，我们需要明确定义它 iptables -A INPUT -s 127.0.0.1 -d 127.0.0.1 -j ACCEPT iptables -A OUTPUT -s 127.0.0.1 -d 127.0.0.1 -j ACCEPT 八：SNAT和DNAT的实现 由于我们现在IP地址十分紧俏，已经分配完了，这就导致我们必须要进行地址转换，来节约我们仅剩的一点IP资源。那么通过iptables如何实现NAT的地址转换呢？ 1.SNAT基于原地址的转换 基于原地址的转换一般用在我们的许多内网用户通过一个外网的口上网的时候，这时我们将我们内网的地址转换为一个外网的IP，我们就可以实现连接其他外网IP的功能。 所以我们在iptables中就要定义到底如何转换： 定义的样式： 比如我们现在要将所有192.168.10.0网段的IP在经过的时候全都转换成172.16.100.1这个假设出来的外网地址： iptables -t nat -A POSTROUTING -s 192.168.10.0/24 -j SNAT –to-source 172.16.100.1 这样，只要是来自本地网络的试图通过网卡访问网络的，都会被统统转换成172.16.100.1这个IP. 那么，如果172.16.100.1不是固定的怎么办？ 我 们都知道当我们使用联通或者电信上网的时候，一般它都会在每次你开机的时候随机生成一个外网的IP，意思就是外网地址是动态变换的。这时我们就要将外网地 址换成 MASQUERADE(动态伪装):它可以实现自动寻找到外网地址，而自动将其改为正确的外网地址。所以，我们就需要这样设置： iptables -t nat -A POSTROUTING -s 192.168.10.0/24 -j MASQUERADE 这里要注意：地址伪装并不适用于所有的地方。 2.DNAT目标地址转换 对于目标地址转换，数据流向是从外向内的，外面的是客户端，里面的是服务器端通过目标地址转换，我们可以让外面的ip通过我们对外的外网ip来访问我们服务器不同的服务器，而我们的服务却放在内网服务器的不同的服务器上。 如何做目标地址转换呢？： iptables -t nat -A PREROUTING -d 192.168.10.18 -p tcp –dport 80 -j DNAT –todestination 172.16.100.2 目标地址转换要做在到达网卡之前进行转换,所以要做在PREROUTING这个位置上 九：控制规则的存放以及开启 注意：你所定义的所有内容，当你重启的时候都会失效，要想我们能够生效，需要使用一个命令将它保存起来 1.service iptables save 命令 它会保存在/etc/sysconfig/iptables这个文件中 2.iptables-save 命令 iptables-save &gt; /etc/sysconfig/iptables 3.iptables-restore 命令 开机的时候，它会自动加载/etc/sysconfig/iptabels 如果开机不能加载或者没有加载，而你想让一个自己写的配置文件（假设为iptables.2）手动生效的话： iptables-restore &lt; /etc/sysconfig/iptables.2 则完成了将iptables中定义的规则手动生效 十：总结 Iptables是一个非常重要的工具，它是每一个防火墙上几乎必备的设置，也是我们在做大型网络的时候，为了很多原因而必须要设置的。学好 Iptables,可以让我们对整个网络的结构有一个比较深刻的了解，同时，我们还能够将内核空间中数据的走向以及linux的安全给掌握的非常透彻。我 们在学习的时候，尽量能结合着各种各样的项目，实验来完成，这样对你加深iptables的配置，以及各种技巧有非常大的帮助。 附加iptables比较好的文章： netfilter/iptables全攻略 原文地址：http://blog.chinaunix.net/uid-26495963-id-3279216.html]]></content>
      <categories>
        <category>技术</category>
      </categories>
      <tags>
        <tag>linux</tag>
        <tag>系统</tag>
        <tag>防火墙</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[django中的多字段外键关联同一张表]]></title>
    <url>%2F2016%2F09%2F05%2F2016-09-05-django-tables-related%2F</url>
    <content type="text"><![CDATA[django中的多字段外键关联同一张表时会报一个错误： 123456SystemCheckError: System check identified some issues: account.Fans.fans: (fields.E304) Reverse accessor for &apos;Fans.fans&apos; clashes with reverse accessor for &apos;Fans.user&apos;. HINT: Add or change a related_name argument to the definition for &apos;Fans.fans&apos; or &apos;Fans.user&apos;.account.Fans.user: (fields.E304) Reverse accessor for &apos;Fans.user&apos; clashes with reverse accessor for &apos;Fans.fans&apos;. HINT: Add or change a related_name argument to the definition for &apos;Fans.user&apos; or &apos;Fans.fans&apos;. 解决方法：将同一个表中的releated_name，全部修改，指定不一样的releated_name 12345678910111213@python_2_unicode_compatibleclass Fans(BaseModel): user = models.ForeignKey(User, verbose_name=u&quot;用户ID&quot;, related_name=u&apos;用户ID&apos;) fans = models.ForeignKey(User, verbose_name=u&quot;粉丝ID&quot;, related_name=u&apos;粉丝ID&apos;) def __str__(self): return str(self.user.id) class Meta: db_table = &apos;fans&apos; verbose_name = u&quot;粉丝表&quot; verbose_name_plural = u&quot;粉丝表&quot;]]></content>
      <categories>
        <category>django</category>
        <category>python</category>
      </categories>
      <tags>
        <tag>django</tag>
        <tag>python</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Python中类总结]]></title>
    <url>%2F2016%2F09%2F01%2F2016-09-01-python-class%2F</url>
    <content type="text"><![CDATA[1.类的继承顺序：a.经典类中继承顺序按照深度优先；b.新式类中继承顺序按照广度优先；新式类中有个mro属性可以显示查找顺序 2.开头的几个类方法： init__() 构造函数 简单的调用方法: obj = className(args)new()call() 表示可调用的实例del(self) 析构方法, 删除一个对象 简单的调用方法 : del obj ;repr(self) 转化为供解释器读取的形式 简单的调用方法 : repr(obj);str(self) 用于将值转化为适于人阅读的形式 简单的调用方法 : str(obj);cmp(self,x) 对象比较 简单的调用方法 : cmp(obj, x); 开头的类属性： dict__: 类的属性（包含一个字典，由类的数据属性组成）;slots: 用于限制类的属性，定义slots以后就不会出现dict了bases : 类的所有父类构成元素（包含了一个由所有父类组成的元组）;doc :类的文档字符串name: 类名 所以，init 和 new 最主要的区别在于： init 通常用于初始化一个新实例，控制这个初始化的过程，比如添加一些属性， 做一些额外的操作，发生在类实例被创建完以后。它是实例级别的方法。 new 通常用于控制生成一个新实例的过程。它是类级别的方法。]]></content>
      <categories>
        <category>python</category>
      </categories>
      <tags>
        <tag>python</tag>
        <tag>class</tag>
        <tag>面向对象</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[ubuntu安装ss客户端]]></title>
    <url>%2F2016%2F08%2F22%2F2016-08-22-ubuntu-install-ss-client%2F</url>
    <content type="text"><![CDATA[文章目录 第一种 ubuntu安装shadowsocks 启动shadowsocks 第二种 配置浏览器 安装插件 设置代理地址 设置自动切换 开机后台自动运行ss 之前介绍过用搬瓦工的vps可以轻松的搭建shadowsocks服务，然后在windows上和安卓手机平板等上轻松科学上网，只要下载对应的程序即可，当来到ubuntu上怎么配置shadowsocks来科学上网呢？有两种方法可行 1.安装shadowsocks命令行程序，配置命令。 2.安装shadowsocks GUI图形界面程序，配置。 个人推荐第一种，配置好后基本不用管。但使用的前提是 你的服务端已经搭建好或者你有别人提供的SS 服务（我也不知道该不该写这文章…） 第一种ubuntu安装shadowsocks用PIP安装很简单， 12345 1. ```pln sudo apt-get update 1sudo apt-get install python-pip 1sudo apt-get install python-setuptools m2crypto 12345678910111213接着安装shadowsocks```prettyprint prettyprinted pip install shadowsocks 如果是ubuntu16.04 直接 (16.04 里可以直接用apt 而不用 apt-get 这是一项改进） prettyprinted 1sudo apt install shadowsocks 当然你在安装时候肯定有提示需要安装一些依赖比如python-setuptools m2crypto ，依照提示安装然后再安装就好。也可以网上搜索有很多教程的。 启动shadowsocks安装好后，在本地我们要用到sslocal ，终端输入sslocal –help 可以查看帮助，像这样 通过帮助提示我们知道各个参数怎么配置，比如 sslocal -c 后面加上我们的json配置文件，或者像下面这样直接命令参数写上运行。 比如 sslocal -s 11.22.33.44 -p 50003 -k “123456” -l 1080 -t 600 -m aes-256-cfb -s表示服务IP, -p指的是服务端的端口，-l是本地端口默认是1080, -k 是密码（要加””）, -t超时默认300,-m是加密方法默认aes-256-cfb， 为了方便我推荐直接用sslcoal -c 配置文件路径 这样的方式，简单好用。 我们可以在/home/mudao/ 下新建个文件shadowsocks.json (mudao是我在我电脑上的用户名，这里路径你自己看你的)。内容是这样： 12345 1. ```pun &#123; 1&quot;server&quot;:&quot;11.22.33.44&quot;, 1&quot;server_port&quot;:50003, 1&quot;local_port&quot;:1080, 1&quot;password&quot;:&quot;123456&quot;, 1&quot;timeout&quot;:600, 1&quot;method&quot;:&quot;aes-256-cfb&quot; 1&#125; 123456789101112131415161718192021222324252627282930313233343536373839404142server 你服务端的IP servier_port 你服务端的端口 local_port 本地端口，一般默认1080 passwd ss服务端设置的密码 timeout 超时设置 和服务端一样 method 加密方法 和服务端一样确定上面的配置文件没有问题，然后我们就可以在终端输入 sslocal -c /home/mudao/shadowsocks.json 回车运行。如果没有问题的话，下面会是这样...![sslocal](https://aitanlu.com/wp-content/uploads/2016/04/sslocal-1.png)（如果继续请不要关闭这个终端）如果你选择这一种请跳过第二种。你可以去系统的代理设置按照说明设置代理，但一般是全局的，然而我们访问baidu,taobao等着些网站如果用代理就有点绕了，而且还会浪费服务器流量。我们最好配置我们的浏览器让它可以自动切换，该用代理用代理该直接连接自动直接连接。所以请看配置浏览器。## 第二种安装GUI 图形界面程序，然后按照提示配置相对应的参数。安装教程地址：[shadowsocks-qt5 安装指南](https://github.com/shadowsocks/shadowsocks-qt5/wiki/%E5%AE%89%E8%A3%85%E6%8C%87%E5%8D%97)在ubuntu上可以这样，通过PPA源安装，仅支持Ubuntu 14.04或更高版本。 1sudo add-apt-repository ppa:hzwhuang/ss-qt5 1sudo apt-get update 1sudo apt-get install shadowsocks-qt5 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899由于是图形界面，配置和windows基本没啥差别就不赘述了。经过上面的配置，你只是启动了sslocal 但是要上网你还需要配置下浏览器到指定到代理端口比如1080才可以正式上网。## 配置浏览器假如你上面任选一种方式已经开始运行sslocal了，火狐那个代理插件老是订阅不了gfwlist所以配置自动模式的话不好使。这里用的是chrome，你可以在Ubuntu软件中心下载得到。### 安装插件我们需要给chrome安装SwitchyOmega插件，但是没有代理之前是不能从谷歌商店安装这个插件的，但是我们可以从Github上直接下载最新版 [https://github.com/FelisCatus/SwitchyOmega/releases/](https://github.com/FelisCatus/SwitchyOmega/releases/) （这个是chrome的）然后浏览器地址打开chrome://extensions/，将下载的插件托进去安装。### 设置代理地址安装好插件会自动跳到设置选项，有提示你可以跳过。左边新建情景模式-选择代理服务器-比如命名为SS（叫什么无所谓）其他默认之后创建，之后在代理协议选择SOCKS5，地址为127.0.0.1,端口默认1080 。然后保存即应用选项。![shadowsocks-0](https://aitanlu.com/wp-content/uploads/2016/04/shadowsocks-0.png)![shadowsocks-1](https://aitanlu.com/wp-content/uploads/2016/04/shadowsocks-1.png)### 设置自动切换接着点击自动切换 ( Auto switch）上面的不用管，在按照规则列表匹配请求后面选择刚才新建的SS，默认情景模式选择直接连接。点击应用选项保存。再往下规则列表设置选择AutoProxy 然后将**[这个地址](https://raw.githubusercontent.com/gfwlist/gfwlist/master/gfwlist.txt)**填进去，点击下面的立即更新情景模式，会有提示更新成功！![shadowsocks-2](https://aitanlu.com/wp-content/uploads/2016/04/shadowsocks-2.png)sorry编辑图片时候少了一步，就是填好规则列表地址后先点击立即更新情景模式 后再应用选项保存https://raw.githubusercontent.com/gfwlist/gfwlist/master/gfwlist.txt点击浏览器右上角的SwitchyOmega图标，下面选择自动切换，然后打开google.com试试，其他的就不在这贴图了。![shadowsocks-3](https://aitanlu.com/wp-content/uploads/2016/04/shadowsocks-3.png)## 开机后台自动运行ss如果你选择了第二种可以不管这个如果你上面可以代理上网了可以进行这一步，之前我让你不要关掉终端，因为关掉终端的时候代理就随着关闭了，之后你每次开机或者关掉终端之后，下次你再想用代理就要重新在终端输入这样的命令 sslocal -c /home/mudao/shadowsocks.json ，挺麻烦是不？我们现在可以在你的ubuntu上安装一个叫做supervisor的程序来管理你的sslocal启动。关于supervisor更多点击这```prettyprint prettyprinted sudo apt-get install supervisor 安装好后我们可以在/etc/supervisor/目录下找到supervisor.conf配置文件，我们可以用以下命令来编辑 prettyprinted 1sudo gedit /etc/supervisor/supervisor.conf 在这个文件的最后加上以下内容 12345 1. ```pun [program:shadowsocks] 1command=sslocal -c /home/mudao/shadowsocks.json 1autostart=true 1autorestart=true 1user=root 1log_stderr=true 1logfile=/var/log/shadowsocks.log 123456789101112131415161718当然在16.04里你可以直接在/etc/supervisor/conf.d/下新建个文件比如ss.conf然后加入上面内容。command = 这里json文件的路径根据你的文件路径来填写。确认无误后记得保存。sslocal 和ssserver这两个命令是被存在 /usr/local/bin/下面的，我们要拷贝一份命令文件到/bin```prettyprint prettyprinted sudo cp /usr/local/bin/sslocal /bin (注意空格) 注意：16.04 命令在 /usr/bin/下所以就用 prettyprinted 1sudo cp /usr/bin/sslocal /bin (注意空格) 现在关掉你之前运行sslocal命令的终端，再打开终端输入sudo service supervisor restart 然后去打开浏览器看看可不可以继续代理上网。你也可以用ps -ef|grep sslocal命令查看sslocal是否在运行。 这个时候我们需要在/etc下编辑一个叫rc.local的文件 ，让supervisor开机启动。 prettyprinted 1sudo gedit /etc/rc.local 在这个配置文件的exit 0前面一行加上 service supervisor start 保存。看你是否配置成功你可以在现在关机重启之后直接打开浏览器看是否代理成功。 4.86941 [ _66_](javascript:;) [ _3_](javascript:;) 评论加载中]]></content>
      <categories>
        <category>linux</category>
      </categories>
      <tags>
        <tag>ubuntu</tag>
        <tag>shadowsocks</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Django中获取请求头header]]></title>
    <url>%2F2016%2F08%2F22%2F2016-08-22-django-get-header%2F</url>
    <content type="text"><![CDATA[requests库来模拟请求 123456789101112#test headerheaders = &#123; &quot;Accept&quot;:&quot;text/html,application/xhtml+xml,application/xml;&quot;, &quot;Accept-Encoding&quot;:&quot;gzip&quot;, &quot;Accept-Language&quot;:&quot;zh-CN,zh;q=0.8&quot;, &quot;Referer&quot;:&quot;http://www.example.com/&quot;, &quot;User-Agent&quot;:&quot;Mozilla/5.0 (Windows NT 6.1; WOW64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/42.0.2311.90 Safari/537.36&quot;, &quot;myuser&quot;: &apos;hello&apos;, &#125;payload = &#123;&apos;user_id&apos;: 11, &apos;token&apos;: &apos;token&apos;, &apos;is_reported&apos;: 25, &apos;content&apos;: u&apos;不正当经营&apos;, &apos;is_activity&apos;: True&#125;r = requests.get(&apos;http://localhost:9000/test/&apos;, data=payload, headers=headers)print r.text request请求头信息的键会加上HTTP_转换成大写存到request.META中 12345678910111213141516def test(request): if request.method == &apos;GET&apos;: # header = request.get(&apos;header&apos;, None) msg = &#123;&apos;code&apos;: 200&#125; print &apos;request:&apos;, dir(request) print &apos;meta:&apos;, request.META print &apos;GET:&apos;, dir(request.GET) print &apos;user:&apos;, request.META.get(&apos;HTTP_MYUSER&apos;, None) fp = open(&apos;out.txt&apos;, &apos;w&apos;) fp.write(&apos;request:%s\n&apos; % str(request)) fp.write(&apos;request:%s\n&apos; % str(request.META)) fp.write(&apos;request:%s\n&apos; % str(request.GET)) fp.close() # response[&apos;X-DJANGO&apos;] = &quot;It&apos;s the best.&quot; return HttpResponse(json.dumps(msg), content_type=&quot;application/json&quot;) django官网的解释： 123456789101112131415161718192021222324252627282930313233HttpRequest.METAA standard Python dictionary containing all available HTTP headers. Available headers depend on the client and server, but here are some examples:CONTENT_LENGTH – the length of the request body (as a string).CONTENT_TYPE – the MIME type of the request body.HTTP_ACCEPT_ENCODING – Acceptable encodings for the response.HTTP_ACCEPT_LANGUAGE – Acceptable languages for the response.HTTP_HOST – The HTTP Host header sent by the client.HTTP_REFERER – The referring page, if any.HTTP_USER_AGENT – The client’s user-agent string.QUERY_STRING – The query string, as a single (unparsed) string.REMOTE_ADDR – The IP address of the client.REMOTE_HOST – The hostname of the client.REMOTE_USER – The user authenticated by the Web server, if any.REQUEST_METHOD – A string such as &quot;GET&quot; or &quot;POST&quot;.SERVER_NAME – The hostname of the server.SERVER_PORT – The port of the server (as a string).With the exception of CONTENT_LENGTH and CONTENT_TYPE, as given above, any HTTP headers in the request are converted toMETA keys by converting all characters to uppercase, replacing any hyphens with underscores and adding an HTTP_ prefix to the name. So, for example, a header called X-Bender would be mapped to the META key HTTP_X_BENDER.]]></content>
      <categories>
        <category>django</category>
        <category>python</category>
      </categories>
      <tags>
        <tag>django</tag>
        <tag>python</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[python模拟生物进化和遗传算法]]></title>
    <url>%2F2016%2F08%2F21%2F2016-08-21-python-Simulated-biological-evolution%2F</url>
    <content type="text"><![CDATA[123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135#-*- coding:utf-8 -*-from PIL import Image as im from os import path from math import log from random import randint from copy import deepcopy import pickle as pk #全局变量 quanju_v = &#123;&#125; #定义图片预处理函数 def process_pic(pic_name): print(&quot;开始预处理图片&quot;) #获得图片对象 img = im.open(pic_name) #获得图片的规格 img_color = [] img_width,img_height = img.size i = 1 for x in range(img_height): img_color_tmp = [] for y in range(img_width): #获得图片像素的rgb信息 r,g,b = img.getpixel((y,x))[:3] #将rgb信息转为10进制数字 img_color_tmp.append((r,g,b,r+g+b)) img_color.append(img_color_tmp) print(&quot;预处理图片结束&quot;) return img_color,img.size #随机基因的函数 def rand_genes(size): print(&quot;图片规格为:&#123;&#125;&quot;.format(size)) print(&quot;正在初始化随机基因&quot;) width,height = size genes = [] for i in range(100): gene = [] for x in range(height): row = [] for y in range(width): a = randint(0,255) b = randint(0,255) c = randint(0,255) row.append([a,b,c,a+b+c]) gene.append(row) genes.append([gene,0]) print(&quot;随机基因初始化完成&quot;) return genes #定义适应度计算函数 def forecast(genes): print(&quot;开始处理基因&quot;) sum_sum = 0 for i,gene in enumerate(genes): sum_ = 0 for j,row in enumerate(gene[0]): for k,col in enumerate(row): _a,_b,_c,_d = data[j][k] a,b,c,d = col det_d = abs(_d-d) sum_ += (abs(_a-a) + abs(_b-b) + abs(_c-c))*det_d genes[i][1] = sum_ sum_sum += sum_ for i,gene in enumerate(genes): genes[i][1] = genes[i][1]/sum_sum print(&quot;正在排序基因&quot;) genes.sort(key=lambda x:x[1]) print(&quot;基因处理完成&quot;) return #基因变异函数 def variation(genes,size): rate = 0.5 print(&quot;开始变异&quot;) for i,gene in enumerate(genes): for x,row in enumerate(gene[0]): for y,col in enumerate(row): if randint(1,100)/100 &lt;= rate: #图片由 r g b 三种颜色混合而成 变异就是改变他们的值 #a b c 分别对应 r_ g_ b_ 改变的值 可自行修改 #r g b 的最大值为255 #------------------------------请修改这里-------------------------------------# a = [-1,1][randint(0,1)]*randint(3,10) b = [-1,1][randint(0,1)]*randint(3,10) c = [-1,1][randint(0,1)]*randint(3,10) #------------------------------请修改这里-------------------------------------# genes[i][0][x][y][0] += a genes[i][0][x][y][0] += b genes[i][0][x][y][0] += c genes[i][0][x][y][3] += a+b+c print(&quot;变异结束&quot;) return def merge(gene1,gene2,size): width,height = size x = randint(0,height-1) y = randint(0,width-1) new_gene = deepcopy(gene1[0][:x]) new_gene = [new_gene,0] new_gene[0][x:] = deepcopy(gene2[0][x:]) new_gene[0][x][:y] = deepcopy(gene1[0][x][:y]) return new_gene #定义选择函数 def select(genes,size): print(&quot;这是选择环节 我们会选取种群中按适应度排名的前 三分之二&quot;) seek = int(len(genes)*2/3) i = 0 back_seek = seek+1 while i&#123;&#125;&quot;.format(genes[i][1])) genera += 1 #----------------------------------程序主体-----------------------------------# #---------------------------------程序数据保存模块------------------------------# #if not path.exists(&quot;quanju_v.tmp&quot;): def save_data(): global quanju_v print(&quot;文件存储中&quot;) with open(&quot;quanju_v.tmp&quot;,&quot;wb&quot;) as fd: pk.dump(quanju_v,fd) print(&quot;文件储存完成&quot;) #---------------------------------程序数据保存模块------------------------------# #main() try: main() except Exception, err: print &apos;main exception err:&apos;.format(str(err)) save_data()]]></content>
      <categories>
        <category>python</category>
      </categories>
      <tags>
        <tag>python</tag>
        <tag>算法</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[ubuntu14.04安装numpy笔记]]></title>
    <url>%2F2016%2F08%2F21%2F2016-08-21-ubuntu14-install-numpy%2F</url>
    <content type="text"><![CDATA[12345sudo apt-get install libtiff5-dev libjpeg8-dev zlib1g-dev libfreetype6-dev liblcms2-dev libwebp-dev tcl8.6-dev tk8.6-dev python-tksudo apt-get install zip unzipsudo apt-get install python-numpysudo apt-get install python-scipy]]></content>
      <categories>
        <category>其它</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[win8下GPT分区安装win7系统]]></title>
    <url>%2F2016%2F08%2F21%2F2016-08-21-win8-GPT-install-win7%2F</url>
    <content type="text"><![CDATA[朋友的笔记本win8升级win10以后比较卡想重装系统，咨询我怎么装，今天让他把本拿到了我家，目前win10激活工具比较难找，so建议朋友装win7，于是找了win7专业版的镜像用UltralSO做U盘启动，记录一下遇到的几个问题：1.不能进入bios修改开机启动：用了F12,F2和Del键都进不了bios，朋友电脑是联想G50，网上查了一下原来是电源键旁边有个按钮，关机状态按该按钮顺利进入bios；2.在win7安装界面提示：无法加载CD/DVD驱动程序：这个问题最坑了，启动U盘插在了usb3.0的口，然而win7安装过程貌似不支持usb3.0, 换了一个usb2.0的口就解决了。3.选择系统安装位置的时候提示win7不能安装在GPT分区上：那就需要把硬盘的分区表格式转换成MBR，可以用分区工具，或者在win7安装界面按shift + F10(+Fn)，然后，输入： 123456789diskpart.exe #启动diskpart程序list disk #列出磁盘sel disk 0 #选择相应磁盘 (根据上面提示，如果你的硬盘是disk 0的话)clean #（这个命令会清除硬盘里面的所有资料，请注意）conver mbr #转换为mbr分区Create Partition Primary Size=512000 #创建主分区，容量为：512000MBActive #激活主分区Format Quick #快速格式化当前分区Create Partition Extended：#创建扩展分区(用所有剩余空间创建扩展分区)]]></content>
      <categories>
        <category>windows</category>
      </categories>
      <tags>
        <tag>系统</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Python使用UUID库生成唯一ID]]></title>
    <url>%2F2016%2F08%2F19%2F2016-08-19-python-uuid-gen-id%2F</url>
    <content type="text"><![CDATA[资料： [Python官方Doc：《20.15. uuid — UUID objects according to RFC 4122》](http://docs.python.org/library/uuid.html) [UUID的算法介绍：《A Universally Unique IDentifier (UUID) URN Namespace》](http://www.ietf.org/rfc/rfc4122.txt) 概述： [UUID](http://en.wikipedia.org/wiki/Universally_unique_identifier)是128位的全局唯一标识符，通常由32字节的字符串表示。 它可以保证时间和空间的唯一性，也称为GUID，全称为： UUID —— [Universally Unique IDentifier](http://en.wikipedia.org/wiki/Universally_unique_identifier) Python 中叫 UUID GUID —— Globally Unique IDentifier C# 中叫 GUID 它通过MAC地址、时间戳、命名空间、随机数、伪随机数来保证生成ID的唯一性。 UUID主要有五个算法，也就是五种方法来实现： 1、uuid1()——基于时间戳 由MAC地址、当前时间戳、随机数生成。可以保证全球范围内的唯一性， 但MAC的使用同时带来安全性问题，局域网中可以使用IP来代替MAC。 2、uuid2()——基于分布式计算环境DCE（Python中没有这个函数） 算法与uuid1相同，不同的是把时间戳的前4位置换为POSIX的UID。 实际中很少用到该方法。 3、uuid3()——基于名字的MD5散列值 通过计算名字和命名空间的MD5散列值得到，保证了同一命名空间中不同名字的唯一性， 和不同命名空间的唯一性，但同一命名空间的同一名字生成相同的uuid。 4、uuid4()——基于随机数 由伪随机数得到，有一定的重复概率，该概率可以计算出来。 5、uuid5()——基于名字的SHA-1散列值 算法与uuid3相同，不同的是使用 Secure Hash Algorithm 1 算法 使用方面： 首先，Python中没有基于DCE的，所以uuid2可以忽略； 其次，uuid4存在概率性重复，由无映射性，最好不用； 再次，若在Global的分布式计算环境下，最好用uuid1； 最后，若有名字的唯一性要求，最好用uuid3或uuid5。 编码方法： 123456789# -*- coding: utf-8 -*-import uuidname = &quot;test_name&quot;namespace = &quot;test_namespace&quot;print uuid.uuid1() # 带参的方法参见Python Docprint uuid.uuid3(namespace, name)print uuid.uuid4()print uuid.uuid5(namespace, name)]]></content>
      <categories>
        <category>python</category>
      </categories>
      <tags>
        <tag>python</tag>
        <tag>uuid</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[linux下iptables小结]]></title>
    <url>%2F2016%2F08%2F19%2F2016-08-19-linux-iptables%2F</url>
    <content type="text"><![CDATA[iptables作用 过滤请求，根据条件决定通过或拒绝 网络地址转换 修改头信息 iptables的组成部分 table：根据类型分了3种，分别是filter,nat,mangle。filter用来过滤，nat用来地址转换，mangle用来改ttl之类的头信息【不常用】。 chain：是指网络包处理的某个阶段，看下图：1.yes这条路线目的地址是本机。2.no这条路线目的地址是其他网段，需要转发。 rule：用来判断哪些包需要处理，例如-p指定协议，-s指定源地址，-d指定目的地址，-i和-o定义输入输出的设备 target：其实用target这个词很不好理解，我的理解是符合规则后的操作 iptables命令的语法12345$ sudo iptables [table] [chain] [rule] [target]# table用-t表示，例如-t nat，-t fileter。如果不加-t 默认就是filter# chain前面需要加一个动词，例如-A INPUT意思是&quot;添加 input链&quot;，例如-I POSTROUTING 2意思是&quot;插入 postrouting 到第二条记录&quot;# rule上面已经解释过了# target可以是ACCEPT，DROP，SNAT，MASQUERADE等，代表满足规则的话，就执行这种操作 记录一些例子，并解释123456# 清空nat表里的记录sudo iptables -F -t nat# 在filter表里增加一条都接收的记录 sudo iptables -t filter -A INPUT -j ACCEPT# 更改从eth1出去的源地址为114.77.99.212，一般用在共享单个ipsudo iptables -t nat -A POSTROUTING -o eth1 -j SNAT --to-source 114.77.99.212]]></content>
      <categories>
        <category>linux</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[用DFA算法来实现敏感词汇的过滤]]></title>
    <url>%2F2016%2F08%2F18%2F2016-08-18-DFA-filter-words%2F</url>
    <content type="text"><![CDATA[工作中遇到一个过滤敏感词汇的问题，网上找了一下主要解决方法有3种思路：【可行思路】1、暴力匹配–这个就算了，只是说说而已，实际应用中很少的。2、正则表达式，暂时没有用过3、利用DFA实现文字过滤，本文主要研究的就是DFA算法，在计算理论中，确定有限状态自动机或确定有限自动机（英语：deterministic finite automation, DFA）是一个能实现状态转移的自动机。对于一个给定的属于该自动机的状态和一个属于该自动机字母表的字符，它都能根据事先给定的转移函数转移到下一个状态（这个状态可以是先前那个状态）。以上是wiki上的介绍，通俗点来讲就是实现了一个链表，每个元素是一个字典，字典中存储的是敏感词的单位子串，子串也是一个链表元素内容也是一个字典，描述起来有点绕，还是图来的实在： python代码实现： 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859class Node(object): def __init__(self): self.children = None# The encode of word is UTF-8def add_word(root,word): node = root for i in range(len(word)): if node.children == None: node.children = &#123;&#125; node.children[word[i]] = Node() elif word[i] not in node.children: node.children[word[i]] = Node() node = node.children[word[i]]def init(path): root = Node() fp = open(path,&apos;r&apos;) for line in fp: line = line[0:-1] # print len(line) # print line # print type(line) add_word(root,line) fp.close() return root# The encode of word is UTF-8# The encode of message is UTF-8def is_contain(message, root): for i in range(len(message)): p = root j = i while (j&lt;len(message) and p.children!=None and message[j] in p.children): p = p.children[message[j]] j = j + 1 if p.children==None: #print &apos;---word---&apos;,message[i:j] return True return Falsedef dfa(): print &apos;----------------dfa-----------&apos; root = init(FILENAME) message = &apos;四处乱咬乱吠，吓得家中11岁的女儿躲在屋里不敢出来，直到辖区派出所民警赶到后，才将孩子从屋中救出。最后在征得主人同意后，民警和村民合力将这只发疯的狗打死&apos; #message = &apos;不顾&apos; print &apos;***message***&apos;,len(message) start_time = time.time() for i in range(10000): res = is_contain(message,root) #print res end_time = time.time() print (end_time - start_time) 14600个敏感词汇查询10000次，普通暴力和dfa对比测试结果： 12345678910----------------dfa-----------***message*** 2240.976715803146------------normal--------------***message*** 224The count of word: 1460030.5309519768Process finished with exit code 0]]></content>
      <categories>
        <category>技术</category>
      </categories>
      <tags>
        <tag>python</tag>
        <tag>算法</tag>
        <tag>DFA</tag>
        <tag>过滤敏感词</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[python中的collections模块学习]]></title>
    <url>%2F2016%2F08%2F17%2F2016-08-17-python-collections%2F</url>
    <content type="text"><![CDATA[Python在一些内置的数据类型，比如str, int, list, tuple, dict等，之后又提供了比较高级的额外的数据类型， 共有以下几种：`Counter1，`deque ，`defaultdict1，`namedtuple ，`OrderedDict12345678910111213141516171819那么接下来一个个的攻克它们。# 一.namedtuplenamedtuple的函数原型如下： `def namedtuple(typename, field_names, verbose=False, rename=False): “””Returns a new subclass of tuple with named fields. 12 作用就是通过将可迭代对象设置字段名，可使用名称来访问元素的数据对象。 比较重要参数释义： typename: 自定义名，字符串类型 field_names： 字段名，list类型 如下例子： 1234567891011121314151617181920212223`&gt;&gt;&gt; Point = namedtuple(&apos;Point&apos;, [&apos;x&apos;, &apos;y&apos;])&gt;&gt;&gt; Point.__doc__ # 新类的文档字符串&apos;Point(x, y)&apos;&gt;&gt;&gt; p = Point(11, y=22) # 通过位置参数或关键字参数实例化&gt;&gt;&gt; p[0] + p[1] # 像普通元组一样使用索引33&gt;&gt;&gt; x, y = p # 像普通元组一样解包(11, 22)&gt;&gt;&gt; p.x + p.y # 通过字段名访问33&gt;&gt;&gt; d = p._asdict() # 转换为字典&gt;&gt;&gt; d[&apos;x&apos;]11&gt;&gt;&gt; Point(**d) # 从字典转换过来Point(x=11, y=22)&gt;&gt;&gt; p._replace(x=100) # _replace() is like str.replace() but targets named fieldsPoint(x=100, y=22) 12345再举一个![:chestnut:](https://assets-cdn.github.com/images/icons/emoji/unicode/1f330.png)： `from collections import namedtuple tuples = [ (‘Bman’, 22, ‘Python’), (‘Jack’, 24, ‘C’),] p = namedtuple(“Code”, [‘name’, ‘age’, ‘language’])print p # print p._fields # (‘name’, ‘age’, ‘language’)print p.doc # Code(name, age, language) for i in tuples: _i = p._make(i) print i, _i, _i.name, _i.age, _i.language (‘Bman’, 22, ‘Python’) Code(name=’Bman’, age=22, language=’Python’) Bman 22 Python(‘Jack’, 24, ‘C’) Code(name=’Jack’, age=24, language=’C’) Jack 24 C12 二.dequedeque其实是 double-ended queue 的缩写，翻译过来就是双端队列，它最大的好处就是实现了从队列 头部快速增加和取出对象: `.popleft()1, `.appendleft() 。该类的原型如下： 1`deque([iterable[, maxlen]]) --&gt; deque object 12345678910111213该类有以下方法： * `append : 添加元素到右侧的双端队列 `appendleft1234: 添加元素到左侧的双端队列 * `clear : 移除所有元素 `count1234: D.count(value) -&gt; integer, 返回出现的值数 * `extend : 通过可迭代元素扩展右侧的双端队列 `extendleft1234: 与上相反 * `pop :删除并返回最右边的元素 `popleft1234:与上相反 * `remove :D.remove(value). 移除第一次出现的值 `reverse1234:取反 * `rotate : rotate是回转的意思，旋转双端队列n步向右（默认值n=1）。如果n是负的，向左旋转时 虽然原生的list也可以从头部添加和取出对象等方法： 12`lis.insert(0, v)lis.pop(0) 1234567891011但是与list不同的是**list对象的这两种用法的时间复杂度是 O(n) ，也就是说随着元素数量的增加耗时呈线性上升。而使用deque对象则是 O(1) 的复杂度，所以当你的代码有这样的需求的时候， 一定要记得使用deque。**我们可以创建一个空的deque对象： `d = deque() deque([])12 然后进行操作： 12345678910111213141516171819202122232425262728293031323334353637`d.append(1)d.append(&apos;2&apos;)print d, len(d) # deque([1, &apos;2&apos;]) 2print d[0] # 1d.appendleft(&apos;a&apos;)print d # deque([&apos;a&apos;, 1, &apos;2&apos;])print d.count(&apos;a&apos;) # 1d.extend([&apos;a&apos;, &apos;b&apos;, &apos;c&apos;])print d # deque([&apos;a&apos;, 1, &apos;2&apos;, &apos;a&apos;, &apos;b&apos;, &apos;c&apos;])d.extendleft([&apos;m&apos;, &apos;n&apos;])print d # deque([&apos;n&apos;, &apos;m&apos;, &apos;a&apos;, 1, &apos;2&apos;, &apos;a&apos;, &apos;b&apos;, &apos;c&apos;])print d.pop() # cprint d.popleft() # nprint d # deque([&apos;m&apos;, &apos;a&apos;, 1, &apos;2&apos;, &apos;a&apos;, &apos;b&apos;])d.remove(&apos;a&apos;)print d # deque([&apos;m&apos;, 1, &apos;2&apos;, &apos;a&apos;, &apos;b&apos;])d = deque(&apos;abcde&apos;)print dfor i in range(len(d)): d.rotate() print i, d# 输出：deque([&apos;a&apos;, &apos;b&apos;, &apos;c&apos;, &apos;d&apos;, &apos;e&apos;])0 deque([&apos;e&apos;, &apos;a&apos;, &apos;b&apos;, &apos;c&apos;, &apos;d&apos;])1 deque([&apos;d&apos;, &apos;e&apos;, &apos;a&apos;, &apos;b&apos;, &apos;c&apos;])2 deque([&apos;c&apos;, &apos;d&apos;, &apos;e&apos;, &apos;a&apos;, &apos;b&apos;])3 deque([&apos;b&apos;, &apos;c&apos;, &apos;d&apos;, &apos;e&apos;, &apos;a&apos;])4 deque([&apos;a&apos;, &apos;b&apos;, &apos;c&apos;, &apos;d&apos;, &apos;e&apos;]) 12345下面例子实现一个跑马灯效果： `import sysimport timefrom collections import deque loading = deque(‘&gt;——————–’) while True: print ‘\r%s’ % ‘’.join(loading), # 注意：”\r”表示回车（将光标移至本行开头）这里不能省略后面的逗号 loading.rotate() # 默认1 sys.stdout.flush() time.sleep(0.08) 12 注意： CR+LF (`\r\n1234); * LF (`\n ); CR (`\r12345678910111213).# 三.Counter实现计数功能 `&gt;&gt;&gt; c = Counter(‘abcdeabcdabcaba’) # count elements from a string c.most_common(3) # 出现最多的三个元素[(‘a’, 5), (‘b’, 4), (‘c’, 3)] sorted(c) # 列出所有唯一元素[‘a’, ‘b’, ‘c’, ‘d’, ‘e’] c.elements() # 迭代器 &lt;itertools.chain at 0x1094c0e50&gt; sorted(c.elements()) # 列出所有元素[‘a’, ‘a’, ‘a’, ‘a’, ‘a’, ‘b’, ‘b’, ‘b’, ‘b’, ‘c’, ‘c’, ‘c’, ‘d’, ‘d’, ‘e’] ‘’.join(sorted(c.elements()))‘aaaaabbbbcccdde’ sum(c.values()) # total of all counts15 c[‘a’] # 元素a出现次数5 for elem in ‘shazam’: # 通过可迭代对象更新counts… c[elem] += 1 # by adding 1 to each element’s countc[‘a’] # now there are seven ‘a’7 del c[‘b’] # remove all ‘b’c[‘b’] # now there are zero ‘b’0 d = Counter(‘simsalabim’) # make another counterc.update(d) # add in the second counterc[‘a’] # now there are nine ‘a’9 c.clear() # empty the countercCounter() Note: If a count is set to zero or reduced to zero, it will remainin the counter until the entry is deleted or the counter is cleared: c = Counter(‘aaabbc’)c[‘b’] -= 2 # reduce the count of ‘b’ by twoc.most_common() # ‘b’ is still in, but its count is zero[(‘a’, 3), (‘c’, 1), (‘b’, 0)] 12 四.OrderedDictOrderedDict相对于dict来说也就是有序字典。用法与dict类似，它有如下常用方法： `clear1234:od.clear() -&gt; None. Remove all items from od * `keys : 同dict `values1234: 同dict * `items : 同dict `iterkeys1234: 返回一个keys迭代器 * `itervalues :返回一个values迭代器 `iteritems1234: 返回一个(key, value)键值对迭代器 * `pop :od.pop(k[,d]) -&gt; v, 删除指定键和返回对应的值。如果无则触发KeyError异常 `setdefault1234567:od.setdefault(k[,d]) -&gt; od.get(k,d), also set od[k]=d if k not in od如下例子： `from collections import OrderedDict items = ( (‘A’, 1), (‘B’, 2), (‘C’, 3)) regular_dict = dict(items)ordered_dict = OrderedDict(items) 无序for k, v in regular_dict.items(): print k, v 有序for k, v in ordered_dict.items(): print k, v Result:Regular Dict:A 1C 3B 2Ordered Dict:A 1B 2C 3 12 五.defaultdictPython原生的数据结构dict的时候，如果用 `d[key]1这样的方式访问， 当指定的key不存在时，是会抛出KeyError异常的。如果使用defaultdict，只要你传入一个默认的工厂方法，那么请求一个不存在的key时， 便会调用这个工厂方法使用其结果来作为这个key的默认值。 `members = [ # Age, name [&apos;male&apos;, &apos;John&apos;], [&apos;male&apos;, &apos;Jack&apos;], [&apos;female&apos;, &apos;Lily&apos;], [&apos;male&apos;, &apos;Pony&apos;], [&apos;female&apos;, &apos;Lucy&apos;], ] result = defaultdict(list)print result # defaultdict(, {}) for sex, name in members: result[sex].append(name) # 将sex做key，value为list类型，append(name) print result # defaultdict(, {‘male’: [‘John’, ‘Jack’, ‘Pony’], ‘female’: [‘Lily’, ‘Lucy’]}) 12 defaultdict(list)的用法和dict.setdefault(key, [])比较类似，上述代码使用setdefault实现如下： 12345`result = &#123;&#125;for sex, name in members: result.setdefault(sex, []).append(name)print result ` 大部分内容看源码就弄明白了，同时也参考了不可不知的Python模块: collections]]></content>
      <categories>
        <category>技术</category>
      </categories>
      <tags>
        <tag>python</tag>
        <tag>collections</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[redis常用命令总结]]></title>
    <url>%2F2016%2F08%2F17%2F2016-08-17-redis-cmd%2F</url>
    <content type="text"><![CDATA[在平时的工作中，需要根据需求对Redis数据库进行一些操作。 可以参考Redis官网http://redis.io/commands 进行详细了解 1.SELECT 切换数据库 123456789plain 1redis 127.0.0.1:6379[1]&gt; HELP SELECTspaces 12plain 1SELECT indexspaces 12plain 1summary: Change the selected database for the current connectionspaces 12plain 1since: 1.0.0spaces 12plain 1group: connectionplain 1redis 127.0.0.1:6379[1]&gt; SELECT 2plain 1OK 2.LLEN 得到一个列表的长度 123456789plain 1redis 127.0.0.1:6379[2]&gt; HELP LLENspaces 12plain 1LLEN keyspaces 12plain 1summary: Get the length of a listspaces 12plain 1since: 1.0.0spaces 12plain 1group: listplain 1redis 127.0.0.1:6379[2]&gt; LLEN biplain 1(integer) 412 3.LRANGE 获取一个列表的所有元素 LRANGE 索引是以0开始的，0表示第一个元素，-1表示最后一个元素 12345678plain 1redis 127.0.0.1:6379[2]&gt; HELP LRANGEspaces 12plain 1LRANGE key start stopspaces 12plain 1summary: Get a range of elements from a listspaces 12plain 1since: 1.0.0spaces 12plain 1group: listplain 1redis 127.0.0.1:6379[2]&gt; LRANGE bi 0 5 4.LPUSH 将一个或多个值添加到一个列表的开头 12345678plain 1redis 127.0.0.1:6379[2]&gt; HELP LPUSHspaces 12plain 1LPUSH key value [value ...]spaces 12plain 1summary: Prepend one or multiple values to a listspaces 12plain 1since: 1.0.0spaces 12plain 1group: listplain 1redis 127.0.0.1:6379[2]&gt; LPUSH bi http://abc.com/logUserLogin?event_id=25&amp;uid=de721bcef5cba1fc182d18 5.RPUSH 将一个或多个值追加到一个列表的末尾 12345678plain 1redis 127.0.0.1:6379[2]&gt; HELP RPUSHspaces 12plain 1RPUSH key value [value ...]spaces 12plain 1summary: Append one or multiple values to a listspaces 12plain 1since: 1.0.0spaces 12plain 1group: listplain 1redis 127.0.0.1:6379[2]&gt; RPUSH bi http://abc.com/logUserLogin?event_id=25&amp;uid=de721bcef5cba1fc182d18 6.SAVE 同步数据到磁盘 SAVE命令执行的时候会阻塞连接，所以生成环境最好使用BGSAVE命令 12345678910plain 1redis 127.0.0.1:6379[2]&gt; HELP SAVEspaces 12plain 1SAVE -spaces 12plain 1summary: Synchronously save the dataset to diskspaces 12plain 1since: 1.0.0spaces 12plain 1group: serverplain 1redis 127.0.0.1:6379[2]&gt; SAVEplain 1OKplain 1(1.33s) 7.BGSAVE 异步数据到磁盘 使用BGSAVE,Redis将会在后台执行保存数据的操作，不影响正常的客户端连接，Redis将会fork出一个子进程用于保存数据，父进程继续处理客户端请求。 123456789plain 1redis 127.0.0.1:6379[2]&gt; HELP BGSAVEspaces 12plain 1BGSAVE -spaces 12plain 1summary: Asynchronously save the dataset to diskspaces 12plain 1since: 1.0.0spaces 12plain 1group: serverplain 1redis 127.0.0.1:6379[2]&gt; BGSAVEplain 1Background saving started 8.TYPE 判断一个KEY的类型 123456789plain 1redis 127.0.0.1:6379[2]&gt; HELP TYPEspaces 12plain 1TYPE keyspaces 12plain 1summary: Determine the type stored at keyspaces 12plain 1since: 1.0.0spaces 12plain 1group: genericplain 1redis 127.0.0.1:6379[2]&gt; TYPE biplain 1list 9.BGREWRITEAOF 异步重写AOF文件，Redis将会创建一个对当前AOF文件优化过的AOF版本。 123456plain 1redis 127.0.0.1:6379&gt; help BGREWRITEAOFspaces 12plain 1BGREWRITEAOF -spaces 12plain 1summary: Asynchronously rewrite the append-only filespaces 12plain 1since: 1.0.0spaces 12plain 1group: server 10.CONFIG GET 获取某个配置项的值 12345678910plain 1redis 127.0.0.1:6379&gt; help config getspaces 12plain 1CONFIG GET parameterspaces 12plain 1summary: Get the value of a configuration parameterspaces 12plain 1since: 2.0.0spaces 12plain 1group: serverplain 1redis 127.0.0.1:6379&gt; config get maxmemoryplain 11) &quot;maxmemory&quot;plain 12) &quot;0&quot; 11.CONFIG SET 设置某个参数的值 123456789plain 1redis 127.0.0.1:6379&gt; help config setspaces 12plain 1CONFIG SET parameter valuespaces 12plain 1summary: Set a configuration parameter to the given valuespaces 12plain 1since: 2.0.0spaces 12plain 1group: serverplain 1redis 127.0.0.1:6379&gt; config set maxmemory 200000000plain 1OK 12.DBSIZE 返回当前数据库的KEY值得数量 123456789plain 1redis 127.0.0.1:6379[3]&gt; HELP DBSIZEspaces 12plain 1DBSIZE -spaces 12plain 1summary: Return the number of keys in the selected databasespaces 12plain 1since: 1.0.0spaces 12plain 1group: serverplain 1redis 127.0.0.1:6379[3]&gt; dbsizeplain 1(integer) 12502 13.DEL 删除一个KEY值 123456789plain 1redis 127.0.0.1:6379&gt; help delspaces 12plain 1DEL key [key ...]spaces 12plain 1summary: Delete a keyspaces 12plain 1since: 1.0.0spaces 12plain 1group: genericplain 1redis 127.0.0.1:6379&gt; del fooplain 1(integer) 1 14.EXISTS 检查一个KEY是否存在 123456789plain 1redis 127.0.0.1:6379&gt; help existsspaces 12plain 1EXISTS keyspaces 12plain 1summary: Determine if a key existsspaces 12plain 1since: 1.0.0spaces 12plain 1group: genericplain 1redis 127.0.0.1:6379&gt; exists fooplain 1(integer) 1 15.SET 命令 设置一个KEY的值 12345678910plain 1redis 127.0.0.1:6379&gt; help setspaces 12plain 1SET key valuespaces 12plain 1summary: Set the string value of a keyspaces 12plain 1since: 1.0.0spaces 12plain 1group: stringplain 1redis 127.0.0.1:6379&gt; set foo testplain 1OKplain 1redis 127.0.0.1:6379&gt; 16.PERSIST 删除一个KEY的过期时间 123456plain 1edis 127.0.0.1:6379&gt; help persistspaces 12plain 1PERSIST keyspaces 12plain 1summary: Remove the expiration from a keyspaces 12plain 1since: 2.2.0spaces 12plain 1group: generic 17.RENAME 重新命名一个KEY 12345678910plain 1redis 127.0.0.1:6379&gt; help renamespaces 12plain 1RENAME key newkeyspaces 12plain 1summary: Rename a keyspaces 12plain 1since: 1.0.0spaces 12plain 1group: genericplain 1redis 127.0.0.1:6379&gt; rename foo footestplain 1OKplain 1redis 127.0.0.1:6379&gt; 18.EXPIRE 为一个KEY设置一个TTL过期时间 123456789plain 1redis 127.0.0.1:6379&gt; help expirespaces 12plain 1EXPIRE key secondsspaces 12plain 1summary: Set a key&apos;s time to live in secondsspaces 12plain 1since: 1.0.0spaces 12plain 1group: genericplain 1redis 127.0.0.1:6379&gt; expire footest 300plain 1(integer) 1 19.TTL 获取过期时间 123456789101112131415161718plain 1redis 127.0.0.1:6379&gt; help ttlspaces 12plain 1TTL keyspaces 12plain 1summary: Get the time to live for a keyspaces 12plain 1since: 1.0.0spaces 12plain 1group: genericplain 1redis 127.0.0.1:6379&gt; ttl footestplain 1(integer) 289plain 1redis 127.0.0.1:6379&gt; ttl footestplain 1(integer) 285plain 1redis 127.0.0.1:6379&gt; ttl footestplain 1(integer) 283plain 1redis 127.0.0.1:6379&gt; ttl footestplain 1(integer) 282plain 1redis 127.0.0.1:6379&gt; ttl footestplain 1(integer) 282plain 1redis 127.0.0.1:6379&gt; 20.EXPIREAT 设置一个KEY的过期时间，以UNIX时间戳表示 1234567891011plain 1redis 127.0.0.1:6379&gt; help expireatspaces 12plain 1EXPIREAT key timestampspaces 12plain 1summary: Set the expiration for a key as a UNIX timestampspaces 12plain 1since: 1.2.0spaces 12plain 1group: genericplain 1redis 127.0.0.1:6379&gt; expireat foo 1431532800plain 1(integer) 1plain 1redis 127.0.0.1:6379&gt; ttl fooplain 1(integer) 3210141 21.GET 获取一个KEY的值 123456789plain 1redis 127.0.0.1:6379&gt; help getspaces 12plain 1GET keyspaces 12plain 1summary: Get the value of a keyspaces 12plain 1since: 1.0.0spaces 12plain 1group: stringplain 1redis 127.0.0.1:6379&gt; get fooplain 1&quot;test&quot; 22.HGET 获取一个哈希字段的值 1234567891011121314plain 1redis 127.0.0.1:6379&gt; help hgetspaces 12plain 1HGET key fieldspaces 12plain 1summary: Get the value of a hash fieldspaces 12plain 1since: 2.0.0spaces 12plain 1group: hashplain 1redis 127.0.0.1:6379&gt; hset myhash field1 &quot;foo&quot;plain 1(integer) 1plain 1redis 127.0.0.1:6379&gt; hget myhash field1plain 1&quot;foo&quot;plain 1redis 127.0.0.1:6379&gt; hget myhash field2plain 1(nil)plain 1redis 127.0.0.1:6379&gt; 23.LASTSAVE 上次成功保存数据到磁盘的UNIX时间戳 12345678910plain 1redis 127.0.0.1:6379&gt; help lastsavespaces 12plain 1LASTSAVE -spaces 12plain 1summary: Get the UNIX time stamp of the last successful save to diskspaces 12plain 1since: 1.0.0spaces 12plain 1group: serverplain 1redis 127.0.0.1:6379&gt; lastsaveplain 1(integer) 1428373205plain 1redis 127.0.0.1:6379&gt; 24.LPUSH 将一个或多个值附加到一个Redis列表中 1234567891011121314151617181920plain 1redis 127.0.0.1:6379&gt; help lpushspaces 12plain 1LPUSH key value [value ...]spaces 12plain 1summary: Prepend one or multiple values to a listspaces 12plain 1since: 1.0.0spaces 12plain 1group: listspaces 12spaces 12spaces 12plain 1redis 127.0.0.1:6379&gt; lpush mylist a b cplain 1(integer) 6plain 1redis 127.0.0.1:6379&gt; LRANGE mylist 0 -1plain 11) &quot;c&quot;plain 12) &quot;b&quot;plain 13) &quot;a&quot;plain 14) &quot;c&quot;plain 15) &quot;b&quot;plain 16) &quot;a&quot;plain 1redis 127.0.0.1:6379&gt; llen mylistplain 1(integer) 6]]></content>
      <categories>
        <category>技术</category>
      </categories>
      <tags>
        <tag>数据库</tag>
        <tag>redis</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[利用Type Hint提升Python程序开发效率]]></title>
    <url>%2F2016%2F08%2F16%2F2016-08-16-use-type-hint-in-python%2F</url>
    <content type="text"><![CDATA[Type Hint（或者叫做PEP-484）提供了一种针对Python程序的类型标注标准。 为什么使用Type Hint？对于动态语言而言，常常出现的情况是当你写了一段代码后，隔段时间你可能忘记这个方法的原型是什么样子的了，你也不清楚具体应该传入什么类型的参数，这样往往需要你去阅读代码才能定义每个类型具体是什么。或者当你使用一个文档并不是特别完全的第三方库，你不知道这个库应该如何使用，这都会很痛苦。 现在，借助Type Hint，你可以实现： 实现类型检查，防止运行时出现的类型不符合情况。 作为文档附加属性，方便开发者调用时传入传出的参数类型。 提升IDE的检查机制，在智能提示时更快给出提示和类型检查结果。 实现这个过程中，你需要使用`Python 3.5+1中提供的新模块[`typing ](https://docs.python.org/3.5/library/typing.html)。值得注意的是，这个改动并不会影响程序运行，仅仅是为了方便类型检查器实现的。 Type Hint类型检查器目前，比如`JetBrains1家的`PyCharm 已经支持Type Hint语法检查功能，如果你使用了这个IDE，可以通过IDE功能进行实现。如果你像我一样，使用了SublimeText编辑器，那么第三方工具[`mypy1](https://github.com/python/mypy)可以帮助到你。`AnacondaST3 最近要发布的2.0版本也内置了`mypy1234567891011功能的支持，具体的进度可以看一下[这个issue](https://github.com/DamnWidget/anaconda/issues/439)。一些其它的Python工具(比如[代码提示工具jedi 0.10+](https://github.com/davidhalter/jedi/pull/661))也支持了Type Hint功能。 ## 从简单的例子开始 从简单的例子开始，我们先从一个简单的程序开始，运行环境为`Python 3.5.2 ，使用`mypy123456工具进行检查。 首先通过`pip install mypy-lang 命令安装`mypy1工具。注意是`mypy-lang ，之所以是这样，是因为在`pypi1里`mypy 这个名字已经被占用掉了。 接下来，通过`mypy1检查下面这个文件 hljs 12345678910111213# fib.pyfrom typing import Iteratordef fib(n: int) -&gt; Iterator[int]: a, b = 0, 1 while a &lt; n: yield a a, b = b, a + bi = fib(3.2)print(next(i))print(next(i)) 1234 在命令行中执行命令`mypy fib.py ，获取返回结果： 1234```language-python hljs ➜ mypy fib.pyfib.py:11: error: Argument 1 to &quot;fib&quot; has incompatible type &quot;float&quot;; expected &quot;int&quot; 1234 但是在实际的应用过程中，这个功能在Python里是可以正常运行的： hljs 123➜ mypy python fib.py01 123456789 可以看到，mypy工具提示了我们的代码中存在一处类型不匹配的问题，但是如果不进行检查，代码有可能执行出不可预知的结果。 在这个例子里面，我们使用了两种类型，一种是Python基础数据类型，比如`str 、`int1等等，这些类型数据是可以直接使用的；另外一种是来自于`typing 中引入的`Iterator1，用来表示迭代器类型。另外一个值得注意的是，`typing 中部分类型也会随时添加，一般我们以演示版本为准。 从简单到复杂，类型组合怎么办？实际上，在我们使用过程中还有可能传递一些更加复杂的参数类型，比如list类型，tuple类型等等，这类型的数据如何声明呢？我们可以先看一个例子： 123```language-python hljs def foo(strings, string_list, count, total): 1234 这个函数的参数我们从字面可以看出来分别是`str ，元素为`str1的`list 类型和两个整数参数。我们假定一个返回值为`((int, int), str)1，那么这个类型检查可以这样定义： hljs 12345from typing import List, TupleResult = Tuple[Tuple[int, int], str]def foo(strings: str, lines: List[str], line_number: int, total_lines: int) -&gt; Result: 1234 其它的一些类型提示、协程等等的支持都可以在官方的[`typing 模块文档](https://docs.python.org/3.5/library/typing.html)中进行查看。 关于生产的一些闲扯我们现在也在进行一些`mypy1工具在生产环境中的具体使用测试，但是我们也发现了一些存在的问题，比如`Python 本身的动态语言特性给类型标注就带来了一些麻烦。另外，变量复用导致的类型变换有可能会提示采用新的变量实现。这对于一个已经存在的线上项目来说相对成本较高，我们后续也会在一些新项目中采用这种方式。另外`mypy1还是一个比较新的项目，本身是拥有一些bug。另外一个是在某些`mypy 的非类型错误提示其实非常的模糊，导致很多错误有时需要进行人工排查。 不管怎样，即便在mypy ``存在一些缺陷，但是仍旧是未来非常有潜力的工具，提前了解和应用也能有效的提升程序的强壮性。 来自：https://ipfans.github.io/2016/07/type-hint-improve-python-programming/]]></content>
      <categories>
        <category>python</category>
      </categories>
      <tags>
        <tag>python</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[连接VMware Workstation子虚拟机到互联网？]]></title>
    <url>%2F2016%2F08%2F16%2F2016-08-16-link-vmware-workstation-in-vms%2F</url>
    <content type="text"><![CDATA[VMware Workstation是桌面或笔记本上的用于独立实验测试环境的理想桌面应用。使用Workstation，你可以创建多个专用网络，连接虚拟机到主机，桥接网络到局域网（LAN）或使用Network Address Translation协议（NAT）连接网络到LAN。 其实，VMware Workstation的虚拟网络配置能力正是Workstation的魅力所在。但同时，虚拟网络灵活性又使其在配置时很困难。因此，在Workstation里创建新虚拟机不难，配置虚拟网络才是难题所在。在本文中，TechTarget中国的特约虚拟化专家David Davis将描述VMware Workstation实验网络的几种情景，并解决一些常见问题：如何将虚拟子机连接到网络？ VMware Workstation的虚拟网络编辑器 使Workstation的虚拟网络配置简单又复杂的一个功能是Virtual Network Editor。这个工具允许你配置每个不同类型的Workstation网络，与动态主机配置协议（DHCP）和NAT Workstation服务一起工作。我们将使用这个工具连接虚拟子机到互联网，并创建不同的实验场景。你可以利用Vrtual Network Editor做许多事。我就不用详细描述如何使用这个工具了，你可以参考我以前的文章“使用VMware Workstation和Virtual Network Editor管理虚拟网络”。 下面我们看看使用VMware Workstation搭建的四个不同的虚拟网络场景。 场景一、使用桥接功能连接虚拟机到互联网 我经常被问及关于VMware Workstation的一个问题是如何连接子虚拟机到互联网。基于你的网络和互联网配置，连接虚拟机到Web的方法可能基于你的网络配置而更改。因此我们假定你的LAN提供了DHPC服务器（使用默认网关或域名系统，或者DNS，没有MAC限制，你的防火墙允许任何计算机从LAN连接到互联网。） 在这种情况下，你不需要做任何事，如果你为虚拟网络适配器选择NAT或者桥接的链接，配置应该能够自动工作。我自己建议你使用Bridged Networking或VMnet0）。 在下图中，虚拟主机有一个IP地址（10.0.0.100），每台虚拟子机有自己的从DHCP服务器获得的IP地址（分别是10.0.0.101、102和103）。这样的话，每台虚拟子机作为网络上自己的IP节点运行。通常我喜欢这样的系统，因为每台虚拟子机都可以识别。我能使用Remote Desktop Protocol（RDP）连接每一台虚拟子机，或者链接到虚拟子机的Web接口上（如果运行Web服务器）。 缺点是如果你的网络存在IP限制，那么每台子机必须在网络上单独配置。就是说你的防火墙只允许某一个设备与互联网通信。使用桥接，每台虚拟子机应该必须在防火墙上有自己的授权，因为它有自己的IP地址。也可能存在Windows网络限制。可能你的思科交换机存在MAC地址限制。如果这样，每一台虚拟子机有自己的MAC地址。由于许多MAC地址请求网络访问，虚拟主机的以太网端口可能在思科交换机上是锁着的。如果在交换机上配置有端口安全的MAC地址和限制的MAC地址，使用桥接就算供养一台虚拟子机，都很容易由于违背端口安全，导致主机PC或服务器从网络断开连接。 为了映射虚拟子机到某个虚拟网络，只需要配置虚拟网络接口卡到桥接“NATed”等。如下图： 场景二、使用NAT连接虚拟机到互联网 如我在第一个场景里所说的，可以使用NAT或VMnet8替换桥接。使用NAT，主机的IP地址供所有虚拟子机使用。换句话说，当虚拟子机与LAN通信时，就好像虚拟主机在发出请求。 不过子虚拟机如何获得它们的IP地址？因为每台虚拟机需要自己的IP地址。在Workstation里使用NAT的情况下，VMware Workstation实际有其自己的内部DHCP服务器，能发送内部的和专用的IP地址给任何位于NAT网络上的虚拟子机。 如果你去到VMware Workstation Virtual Network Editor里的NAT表，你能看见NAT服务。需要运行NAT服务翻译某个Workstation NAT网络——192.168.220.0到192.168.220.254——到虚拟主机的IP地址。如你在下一张图所看见的，NAT’ed虚拟机的默认网关是192.168.220.2。 NAT服务仍然没有发放IP地址，VMware Workstation DHCP Service发了。如果我们查看DHPC表格，能看见用于VMnet8的DHPC列。如下图： 因此使用NAT，每台虚拟机将有其自己的IP地址，是由VMware Workstation DHCP服务提供的。这个IP是NAT’ed到虚拟主机的IP，以便访问LAN（然后访问互联网）。 场景三、使用IP地址冲突、恶意软件或重复域名测试机器 如果你有一些虚拟机存在IP地址冲突、恶意软件或者与生产服务器DNS名称相冲突的DNS名称该怎么办？你想要这些服务器运行在安全的专用网络里，避免对生产网络产生任何威胁。使用VMware Workstation能做到。 默认下，VMware Workstation拥有一个叫做VMnet7的专用虚拟网络，如下图： 记住，你将在专有网络里的虚拟子机上配置一个静态IP地址，因为默认下，在这个子网上没有DHCP服务。如果想要DHCP，你应该在子网中配置Workstation以提供拥有Workstation DHCP服务的IP地址，或者运行Windows DHCP服务作为虚拟机。 场景四、测试需要访问主机（仅仅是主机）的安全虚拟机 最后，如果你想要虚拟子机不在本地LAN上，但又需要跨虚拟网络共享文件和访问虚拟机该怎么办？虽然没有专有网络（VMnet7）那么安全，仅仅访问主机的虚拟网络（VMnet1）可用。使用Host Only，在虚拟网络上的虚拟主机和虚拟子机能够通过它们共享的专有网络上的TCP/IP网络进行通信。 VMware Workstation使用192.168.234.0到192.168.234.254范围的默认IP地址，为专有网络提供DHCP服务，如下图所示： 要配置虚拟子机使用这个专有网络，连接它到Host Only Virtual network（VMnet1），如下图： 总之，VMware Workstation为配置虚拟网络提供了许多可能，如桥接、NAT’ed、专有和host-only。每一种都有其专门的用处。如果你只是想连接虚拟子机到本地LAN和互联网，根据网络的安全配置，我建议使用bridged或NAT’ed。 【编辑推荐】 企业如何应对虚拟化管理的挑战 实施服务器虚拟化前需要评估4个问题 2009年度思杰的虚拟化之路 【责任编辑：符甲 TEL：（010）68476606】 原文：如何连接VMware Workstation子虚拟机到互联网？ 返回虚拟化频道首页]]></content>
      <categories>
        <category>云计算</category>
      </categories>
      <tags>
        <tag>linux</tag>
        <tag>虚拟化</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Python中的几种设计模式]]></title>
    <url>%2F2016%2F08%2F11%2F2016-08-11-python-design-patterns%2F</url>
    <content type="text"><![CDATA[1.单例模式：法一：通过类的new()方法，但是个人感觉没有装饰器方便 12345678910111213141516171819202122class Singleton(object): __instance = None def __init__(self): pass def __new__(cls, *args, **kwd): if Singleton.__instance is None: Singleton.__instance = object.__new__(cls, *args, **kwd) return Singleton.__instanceclass MyClass(Singleton): aa = 88instance1 = MyClass()instance2 = MyClass()print id(instance1)print id(instance2)139984856635600139984856635600 法二：用装饰器来实现 123456789101112131415161718def singleton(cls, *args, **kw): instances = &#123;&#125; def _singleton(): if cls not in instances: instances[cls] = cls(*args, **kw) return instances[cls] return _singleton@singletonclass MyClass1(object): aa = 56instance1 = MyClass1()instance2 = MyClass1()print id(instance1)#139764123790288print id(instance2)#139764123790288]]></content>
      <categories>
        <category>技术</category>
      </categories>
      <tags>
        <tag>python</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[python中密码的保存和token的生成验证itsdangerous模块]]></title>
    <url>%2F2016%2F08%2F09%2F2016-08-09-itsdangerous%2F</url>
    <content type="text"><![CDATA[密码的保存： 123import hashlibhashlib.sha1(config.SECRET_KEY+password).hexdigest() token的生成和保存： 12345678910111213141516171819202122232425262728293031from itsdangerous import TimedJSONWebSignatureSerializer as Serializer, BadSignature, SignatureExpiredclass QXToken(object):&quot;&quot;&quot;生成/验证 用户token&quot;&quot;&quot; def __init__(self, name): self.name = name def generate_auth_token(self, expiration=3600): s = Serializer(config.SECRET_KEY, expires_in=expiration) return s.dumps(&#123;&apos;name&apos;: self.name&#125;) def verify_auth_token(self, token): s = Serializer(config.SECRET_KEY) try: data = s.loads(token) print &apos;data:&apos;, data except SignatureExpired: return 0 # valid token, but expired except BadSignature: return -1 # invalid token return data[&apos;name&apos;] == self.name#生成tokenqxtoken = QXToken(&apos;name&apos;)token = qxtoken.generate_auth_token()#验证tokenq = QXToken(&apos;name&apos;)res = q.verify_auth_token()]]></content>
      <categories>
        <category>python</category>
      </categories>
      <tags>
        <tag>python</tag>
        <tag>itsdangerous</tag>
        <tag>token</tag>
        <tag>数字</tag>
        <tag>签名</tag>
        <tag>过期</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[GeoHash核心原理解析]]></title>
    <url>%2F2016%2F08%2F09%2F2016-08-09-geohash%2F</url>
    <content type="text"><![CDATA[机机是个好动又好学的孩子，平日里就喜欢拿着手机地图点点按按来查询一些好玩的东西。某一天机机到北海公园游玩，肚肚饿了，于是乎打开手机地图，搜索北海公园附近的餐馆，并选了其中一家用餐。 饭饱之后机机开始反思了，地图后台如何根据自己所在位置查询来查询附近餐馆的呢？苦思冥想了半天，机机想出了个方法：计算所在位置P与北京所有餐馆的距离，然后返回距离&lt;=1000米的餐馆。小得意了一会儿，机机发现北京的餐馆何其多啊，这样计算不得了，于是想了，既然知道经纬度了，那它应该知道自己在西城区，那应该计算所在位置P与西城区所有餐馆的距离啊，机机运用了递归的思想，想到了西城区也很多餐馆啊，应该计算所在位置P与所在街道所有餐馆的距离，这样计算量又小了，效率也提升了。 机机的计算思想很朴素，就是通过过滤的方法来减小参与计算的餐馆数目，从某种角度上讲，机机在使用索引技术。 一提到索引，大家脑子里马上浮现出B树索引，因为大量的数据库（如MySQL、oracle、PostgreSQL等）都在使用B树。B树索引本质上是对索引字段进行排序，然后通过类似二分查找的方法进行快速查找，即它要求索引的字段是可排序的，一般而言，可排序的是一维字段，比如时间、年龄、薪水等等。但是对于空间上的一个点（二维，包括经度和纬度），如何排序呢？又如何索引呢？解决的方法很多，下文介绍一种方法来解决这一问题。 思想：如果能通过某种方法将二维的点数据转换成一维的数据，那样不就可以继续使用B树索引了嘛。那这种方法真的存在嘛，答案是肯定的。目前很火的GeoHash算法就是运用了上述思想，下面我们就开始GeoHash之旅吧。 一、感性认识GeoHash 首先来点感性认识，http://openlocation.org/geohash/geohash-js/ 提供了在地图上显示geohash编码的功能。 1）GeoHash将二维的经纬度转换成字符串，比如下图展示了北京9个区域的GeoHash字符串，分别是WX4ER，WX4G2、WX4G3等等，每一个字符串代表了某一矩形区域。也就是说，这个矩形区域内所有的点（经纬度坐标）都共享相同的GeoHash字符串，这样既可以保护隐私（只表示大概区域位置而不是具体的点），又比较容易做缓存，比如左上角这个区域内的用户不断发送位置信息请求餐馆数据，由于这些用户的GeoHash字符串都是WX4ER，所以可以把WX4ER当作key，把该区域的餐馆信息当作value来进行缓存，而如果不使用GeoHash的话，由于区域内的用户传来的经纬度是各不相同的，很难做缓存。 2）字符串越长，表示的范围越精确。如图所示，5位的编码能表示10平方千米范围的矩形区域，而6位编码能表示更精细的区域（约0.34平方千米） 3）字符串相似的表示距离相近（特殊情况后文阐述），这样可以利用字符串的前缀匹配来查询附近的POI信息。如下两个图所示，一个在城区，一个在郊区，城区的GeoHash字符串之间比较相似，郊区的字符串之间也比较相似，而城区和郊区的GeoHash字符串相似程度要低些。 城区 郊区 通过上面的介绍我们知道了GeoHash就是一种将经纬度转换成字符串的方法，并且使得在大部分情况下，字符串前缀匹配越多的距离越近，回到我们的案例，根据所在位置查询来查询附近餐馆时，只需要将所在位置经纬度转换成GeoHash字符串，并与各个餐馆的GeoHash字符串进行前缀匹配，匹配越多的距离越近。 二、GeoHash算法的步骤 下面以北海公园为例介绍GeoHash算法的计算步骤 2.1. 根据经纬度计算GeoHash二进制编码 地球纬度区间是[-90,90]， 北海公园的纬度是39.928167，可以通过下面算法对纬度39.928167进行逼近编码: 1）区间[-90,90]进行二分为[-90,0),[0,90]，称为左右区间，可以确定39.928167属于右区间[0,90]，给标记为1； 2）接着将区间[0,90]进行二分为 [0,45),[45,90]，可以确定39.928167属于左区间 [0,45)，给标记为0； 3）递归上述过程39.928167总是属于某个区间[a,b]。随着每次迭代区间[a,b]总在缩小，并越来越逼近39.928167； 4）如果给定的纬度x（39.928167）属于左区间，则记录0，如果属于右区间则记录1，这样随着算法的进行会产生一个序列1011100，序列的长度跟给定的区间划分次数有关。 根据纬度算编码 bitminmidmax1-90.0000.00090.00000.00045.00090.00010.00022.50045.000122.50033.75045.000133.750039.37545.000039.37542.18845.000039.37540.781542.188039.37540.0782540.7815139.37539.72662540.07825139.72662539.902437540.07825 同理，地球经度区间是[-180,180]，可以对经度116.389550进行编码。 根据经度算编码 bitminmidmax1-1800.00018010.00090180090135180190112.51350112.5123.751350112.5118.125123.751112.5115.3125118.1250115.3125116.71875118.1251115.3125116.015625116.718751116.015625116.3671875116.71875 2.2. 组码 通过上述计算，纬度产生的编码为10111 00011，经度产生的编码为11010 01011。偶数位放经度，奇数位放纬度，把2串编码组合生成新串：11100 11101 00100 01111。 最后使用用0-9、b-z（去掉a, i, l, o）这32个字母进行base32编码，首先将11100 11101 00100 01111转成十进制，对应着28、29、4、15，十进制对应的编码就是wx4g。同理，将编码转换成经纬度的解码算法与之相反，具体不再赘述。 三、GeoHash Base32编码长度与精度 下表摘自维基百科：http://en.wikipedia.org/wiki/Geohash 可以看出，当geohash base32编码长度为8时，精度在19米左右，而当编码长度为9时，精度在2米左右，编码长度需要根据数据情况进行选择。 三、GeoHash算法 上文讲了GeoHash的计算步骤，仅仅说明是什么而没有说明为什么？为什么分别给经度和维度编码？为什么需要将经纬度两串编码交叉组合成一串编码？本节试图回答这一问题。 如图所示，我们将二进制编码的结果填写到空间中，当将空间划分为四块时候，编码的顺序分别是左下角00，左上角01，右下脚10，右上角11，也就是类似于Z的曲线，当我们递归的将各个块分解成更小的子块时，编码的顺序是自相似的（分形），每一个子快也形成Z曲线，这种类型的曲线被称为Peano空间填充曲线。 这种类型的空间填充曲线的优点是将二维空间转换成一维曲线（事实上是分形维），对大部分而言，编码相似的距离也相近， 但Peano空间填充曲线最大的缺点就是突变性，有些编码相邻但距离却相差很远，比如0111与1000，编码是相邻的，但距离相差很大。 除Peano空间填充曲线外，还有很多空间填充曲线，如图所示，其中效果公认较好是Hilbert空间填充曲线，相较于Peano曲线而言，Hilbert曲线没有较大的突变。为什么GeoHash不选择Hilbert空间填充曲线呢？可能是Peano曲线思路以及计算上比较简单吧，事实上，Peano曲线就是一种四叉树线性编码方式。 四、使用注意点 1）由于GeoHash是将区域划分为一个个规则矩形，并对每个矩形进行编码，这样在查询附近POI信息时会导致以下问题，比如红色的点是我们的位置，绿色的两个点分别是附近的两个餐馆，但是在查询的时候会发现距离较远餐馆的GeoHash编码与我们一样（因为在同一个GeoHash区域块上），而较近餐馆的GeoHash编码与我们不一致。这个问题往往产生在边界处。 解决的思路很简单，我们查询时，除了使用定位点的GeoHash编码进行匹配外，还使用周围8个区域的GeoHash编码，这样可以避免这个问题。 2）我们已经知道现有的GeoHash算法使用的是Peano空间填充曲线，这种曲线会产生突变，造成了编码虽然相似但距离可能相差很大的问题，因此在查询附近餐馆时候，首先筛选GeoHash编码相似的POI点，然后进行实际距离计算。 geohash只是空间索引的一种方式，特别适合点数据，而对线、面数据采用R树索引更有优势 转载自：http://www.cnblogs.com/LBSer/p/3310455.html]]></content>
      <categories>
        <category>技术</category>
      </categories>
      <tags>
        <tag>算法</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[查找附近的人功能实现]]></title>
    <url>%2F2016%2F08%2F09%2F2016-08-09-find-somebody-in-map%2F</url>
    <content type="text"><![CDATA[查找附近的人是移动开发非常流行的功能，最近在给移动端写后台接口，上午查了很多资料发现用geohash算法的人居多，本来想自己设计数据库来实现以下geohash的，但是项目赶得紧，正好发现新版的redis支持geo的地理位置的操作： 安装最新版的redis3.2.3+2.redis的geo模块支持的操作有： 添加位置和获取位置为了进行地理位置相关操作， 我们首先需要将具体的地理位置记录起来， 这一点可以通过执行 GEOADD 命令来完成， 该命令的基本格式如下： 12GEOADD location-set longitude latitude name [longitude latitude name ...] GEOADD 命令每次可以添加一个或多个经纬度地理位置。 其中 location-set 为储存地理位置的集合， 而 longitude 、 latitude 和 name 则分别为地理位置的经度、纬度、名字。 举个例子， 以下代码展示了如何通过 GEOADD 命令， 将清远、广州、佛山、东莞、深圳等数个广东省的市添加到位置集合 Guangdong-cities 里面： 12redis&gt; GEOADD Guangdong-cities 113.2099647 23.593675 Qingyuan 1 – 成功添加一个位置 12redis&gt; GEOADD Guangdong-cities 113.2278442 23.1255978 Guangzhou 113.106308 23.0088312 Foshan 113.7943267 22.9761989 Dongguan 114.0538788 22.5551603 Shenzhen 4 – 成功添加四个位置在将位置记录到位置集合之后， 我们可以使用 GEOPOS 命令， 输入位置的名字并取得位置的具体经纬度： 12GEOPOS location-set name [name ...] 比如说， 如果我们想要获取清远、广州和佛山的经纬度， 那么可以执行以下代码： 12345678redis&gt; GEOPOS Guangdong-cities Qingyuan Guangzhou Foshan1) 1) &quot;113.20996731519699&quot; -- 清远的经度2) &quot;23.593675019671288&quot; -- 清远的纬度2) 1) &quot;113.22784155607224&quot; -- 广州的经度2) &quot;23.125598202060807&quot; -- 广州的纬度3) 1) &quot;113.10631066560745&quot; -- 佛山的经度2) &quot;23.008831202413539&quot; -- 佛山的纬度 计算两个位置之间的距离在拥有了地理数据之后， 我们就可以基于这些数据进行各种各样的操作。 针对地理位置信息的其中一个最简单的操作， 就是计算两个位置之间的距离。 在 Redis 里面， 计算两个位置之间的距离可以通过 GEODIST 命令来实现： 12GEODIST location-set location-x location-y [unit] 在调用这个命令时， 用户需要给定想要计算差距的地点 location-x 和 location-y ， 以及储存这两个地点的地理位置集合。 可选参数 unit 用于指定计算距离时的单位， 它的值可以是以下单位的其中一个： m 表示单位为米。km 表示单位为千米。mi 表示单位为英里。ft 表示单位为英尺。如果用户没有指定 unit 参数， 那么 GEODIST 默认使用米为单位。 作为例子， 以下代码展示了如何计算清远和广州之间的距离： 12redis&gt; GEODIST Guangdong-cities Qingyuan Guangzhou “52094.433840356309” – 两地相距 52094 米上面的计算结果使用了米来表示清远和广州两地的距离， 不过在表示比较长的距离时， 我们更习惯采用公里（km）作为单位。 通过显式地给定 km （千米）作为单位， 我们可以让 GEODIST 显示两个地点之间相距的公里数： 12redis&gt; GEODIST Guangdong-cities Qingyuan Guangzhou km “52.094433840356309” – 两地相距 52 公里获取指定范围内的元素除了计算两地的距离之外， 另一个常见的地理位置操作就是找出特定范围之内的其他存在的地点。 比如找出地点 x 范围 100 米之内的所有地点， 找出地点 y 范围 50 公里之内的所有地点等等。 Redis 提供了 GEORADIUS 和 GEORADIUSBYMEMBER 两个命令来实现查找特定范围内地点的功能， 它们的作用一样， 只是指定中心点的方式不同： GEORADIUS 使用用户给定的经纬度作为计算范围时的中心点， 而 GEORADIUSBYMEMBER 则使用储存在位置集合里面的某个地点作为中心点。 以下是这两个命令的基本格式： 1234GEORADIUS location-set longitude latitude radius m|km|ft|mi [WITHCOORD] [WITHDIST] [ASC|DESC] [COUNT count]GEORADIUSBYMEMBER location-set location radius m|km|ft|mi [WITHCOORD] [WITHDIST] [ASC|DESC] [COUNT count] 这两个命令的各个参数的意义如下： m|km|ft|mi 指定的是计算范围时的单位；如果给定了可选的 WITHCOORD ， 那么命令在返回匹配的位置时会将位置的经纬度一并返回；如果给定了可选的 WITHDIST ， 那么命令在返回匹配的位置时会将位置与中心点之间的距离一并返回；在默认情况下， GEORADIUS 和 GEORADIUSBYMEMBER 的结果是未排序的， ASC 可以让查找结果根据距离从近到远排序， 而 DESC 则可以让查找结果根据从远到近排序；COUNT 参数指定要返回的结果数量。作为示例， 我们可以使用 GEORADIUSBYMEMBER 去找出位于广州 50 公里、 100 公里以及 150 公里以内的城市： 1234567891011121314151617redis&gt; GEORADIUSBYMEMBER Guangdong-cities Guangzhou 50 km1) &quot;Foshan&quot;2) &quot;Guangzhou&quot;redis&gt; GEORADIUSBYMEMBER Guangdong-cities Guangzhou 100 km1) &quot;Foshan&quot;2) &quot;Guangzhou&quot;3) &quot;Dongguan&quot;4) &quot;Qingyuan&quot;redis&gt; GEORADIUSBYMEMBER Guangdong-cities Guangzhou 150 km1) &quot;Foshan&quot;2) &quot;Guangzhou&quot;3) &quot;Dongguan&quot;4) &quot;Qingyuan&quot;5) &quot;Shenzhen&quot; geohash查找精度：示例：查找附近的人好的， 在了解了 Redis GEO 特性的基本信息之后， 接下来我们该思考如何使用这些特性去解决实际的问题了。 为了让用户可以方便地找到自己附近的其他用户， 每个社交网站基本上都内置了“查找附近的人”这一功能， 通过 Redis ， 我们也可以实现同样的功能， 以下是实现该功能的伪代码： 123456789101112def pin(user, longitude, latitude):&quot;&quot;&quot;记录用户的地理位置。&quot;&quot;&quot;GEOADD(&apos;user-location-set&apos;, longitude, latitude, user)def find_nearby(user, n):&quot;&quot;&quot;返回指定用户附近 n 公里的所有其他用户。&quot;&quot;&quot;return GEORADIUSBYMEMBER(&apos;user-location-set&apos;, user, n, unit=&apos;km&apos;) 示例：摇一摇为了增加乐趣性， 我们可以对“查找附近的人”这一功能进行修改 —— 程序不是返回指定范围内的所有人， 而是随机地返回指定范围内的某个人， 这也就是非常著名的“摇一摇”功能。 以下是实现该功能的伪代码： 12345678910RANDOM_RADIUS = 1 # 随机查找的范围为 1 公里def find_random(user):# 获取范围内的所有其他用户get_all_near_users = find_nearby(user, RANDOM_RADIUS)# 将查找的结果从 Python 列表转换为 Python 集合user_set = set(get_all_near_users)# 然后调用 pop() 方法，从集合里面随机地移除并返回一个元素return user_set.pop() ` python目前的连接redis的第三方模块暂时没发现支持geo模块的，但是redis模块有一个execute_command()的函数支持传入redis命令： db= redis.Redis(host=self.ip, port=self.port, db=0, password=self.password) db.execute_command(‘geoadd’, collect, lng, lat, user_id) db.execute_command(‘georadiusbymember’, collect, user_id, distance, ‘m’) 1234简单的测了一下：百万条地理位置信息，查询附近的人只需要0.002秒左右，redis还是很给力的，以后要多多研究 `]]></content>
      <categories>
        <category>技术</category>
      </categories>
      <tags>
        <tag>数据库</tag>
        <tag>系统</tag>
        <tag>python</tag>
        <tag>redis</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[CentOS下python基本环境]]></title>
    <url>%2F2016%2F08%2F03%2F2016-08-03-centos-python-env%2F</url>
    <content type="text"><![CDATA[mysql的python连接工具： 12yum -y install MySQL-python python基本开发环境： 12yum install gcc gcc-c++ yum install python-devel 安装虚拟环境： 12pip install virtualenv]]></content>
      <categories>
        <category>技术</category>
      </categories>
      <tags>
        <tag>centos</tag>
        <tag>python</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Python字符串的问题]]></title>
    <url>%2F2016%2F07%2F22%2F2016-07-22-python-string%2F</url>
    <content type="text"><![CDATA[普通字符串可以用多种方式编码成Unicode字符串，具体要看你究竟选择了哪种编码： 12unicodestring = u&quot;Hello world&quot; 将Unicode转化为普通Python字符串：”encode”12345utf8string = unicodestring.encode(&quot;utf-8&quot;) asciistring = unicodestring.encode(&quot;ascii&quot;) isostring = unicodestring.encode(&quot;ISO-8859-1&quot;) utf16string = unicodestring.encode(&quot;utf-16&quot;) 将普通Python字符串转化为Unicode：”decode”12345plainstring1 = unicode(utf8string, &quot;utf-8&quot;) plainstring2 = unicode(asciistring, &quot;ascii&quot;) plainstring3 = unicode(isostring, &quot;ISO-8859-1&quot;) plainstring4 = unicode(utf16string, &quot;utf-16&quot;)]]></content>
      <categories>
        <category>技术</category>
      </categories>
      <tags>
        <tag>python</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Apache配置优化]]></title>
    <url>%2F2016%2F07%2F20%2F2016-07-20-apache-config%2F</url>
    <content type="text"><![CDATA[过滤配置文件中的注释信息： 12grep -v ‘^#\|^$\|#’ /etc/httpd/conf/httpd.conf CentOS6.5下配置apache启动方式为worker： 1234mv /usr/sbin/httpd /usr/sbin/httpd.preforkmv /usr/sbin/httpd.worker /usr/sbin/httpd 配置参数解读： ServerTokens OS 当服务器响应主机头（header）信息时显示Apache的版本和 操作系统名称ServerRoot “/etc/httpd” 设置服务器的根目录PidFile run/httpd.pid PID存放位置Timeout 60 若60秒后没有收到或送出任何数据就切断该连接KeepAlive Off 是否开启保持链接状态MaxKeepAliveRequests 100 在使用保持连接功能时，设置客户一次请求连接能 响应文件的最大上限KeepAliveTimeout 15 在使用保持连接功能时，两个相邻的连接的时间间 隔超过15秒，就切断连接 设置使用Prefork MPM运行方式的参数，此运行方式是Red hat默认的方式StartServers 8 设置服务器启动时运行的进程数MinSpareServers 5 最小空闲进程数MaxSpareServers 20 最大空闲进程数ServerLimit 256 最大的进程数MaxClients 256 最大的请求并发MaxClients=ServerLimit*进程的线程数MaxRequestsPerChild 4000 限制每个子进程在结束处理请求之前能处理的连接请求为1000ServerLimit 64ThreadLimit 200StartServers 5MaxClients 2500MinSpareThreads 50maxSpareThreads 200ThreadsPerChild 100MaxRequestsPerChild 1000 ServerLimit 16//服务器允许配置的进程数上限。这个指令和ThreadLimit结合使用设置了MaxClients最大允许配置的数值。任何在重启期间对这个指令的改变都将被忽略，但对MaxClients的修改却会生效。ThreadLimit 64//每个子进程可配置的线程数上限。这个指令设置了每个子进程可配置的线程数ThreadsPerChild上限。任何在重启期间对这个指令的改变都将被忽略，但对ThreadsPerChild的修改却会生效。默认值是”64″.StartServers 3//服务器启动时建立的子进程数，默认值是”3″。MinSpareThreads 75//最小空闲线程数,默认值是”75″。这个MPM将基于整个服务器监视空闲线程数。如果服务器中总的空闲线程数太少，子进程将产生新的空闲线程。MaxSpareThreads 250//设置最大空闲线程数。默认值是”250″。这个MPM将基于整个服务器监视空闲线程数。如果服务器中总的空闲线程数太多，子进程将杀死多余的空闲线 程。MaxSpareThreads的取值范围是有限制的。Apache将按照如下限制自动修正你设置的值：worker要求其大于等于 MinSpareThreads加上ThreadsPerChild的和MaxClients 400//允许同时伺服的最大接入请求数量(最大线程数量)。任何超过MaxClients限制的请求都将进入等候队列。默认值是”400″ ,16(ServerLimit)乘以25(ThreadsPerChild)的结果。因此要增加MaxClients的时候，你必须同时增加 ServerLimit的值。ThreadsPerChild 25//每个子进程建立的常驻的执行线程数。默认值是25。子进程在启动时建立这些线程后就不再建立新的线程了。MaxRequestsPerChild 0//设置每个子进程在其生存期内允许伺服的最大请求数量。到达MaxRequestsPerChild的限制后，子进程将会结束。如果MaxRequestsPerChild为”0″，子进程将永远不会结束。将MaxRequestsPerChild设置成非零值有两个好处：1.可以防止(偶然的)内存泄漏无限进行，从而耗尽内存。2.给进程一个有限寿命，从而有助于当服务器负载减轻的时候减少活动进程的数量。]]></content>
      <categories>
        <category>技术</category>
      </categories>
      <tags>
        <tag>redhat</tag>
        <tag>apache</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[python对时间日期做格式化]]></title>
    <url>%2F2016%2F07%2F06%2F2016-07-06-python-datetime-format%2F</url>
    <content type="text"><![CDATA[Python格式化日期时间的函数为datetime.datetime.strftime()；由字符串转为日期型的函数为：datetime.datetime.strptime()，两个函数都涉及日期时间的格式化字符串，列举如下： %a Abbreviated weekday name%A Full weekday name%b Abbreviated month name%B Full month name%c Date and time representation appropriate for locale%d Day of month as decimal number (01 - 31)%H Hour in 24-hour format (00 - 23)%I Hour in 12-hour format (01 - 12)%j Day of year as decimal number (001 - 366)%m Month as decimal number (01 - 12)%M Minute as decimal number (00 - 59)%p Current locale’s A.M./P.M. indicator for 12-hour clock%S Second as decimal number (00 - 59)%U Week of year as decimal number, with Sunday as first day of week (00 - 51)%w Weekday as decimal number (0 - 6; Sunday is 0)%W Week of year as decimal number, with Monday as first day of week (00 - 51)%x Date representation for current locale%X Time representation for current locale%y Year without century, as decimal number (00 - 99)%Y Year with century, as decimal number%z, %Z Time-zone name or abbreviation; no characters if time zone is unknown%% Percent sign 举一个例子： ebay中时间格式为‘Sep-21-09 16:34’ 则通过下面代码将这个字符串转换成datetime c = datetime.datetime.strptime(‘Sep-21-09 16:34’,’%b-%d-%y %H:%M’);cdatetime.datetime(2009, 9, 21, 16, 34) 又如：datetime转换成字符串 &gt;&gt; datetime.datetime.now().strftime(‘%b-%d-%y %H:%M:%S’);‘Sep-22-09 16:48:08’ 2.获取指定日期的n个月之后（或之前）的日期 123456789def months(dt, months): # 这里的months 参数传入的是正数表示往后 ，负数表示往前 month = dt.month - 1 + months year = dt.year + month / 12 month = month % 12 + 1 day = min(dt.day, calendar.monthrange(year, month)[1]) dt = dt.replace(year=year, month=month, day=day) return dt求两天以前的日期： 123456789today = datetime.datetime.now()morning_day = datetime.datetime(today.year, today.month, today.day, 0, 0, 0)before_two_day = today - datetime.timedelta(days=2)3.django utc时间格式不兼容的问题：RuntimeWarning: DateTimeField MonthlyStatistics.start_time received a naive datetime (2016-06-30 00:00:00) while time zone support is active. RuntimeWarning)import pytz 1234utc = pytz.timezone(&apos;UTC&apos;)today = datetime.date.today()today_start = datetime.datetime(today.year, today.month, today.day).replace(tzinfo=utc)end_day = today_start - datetime.timedelta(days=today_start.day)]]></content>
      <categories>
        <category>技术</category>
        <category>爬虫</category>
      </categories>
      <tags>
        <tag>数据库</tag>
        <tag>django</tag>
        <tag>python</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[两款xshell中的比较美观的配色方案]]></title>
    <url>%2F2016%2F06%2F29%2F2016-06-29-xshell-display-fonts%2F</url>
    <content type="text"><![CDATA[在众多SSH工具中，老左还是比较喜欢XSHELL，每天习惯对着默认的黑色背景和白色字体颜色的时候可能稍显枯燥，如果不喜欢图片背景的网友可以修改和自定义配色方案。下面有2个本人认为还算可以的配色方案。 第一、isayme.xcs 1234567891011121314151617181920212223[isayme]text(bold)=eaeaeamagenta(bold)=ff00fftext=ffffffwhite(bold)=eaeaeagreen=00c000red(bold)=d20000green(bold)=00ff00black(bold)=808080red=c00000blue=113fccblack=000000blue(bold)=0080ffyellow(bold)=ffff00cyan(bold)=00ffffyellow=c0c000magenta=c000c0background=222222white=c0c0c0cyan=00c0c0[Names]count=1name0=isayme 第二、ubuntu.xcs 1234567891011121314151617181920212223[ubuntu]text(bold)=ffffffmagenta(bold)=ad7fa8text=ffffffwhite(bold)=eeeeecgreen=4e9a06red(bold)=ef2929green(bold)=8ae234black(bold)=555753red=cc0000blue=3465a4black=000000blue(bold)=729fcfyellow(bold)=fce94fcyan(bold)=34e2e2yellow=c4a000magenta=75507bbackground=300a24white=d3d7cfcyan=06989a[Names]count=1name0=ubuntu 我们只需要复制且保存为对应的xcs文件名称就可以。 然后在xshell中导入配色方案即可12]]></content>
      <categories>
        <category>技术</category>
      </categories>
      <tags>
        <tag>linux</tag>
        <tag>redhat</tag>
        <tag>ubuntu</tag>
        <tag>vim</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Python中使用*args和**kwargs语法]]></title>
    <url>%2F2016%2F06%2F24%2F2016-06-24-python-use-args-kwargs%2F</url>
    <content type="text"><![CDATA[可变参数 (Variable Argument) 的方法：使用args和**kwargs语法。其中，args是可变的positional arguments列表，kwargs是可变的keyword arguments字典。并且，*args必须位于kwargs之前，因为positional arguments必须位于keyword arguments之前。 1234567def test_kwargs(first, *args, **kwargs): print &apos;Required argument: &apos;, first for v in args: print &apos;Optional argument (*args): &apos;, v for k, v in kwargs.items(): print &apos;Optional argument %s (*kwargs): %s&apos; % (k, v) 使用： 12345678910111213141516def test(a, *args, **kwargs): print &apos;------args-------&apos; for k in args: print k print &apos;------kwargs----&apos; for k, v in kwargs.items(): print k, vtest(1, 2, 3, b=7, c=8)#------args-------#2#3#------kwargs----#c 8#b 7]]></content>
      <categories>
        <category>技术</category>
      </categories>
      <tags>
        <tag>python</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Vim实用技巧]]></title>
    <url>%2F2016%2F06%2F23%2F2016-06-23-vim-methods%2F</url>
    <content type="text"><![CDATA[指定开始行到结尾行缩进： 12：2,7&gt; 指定第2到第7行右缩进一个单位 vim拷贝指定行到目的行： 12：30,50 co 20 #copy 30行到50行内容到20行; 注释多行: 12Ctl +v 方向键向下指定行 shift + i 注释符 esc Uwsgi依赖与lxml , 必须先装lxml再装uwsgi 否则会报错]]></content>
      <categories>
        <category>技术</category>
      </categories>
      <tags>
        <tag>linux</tag>
        <tag>centos</tag>
        <tag>python</tag>
        <tag>centos7</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[python中的中英文混搭字符串中文的提取]]></title>
    <url>%2F2016%2F06%2F21%2F2016-06-21-python-search-ch-in-string%2F</url>
    <content type="text"><![CDATA[模块内容re.compile(pattern, flags=0)编译正则表达式，返回RegexObject对象，然后可以通过RegexObject对象调用match()和search()方法。 1234#coding=utf-8import res = &apos;hi新手oh&apos;.decode(&apos;utf-8&apos;) #举个栗子是字符串s，为了匹配下文的unicode形式，所以需要解码p = re.compile(ur&apos;[\u4e00-\u9fa5]&apos;) #这里是精髓，[\u4e00-\u9fa5]是匹配所有中文的正则，因为是unicode形式，所以也要转为ur print p.split(s) #使用re库的split切割 中英文混搭字符串中文的提取 123456import remys = u&apos;hi新手oh上o路hea多ooo多oo指教98&apos; #提取其中的中文字符串p = re.compile(ur&apos;[\u4e00-\u9fa5]&apos;)res = re.findall(p, mys)result = &apos;&apos;.join(res)print result 新手上路多多指教 ###]]></content>
      <categories>
        <category>技术</category>
      </categories>
      <tags>
        <tag>python</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Django添加富文本编辑器DjangoUeditor]]></title>
    <url>%2F2016%2F06%2F20%2F2016-06-20-django-add-DjangoUeditor%2F</url>
    <content type="text"><![CDATA[1.上DjangoUeditor的github官网下载安装Ueditor，网址如下：https://github.com/zhangfisher/DjangoUeditor.git 按照readme.md安装即可推荐下载DjangoUeditor源码到项目根目录下 2.django admin中配置富文本编辑器：a. settings.py中添加apps： 1234567891011INSTALLED_APPS = ( &apos;django.contrib.admin&apos;, &apos;django.contrib.auth&apos;, &apos;django.contrib.contenttypes&apos;, &apos;django.contrib.sessions&apos;, &apos;django.contrib.messages&apos;, &apos;django.contrib.staticfiles&apos;, &apos;bootstrap_toolkit&apos;, &apos;DjangoUeditor&apos;, &apos;news&apos;,) b. urls.py中配置ueditor的路由： 1url(r&apos;^ueditor/&apos;, include(&apos;DjangoUeditor.urls&apos;)), c. models.py中添加ueditor字段： 12345from DjangoUeditor.models import UEditorWidgetclass News(BaseModel): title = models.CharField(verbose_name=u&quot;新闻标题&quot;, max_length=127) content = UEditorField(u&quot;文章正文&quot;, width=600, height=300, default=u&apos;&apos;, blank=True, imagePath=&quot;uploads/images/&quot;, toolbars=&apos;besttome&apos;, filePath=&apos;uploads/files/&apos;) d. 在admin.py中添加ueditor 1234567891011121314151617181920212223242526272829303132333435# -*- encoding: utf-8 -*-from django.contrib import adminfrom django import formsfrom models import Newsfrom django.utils.html import strip_tagsfrom DjangoUeditor.models import UEditorWidget# Register your models here.class NewsForm(forms.ModelForm): content=forms.CharField(widget=UEditorWidget(attrs=&#123;&apos;width&apos;: 1000, &apos;height&apos;: 500, &apos;imagePath&apos;: &apos;uploads/images/&apos;, &apos;filePath&apos;: &apos;uploads/files/&apos;&#125;)) class Meta: model = News exclude = []class NewsAdmin(admin.ModelAdmin): form = NewsForm # 只读字段 readonly_fields = [&apos;_get_thumbnail&apos;, &apos;create_time&apos;] # 可编辑的字段 fields = [&apos;title&apos;, &apos;publish_time&apos;,&apos;is_active&apos;, &apos;news_type&apos;, &apos;index_flag&apos;, &apos;cover_image&apos;, &apos;slide_show&apos;, &apos;_get_thumbnail&apos;, &apos;introduce&apos;, &apos;content&apos;] # 列表页展示字段 list_display = (&apos;title&apos;, &apos;introduce&apos;,) # 筛选字段 list_filter = [&apos;publish_time&apos;] # 搜索字段 search_fields = [&apos;title&apos;] def _get_content(self, obj): return strip_tags(obj.content)[:20] _get_content.short_description = &apos;内容&apos; _get_content.allow_tags = Trueadmin.site.register(News, NewsAdmin) e. 参数说明：文件图片和视频都是保存在MEDIA_ROOT目录下，所以需要在settings.py文件中指定MEDIA_ROOT = os.path.join(BASE_DIR, ‘media’)imagePath 保存图片的目录filePath 保存文件的目录]]></content>
      <categories>
        <category>技术</category>
      </categories>
      <tags>
        <tag>linux</tag>
        <tag>django</tag>
        <tag>python</tag>
        <tag>DjangoUeditor</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[用Python来写5种排序方法]]></title>
    <url>%2F2016%2F06%2F20%2F2016-06-20-five-methods-sort-in-python%2F</url>
    <content type="text"><![CDATA[中C语言的毒太深了，目前在自学Python，一时兴起用Python写了五种排序 1.冒泡排序：123456789def bubble(ori_list, n): &quot;&quot;&quot; 冒泡排序 &quot;&quot;&quot; for i in range(n-1, 0, -1): for j in range(0, i): if ori_list[j] &gt; ori_list[j+1]: ori_list[j], ori_list[j+1] = ori_list[j+1], ori_list[j] 2.选择排序：12345678910111213def select(ori_list, n): &quot;&quot;&quot; 选择排序 &quot;&quot;&quot; for i in range(1, n): min_num = i-1 j = i while j &lt; n: if ori_list[j] &lt; ori_list[min_num]: min_num = j j += 1 ori_list[i-1], ori_list[min_num] = ori_list[min_num], ori_list[i-1] 3.插入排序：12345678910111213def insert(ori_list, n): &quot;&quot;&quot; 插入排序 &quot;&quot;&quot; for i in range(1, n): tmp = ori_list[i] j = i - 1 while j &gt; -1: if ori_list[j] &gt; tmp: ori_list[j+1] = ori_list[j] ori_list[j] = tmp j -= 1 4.归并排序：12345678910111213141516171819202122232425def merge(left, right): &quot;&quot;&quot; 归并排序 &quot;&quot;&quot; i, j = 0, 0 result = [] while i &lt; len(left) and j &lt; len(right): if left[i] &lt;= right[j]: result.append(left[i]) i += 1 else: result.append(right[j]) j += 1 result += left[i:] result += right[j:] return resultdef merge_sort(ori_list): if len(ori_list) &lt;= 1: return ori_list mid = len(ori_list)/2 left = merge_sort(ori_list[:mid]) right = merge_sort(ori_list[mid:]) return merge(left, right) 5.快速排序：123456789101112131415161718192021def quick_sort(lists, left, right): # 快速排序 if left &gt;= right: return lists key = lists[left] low = left high = right while left &lt; right: while left &lt; right and lists[right] &gt;= key: right -= 1 lists[left] = lists[right] while left &lt; right and lists[left] &lt;= key: left += 1 lists[right] = lists[left] lists[right] = key quick_sort(lists, low, left - 1) quick_sort(lists, left + 1, high) return listsres_list = quick_sort(ori_list, 0, len(ori_list)-1)print &apos;quick_sort:&apos;, res_list 简易写法： 1234567def qsort(q): if len(q) &lt;= 1: return q else: p = q[0] return qsort([x for x in q[1:] if x &lt; p]) + [p] + qsort([x for x in q[1:] if x &gt;= p])]]></content>
      <categories>
        <category>python</category>
      </categories>
      <tags>
        <tag>linux</tag>
        <tag>python</tag>
        <tag>算法</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[redhat7下rdo方式安装openstack笔记]]></title>
    <url>%2F2016%2F06%2F19%2F2016-06-19-redhat-rdo-install-openstack%2F</url>
    <content type="text"><![CDATA[学习openstack在安装过程中也遇到了很多的问题，，在此记录一下： 首先查看硬件是否支持虚拟化：linux下： 12grep -E &apos;svm|vmx&apos; /proc/cpuinfo 有输出信息说明支持，然后在bios中开启虚拟化如果不支持虚拟化，openstack会默认使用软件虚拟化技术qemu来创建虚拟机，性能上和kvm差距很大，并且个人赶脚比较占内存； 先用 YUM 安裝 RDO 及 openstack-packstack 1234# yum update -y# yum install -y http://rdo.fedorapeople.org/rdo-release.rpm# yum install -y openstack-packstack 本机设置成静态ip： 12# vim /etc/sysconfig/network-scripts/ifcfg-eno16777736 修改如下： 1234567891011121314151617181920HWADDR=00:0C:29:99:3C:45TYPE=EthernetBOOTPROTO=noneDEFROUTE=yesPEERDNS=yesPEERROUTES=yesIPV4_FAILURE_FATAL=noIPV6INIT=yesIPV6_AUTOCONF=yesIPV6_DEFROUTE=yesIPV6_PEERDNS=yesIPV6_PEERROUTES=yesIPV6_FAILURE_FATAL=noNAME=eno16777736UUID=88d86789-394c-4647-b8e6-88f14a652c84ONBOOT=yesIPADDR=192.168.1.50PREFIX=24GATEWAY=192.168.1.1DNS1=114.114.114.114 重启网卡： 1# systemctl restart network 4.生成安装配置文件： 12# packstack --gen-answer-file=allinone.txt# vim allinone.txt 配置需要安装的服务和设置密码，根据个人需要设置，然后执行费时较长的最终安装： 1# packstack --answer-file=allinone.txt 国内安装过程中极有可能会中断，重新执行即可，直到安装成功。5.allinone方式安装成功以后需要配置网卡： 12# vim /etc/sysconfig/network-scripts/ifcfg-eno16777736 配置如下: 1234567891011121314151617181920212223HWADDR=00:0C:29:99:3C:45#TYPE=EthernetBOOTPROTO=noneDEFROUTE=yesPEERDNS=yesPEERROUTES=yesIPV4_FAILURE_FATAL=noIPV6INIT=yesIPV6_AUTOCONF=yesIPV6_DEFROUTE=yesIPV6_PEERDNS=yesIPV6_PEERROUTES=yesIPV6_FAILURE_FATAL=noNAME=eno16777736UUID=88d86789-394c-4647-b8e6-88f14a652c84#ONBOOT=yes#IPADDR=192.168.1.50#PREFIX=24#GATEWAY=192.168.1.1#DNS1=114.114.114.114TYPE=OVSPortDEVICETYPE=ovsOVS_BRIDGE=br-ex 12# vim /etc/sysconfig/network-scripts/ifcfg-br-ex 配置如下： 123456789DEVICE=br-exDEVICETYPE=ovsTYPE=OVSBridgeBOOTPROTO=staticIPADDR=192.168.1.50NETMASK=255.255.255.0GATEWAY=192.168.1.1DNS1=114.114.114.114ONBOOT=yes 重启网卡： 12# systemctl restart network 记录的一些问题：a. packstack –answer-file=xxx.txt安装过程，有可能因为源的原因中断，你可以修改一下netns.pp文件中延时。 b.创建云主机参照：http://www.chenshake.com/centos6-4-single-card-all-in-one-install-havana/ 照着步骤用SecureCRT登录不上云主机，提示：需要一个.pub的公钥文件，所以照着第四步用用户名和密码登录的 c.登录云主机参照：http://www.chenshake.com/openstack-mirror-and-password/ d. DNS的错误，今天搭了CentOS6.5上RDO（Vlan）双节点安装Icehouse版本：总是报DNS的错误： 12345678910111213ERROR : Failed to run remote script, stdout: Loaded plugins: fastestmirror, securityLoading mirror speeds from cached hostfile* epel: mirrors.neusoft.edu.cnstderr: Warning: Permanently added &apos;192.168.115.115&apos; (RSA) to the list of known hosts.+ trap t ERR+ yum install -y puppet openssh-clients tar nc rubygem-jsonhttp://yum.theforeman.org/releases/1.3/el6/x86_64/repodata/repomd.xml: [Errno 14] PYCURL ERROR 6 - &quot;Couldn&apos;t resolve host &apos;yum.theforeman.org&apos;&quot;Trying other mirror.Error: Cannot retrieve repository metadata (repomd.xml) for repository: foreman. Please verify its path and try again++ t++ exit 1Please check log file /var/tmp/packstack/20141102-222130-D8Ve6D/openstack-setup.log for more information 最后yum update以后还是报DNS的错误：于是把8.8.8.8 改成了114.114.114.114，关了计算节点的iptables和Selinux以后就好了，记录一下]]></content>
      <categories>
        <category>云计算</category>
      </categories>
      <tags>
        <tag>linux</tag>
        <tag>epel</tag>
        <tag>openstack</tag>
        <tag>云计算</tag>
        <tag>centos7</tag>
        <tag>rdo</tag>
        <tag>redhat7</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[用nginx和uwsgi来部署django项目]]></title>
    <url>%2F2016%2F06%2F12%2F2016-06-12-nginx-and-uwsgi-deploy-django%2F</url>
    <content type="text"><![CDATA[#用nginx和uwsgi来部署django项目 ##1. 安装基本软件 1234sudo apt-get install python-devsudo apt-get install nginxpip install uwsgi ##2.配置uwsgi和django的集成vim test.py 创建test.py,添加如下代码 1234def application(env, start_response): start_response(&apos;200 OK&apos;, [(&apos;Content-Type&apos;,&apos;text/html&apos;)]) return &quot;Hello World&quot; 然后执行shell命令：uwsgi –http :8001 –wsgi-file test.py 访问网页：http://127.0.0.1:8001/ 编写django_wsgi.py文件，将其放在与文件manage.py同一个目录下：vim django_wsgi.py 添加如下代码： 123456789101112131415#!/usr/bin/env python# coding: utf-8import osimport sys# 将系统的编码设置为UTF8reload(sys)sys.setdefaultencoding(&apos;utf8&apos;)os.environ.setdefault(&quot;DJANGO_SETTINGS_MODULE&quot;, &quot;yoursite.settings&quot;)from django.core.handlers.wsgi import WSGIHandlerapplication = WSGIHandler() 连接django和uwsgi，实现简单的WEB服务器。我们假设你的Django项目的地址是/home/work/src/sites/testdjango1/testdjango/mysite， 然后，就可以执行以下命令：uwsgi –http :8000 –chdir /home/work/src/sites/testdjango1/testdjango/mysite –module django_wsgi这样，你就可以在浏览器中访问你的Django程序了。所有的请求都是经过uwsgi传递给Django程序的。 ##集成django,uwsgi和nginx部署： ####a.在django项目根目录创建启动uwsgi的xml文件： 1234567:8077/home/work/src/sites/testdjango1/testdjango/mysitedjango_wsgi4 uwsgi.log ####b.配置Nginx服务器：备份nginx配置文件：sudo cp /etc/nginx/sites-available/default /etc/nginx/sites-available/default.bakvim /etc/nginx/sites-available/default 修改如下： 12345678910111213141516171819202122232425262728293031server &#123; listen 80; server_name localhost; access_log /var/log/nginx/access.log; error_log /var/log/nginx/error.log; #charset koi8-r; #access_log logs/host.access.log main; location / &#123; include uwsgi_params; uwsgi_pass 127.0.0.1:8077; &#125; #error_page 404 /404.html; # redirect server error pages to the static page /50x.html # error_page 500 502 503 504 /50x.html; location = /50x.html &#123; root html; &#125; location /static/ &#123; alias /home/hz/PycharmProjects/myscrapy/check_ip/; index index.html index.htm; &#125;&#125; 如果不能访问日志文件，修改相关文件的权限即可 ####c. 验证测试各步骤结果重启Nginx服务器，以使Nginx的配置生效。nginx -s reload重启后检查Nginx日志是否有异常。 启动uWSGI服务器 cd /home/work/src/sites/testdjango1/testdjango/mysite uwsgi -x djangochina_socket.xml `]]></content>
      <categories>
        <category>技术</category>
      </categories>
      <tags>
        <tag>ubuntu</tag>
        <tag>django</tag>
        <tag>python</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[linux系统下常用命令总结 ubuntu CentOS6.5]]></title>
    <url>%2F2016%2F05%2F31%2F2016-05-31-linux-cmd-ubuntu-centos6-5%2F</url>
    <content type="text"><![CDATA[python环境相http方式共享文件命令：12python -m SimpleHTTPServer 根据端口杀死进程命令：12kill `lsof -i :9077 | awk &apos;&#123;print $2&#125;&apos; | grep -v PID` 1.获取文本中含有某个字符串的上一行：1grep &apos;old mode 100644&apos; -B 1 filename 含有摸个字符串的下一行用： 1grep &apos;old mode 100644&apos; -A 1 filename 2.查看当前系统文件系统类型：123fdisk -ldf -Tparted /dev/sda print ----列出本机目前的分区情况 ls查看文件以K、M、G为单位显示：ls -lh 3.在LINUX中，两条命令可以用来访问WINDOWS共享： smbclient -U 用户名 //IP地址/共享名例如： smbclient -U share //192.168.4.165/fg如果成功，会出现smb&gt;提示符，好像是输入一个？，就可以看到能够使用的命令了。 mount -o username=用户名 //IP地址/共享名 /LINUX本地挂载点例如： mount -o username=share //192.168.4.165/fg /test如果成功，直接访问linux系统中的/test目录，就可以看到WINDOWS的共享内容linux 中将一个目录挂载到另一个目录： mount –bind olddir newdir 4.find名称 : find用法 : find使用说明 :将档案系统内符合 expression 的档案列出来。你可以指要档案的名称、类别、时间、大小、权限等不同资讯的组合，只有完全相符的才会被列出来。 find 根据下列规则判断 path 和 expression，在命令列上第一个 - ( ) , ! 之前的部份为 path，之后的是 expression。如果 path 是空字串则使用目前路径，如果 expression 是空字串则使用 -print 为预设 expression。 expression 中可使用的选项有二三十个之多，在此只介绍最常用的部份。 -mount, -xdev : 只检查和指定目录在同一个档案系统下的档案，避免列出其它档案系统中的档案-amin n : 在过去 n 分钟内被读取过-anewer file : 比档案 file 更晚被读取过的档案-atime n : 在过去 n 天过读取过的档案-cmin n : 在过去 n 分钟内被修改过-cnewer file :比档案 file 更新的档案-ctime n : 在过去 n 天过修改过的档案-empty : 空的档案-gid n or -group name : gid 是 n 或是 group 名称是 name-ipath p, -path p : 路径名称符合 p 的档案，ipath 会忽略大小写-name name, -iname name : 档案名称符合 name 的档案。iname 会忽略大小写-size n : 档案大小 是 n 单位，b 代表 512 位元组的区块，c 表示字元数，k 表示 kilo bytes，w 是二个位元组。-type c : 档案类型是 c 的档案。d: 目录c: 字型装置档案b: 区块装置档案p: 具名贮列f: 一般档案l: 符号连结s: socket-pid n : process id 是 n 的档案 你可以使用 ( ) 将运算式分隔，并使用下列运算。exp1 -and exp2! expr-not exprexp1 -or exp2exp1, exp2范例:将目前目录及其子目录下所有延伸档名是 c 的档案列出来。 find . -name “*.c”将目前目录其其下子目录中所有一般档案列出 find . -ftype f将目前目录及其子目录下所有最近 20 分钟内更新过的档案列出 find . -ctime -20find . -name “*” -exec grep xxx {} ; -print |morexxx为你想要找的字符串 查找当前目录下含有某字符的文件名并列出： find . | xargs -ri “IBM” -l CentOS6.5下添加epel源]]></content>
      <categories>
        <category>linux</category>
      </categories>
      <tags>
        <tag>epel</tag>
        <tag>find</tag>
        <tag>查找关键字</tag>
        <tag>系统</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[CentOS6.5配置本地openstack源]]></title>
    <url>%2F2016%2F05%2F26%2F2016-05-26-centos6-config-local-openstack-resources%2F</url>
    <content type="text"><![CDATA[6.5搭建本地OpenStack软件源 1、把相关软件包全部下载到本地机器 12wget -np -nH –cut-dirs=1 -r -c -L –exclude-directories=repodata –accept=rpm,gz,xml http://repos.Fedorapeople.org/repos/openstack/openstack-icehouse/epel-6/ -P /opt/epel6 如果不行： 1 wget -np -nH --cut-dirs=1 -r -c -L --exclude-directories=repodata --accept=rpm,gz,xml https://repos.Fedorapeople.org/repos/openstack/openstack-icehouse/epel-6/ -P /opt/epel6 --no-check-certificate 注意： 不要将下载的文件放在/root目录下，否则httpd不能提供服务 wget参数介绍-r,–recursive 下载整个网站、目录-nH, –no-host-directories 不创建主机目录-P, –directory-prefix=PREFIX 将文件保存到目录PREFIX/…–cut-dirs=NUMBER 忽略 NUMBER层远程目录-k, –convert-links 转换非相对链接为相对链接-I, –include-directories=LIST 允许目录的列表-X, –exclude-directories=LIST 不被包含目录的列表-np, –no-parent 不要追溯到父目录-A, –accept=LIST 分号分隔的被接受扩展名的列表-R, –reject=LIST 分号分隔的不被接受的扩展名的列表-c, –continue 接着下载没下载完的文件-L, –relative 仅仅跟踪相对链接 2、创建repodata信息 12createrepo -p -d -o /opt/epel6 /opt/epel6 3、配置http服务器，将根目录指到/opt/epel6 12345yum install -y httpdrm -rf /var/www/htmlln -s /opt/epel6 /var/www/htmlservice httpd start 创建rdo-release.repo文件 123456[openstack-icehouse]name=OpenStack Icehouse Repositorybaseurl=http://10.0.0.137/epel6/enabled=1gpgcheck=0 5、把生成的rdo-release.repo文件传到客户端的/etc/yum.repos.d/目录下，即可 `使用wget下载https链接：123456`# wget -r -np -nd --accept=gz --no-check-certificate https: `//www.xxx.com/dir/ –http-user=username –http-password=password123456`下载 `’dir’1`目录下的所有gz文件 `-np 没有父目录123456`-nd 不要构建本地目录结构 `–accept=gz 只下载gz文件123456789`HTTPS (SSL/TLS) Options（HTTPS (SSL) 参数选项） `–certificate=file123456`可选的客户段端证书 `–1`private `-key=file123456`对此证书可选的“密钥文档” `–1`private `-key-type=type123456`对此证书可选的“密钥类型“ `–egd-file=file123456`EGD socket 文档名 `–ca-directory=directory123456`CA 散列表所在的目录 `–ca-certificate=file123456`包含 CA 的文档 `–certificate-type=[ PEM（默认），DER ]123456`Client-Cert 类型：PEM，DER `–no-check-certificate123456`不用检查服务器的证书 `–secure-protocol=[ auto，SSLv2，SSLv3，TLSv1 ]123456`选择 SSL 协议：auto，SSLv2，SSLv3，TLSv1 `FTP Options（FTP参数选项）123456`--ftp-user `登录ftp的用户名（注意：最好方法是在.netrc或.wgetrc文件中定义）123456`--ftp-password `登录ftp的密码（注意：最好方法是在.netrc或.wgetrc文件中定义）123456`--no-remove-listing `不删除“.listing” 文档123456`--no-glob `关闭所有通配符的ftp文档名123456`--no-passive-ftp `禁用“被动”传输模式123456`--retr-symlinks `在递归模式中，下载链接所指示的文档（排除连接目录的）123456789`1 `. 下载单个文件123456`wget url + filename `下载过程中可以看到四项信息123456`已经下载的比例，已经下载的大小，当前的下载速度，剩余的时间 `21`. 使用一个大写O做参数表示另存为 `wget -O save_name url123456`这种方法适用于对应链接中没有显式文件名的情况。 `31`. 指定下载速率 `wget –limit-rate123456`wget -limit-rate=200k url + filename `41`. 断点下载 `wget -c完成未完成的下载123456`下载一半时可以停下来，ctrl+c停顿，继续下载可以加入一个-c参数。 `注意：如果不加入-c，那么下载的文件会多出一个.1`1 `的后缀。123456`5 `. 后台下载123456`加上一个-b参数 `wget -b url/filename为后台下载，下载经过写入到wget-log文件中。123456`用tail -f wget-log查看下载日志 `61`. 模拟在浏览器下下载 `有的网站不允许客户在非浏览器环境下下载。使用–user-agent来设置123456`wget --user-agent= `”Mozilla/5.0 (X11; U; Linux i686; en-US; rv:1.9.0.3) Gecko/2008092416 Firefox/3.0.3”1 `URL-TO-DOWNLOAD `71`. 测试下载链接 `方法:使用–spider123456`试图做计划下载时候，需要先检查一下下载链接是否有效。 `wget –spider DOWNLOAD-URL123456`如果返回OK，则表示下载链接是正确的 `81`、增加尝试次数 `方法：–tries=1`1000 `如果网速有问题，下载大文件的时候可能会发生错误，123456`默认wget尝试 `201`次链接。 `如果尝试1`75 `次，可以123456`wget --tires= `751 `DOWNLOAD-URL `91`、下载多个文件使用wget -i `将多个下载链接写入到一个download-file-list.txt文件中，而后用123456`wget -i download-file-list.txt `101`、下载整站 `方法：用–mirror参数123456`当你要下载一个完整站点并实现本地浏览的时候， `wget –mirror -p –convert-links -P ./LOCAL-DIR WEBSITE-URL123456`参数讲解： `–mirror：设置这个参数用来建立本地镜像123456`-p：下载所有html文件适合显示的元素 `–convert-links：下载完成后，将文档链接都转换成本地的123456`-P ./LOCAL-DIR：保存所有的文件和目录到指定文件夹下 `111`、下载时候禁止下载指定类型的文件 `例如下载站点时候，不打算下载gif动画图片。123456`wget --reject=gif WEBSITE-TO-BE-DOWNLOADED `121`、记录下载日志 `方法：使用小写字母o123456`wget -o xx.html.log -O xx.html `”http://ip138.com/ips.asp?ip=58.251.193.137&amp;action=2&quot;123456`检查一下日志： `[root1`@localhost `opt]# cat xx.html.log123456`-- `20101`- `071`- `121 `11 `:1`57 `:1`22 `– http:1`//ip138.com/ips.asp?ip=58.251.193.137&amp;action=2 `正在解析主机 ip138.com…1`221.5 `.1`47.136 `Connecting to ip138.com|1`221.5 `.1`47.136 `|:1`80 `… 已连接。123456`已发出 HTTP 请求，正在等待回应... `2001 `OK `长度：1`7817 `(1`7 `.6K) [text/html]123456`Saving to: `xx.html&apos; `0K …….1`100 `%1`65 `.5K=1`0 `.1s123456`2010 `-1`07 `-1`12 `111`: `571`: `221 `( `65.51 `KB/s) - `xx.html&apos; saved [ `78171`/ `78171`] `131`、是第 `91`条的增强版。可以限制下载容量 `wget -Q5m -i FILE-WHICH-HAS-URLS123456`当下载的文件达到 `51`兆的时候，停止下载。 `注意：如果不是对一个文件下载链接清单，对单个文件，这个限制不会生效的。123456`14 `、和第1`11 `条正好相反，123456`这条技巧是讲述如何仅仅下载指定类型的文件 `从一个网站中下载所有的pdf文件123456`wget -r -A.pdf http: `//url-to-webpage-with-pdfs/123456`15 `、使用wget完成ftp下载123456`匿名ftp下载类似于http下载 `wget ftp-url即可。123456`如果是需要输入用户名和密码，则是 wget --ftp-user=USERNAME --ftp-password=PASSWORD DOWNLOAD-URL ``]]></content>
      <categories>
        <category>云计算</category>
        <category>技术</category>
      </categories>
      <tags>
        <tag>linux</tag>
        <tag>centos</tag>
        <tag>镜像</tag>
        <tag>openstack</tag>
        <tag>云计算</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[CentOS6.5下添加epel源]]></title>
    <url>%2F2016%2F05%2F26%2F2016-05-26-centos6-add-epel-resources%2F</url>
    <content type="text"><![CDATA[0.安装yum优先级插件 1yum install yum-priorities 1.epel简介: https://fedoraproject.org/wiki/EPEL/zh-cn 1rpm -Uvh http://mirrors.ustc.edu.cn/fedora/epel/6/x86_64/epel-release-6-8.noarch.rpm rpm -Uvh http://rpms.famillecollet.com/enterprise/remi-release-6.rpm 以上URL请按实际情况修改 2.查看是否安装成功 1rpm -q epel-release 3.导入key： 1rpm --import /etc/pki/rpm-gpg/RPM-GPG-KEY-EPEL-6 4.修改/etc/yum.repos.d/epel.repo文件 在[epel]最后添加一条属性 priority=11 1vi /etc/yum.repos.d/epel.repo 意思是yum先去官方源查，官方没有再去epel的源找 5.重建缓存 1yum makecache]]></content>
      <categories>
        <category>技术</category>
      </categories>
      <tags>
        <tag>linux</tag>
        <tag>centos</tag>
        <tag>epel</tag>
        <tag>redhat</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[制作linux还原镜像]]></title>
    <url>%2F2016%2F05%2F26%2F2016-05-26-make-linux-iso%2F</url>
    <content type="text"><![CDATA[ghost和g4l安装操作系统，速度太慢，整个过程太冗长乏味了。 安装过程中，需要回答若干问题，系统需要安装无数个软件，创建和写入无数的文件。因为涉及到大量的文件定位和读写，速度一定是快不起来的。 Windows下我们常常使用ghost系统来备份和刻录操作系统。ghost可以clone整个系统的镜像，然后在新的电脑上恢复，相当简单。用ghost系统安装操作系统比使用安装光盘安装系统要快捷多了，也不需要回答任何问题了。 那么，我们能不能用ghost来备份和恢复Linux系统呢。 答案是不行。因为ghost只能识别很少的老旧Linux文件系统，也无法识别grub和LILO等引导加载程序。 其实，Linux下也有ghost工具，最著名的有g4l—ghostForLinux。 用了一下ghostForLinux。如果是整个磁盘的复制和恢复，还算简单。但是，我试了半天，也没办法实现对一个或者几个分区的恢复。 g4l，还是太弱了，无法满足我的要求！ 神奇的fdisk和dd命令深深的苦恼中，灵光乍现：神奇的ghost的原理是什么呢？不就是数据复制吗？Linux下的dd命令不就是最强大的数据复制工具！ 既然如此，我为什么要使用g4l这样复杂的工具呢？一条dd命令不就可以帮我实现任意复杂的镜像复制和恢复的需求了吗？管他是grub，还是ext4，btrfs，FAT32，NTFS…dd面前众生平等。 进入Linux操作系统，打开命令行，执行如下命令： sudo fdisk -u -l 可以查看所有磁盘上的所有分区的尺寸和布局情况。 -u，让start和end中数字的单位是512字节，也就是一个sector扇区的大小。 假设我有一个/dev/sda磁盘，有100GB大小。我安装了一个Ubuntu操作系统。使用了如下分区： /dev/sda1 5GB /dev/sda2 1GB 扩展分区 /dev/sda5 1GB 扩展分区 /dev/sda2是所有扩展分区，它的大小和/dev/sda5重合。 /dev/sda1是ext4格式的文件系统。用于安装ubuntu操作系统。 /dev/sda5是swap格式的文件系统，作为交换分区。 如果我用弱智的g4l工具制作系统的镜像，就需要备份整个磁盘100GB，而不是我需要的6GB。 g4l也可以单独备份分区，但是在恢复时，就需要在目标计算机上安装好grub，并进行了适当的分区。很麻烦！ 我这里，可以使用一条dd命令就生成6GB的镜像。然后可以在任意硬盘大于6GB的计算机上恢复出完整的系统，包括MBR和3个分区sda1,sda2,sda5。 具体步骤找一个U盘，安装UbuntuLive Cd系统。【具体如何制作U盘启动的UbuntuLive CD，可以参考Ubuntu官方网站的帮助。】 UbuntuLive Cd和WindowsPE系统类似，是光盘/U盘引导的Ubuntu操作系统，不需要安装就可以直接使用。 U盘启动，进入盘上的Ubuntu系统，打开命令行，执行： sudo fdisk -u -l /dev/sda 查看硬件的分区情况。 然后执行： dd bs=512 count=[fdisk**命令中最大的end数+1] if=/dev/sda of=/ghost.img** 这样，就可以把我需要的分区数据全部copy到ghost.img文件中。镜像制作完成了！ 然后，我们就可以把U盘插到其他系统上，用U盘启动，进入UbuntuLiveCD，打开命令行，执行如下命令： dd if=/ghost.img of=/dev/sda 完成后，拔掉U盘，启动计算机，就可以看到我们的Linux系统已经安装完毕了！ 注意： 不要直接在计算机上用本地磁盘启动系统后执行dd命令生成本地磁盘的镜像。而应该使用livecd启动计算机。 因此计算机运行时会对系统盘产生大量写操作。 直接对运行中的系统盘生成的镜像，在恢复到其他硬盘上时，很可能会无法启动！ 一样适用于非Linux操作系统在linux上用dd命令实现系统镜像备份和恢复，是不是很简单呢？ 对于Windows系统，甚至Mac等等任意系统，其实都可以用dd命令实现系统镜像的备份和恢复。 因为，Linux的fdisk命令能够识别任意系统下的分区格式。fdisk并不关系分区上的文件系统，甚至有无文件系统都不关心。fdisk总是可以报告分区占用了哪些扇区。 dd命令也不关心磁盘的文件系统格式，它只是简单地按照要求从指定的位置，复制多少字节数据而已。 dd命令实现镜像备份和恢复，比Ghost软件简单和强大多了。使用ghost软件，依然需要用户进行复杂而危险的磁盘分区操作。 而使用fdisk和dd这两条命令，一切都免了！ 压缩和解压缩可能我们需要备份的分区很大，使用dd命令生成的镜像文件也就很大。存储和传输这些镜像不太方便。 我们也可以使用压缩程序压缩生成的镜像文件。 这里，我选择使用gzip程序，配合dd命令一起使用。 gzip参数： -c 表示输出到stdout -d 表示解压缩 -1 表示最快压缩 -9 表示最好压缩 默认使用的是-6压缩级别。 要使用 dd 和 gzip 生成压缩的镜像文件，可以执行命令： `# dd bs=512count=[fdisk命令中最大的end数+1] if=/dev/sda | gzip -6 &gt; /ghost.img.gz 123还原时，可以执行下列命令： `# **gzip -dc /ghost.img.gz.gz | dd of=/dev/sda** 提醒： 如果你把镜像恢复到另一台计算机上，你可能会发现你的网卡是eth1，而不是eth0。这是因为 /etc/udev/rules.d/70-persistent-net.rules 文件把你做镜像的计算机的网卡作为eth0登记了。 如果你的网络脚本对eth0进行了处理，而没有对eth1进行处理，那么不修改网络脚本，你可能就无法上网了。 也许你会希望在做镜像之前，先删除 /etc/udev/rules.d/70-persistent-net.rules 文件。这样你恢复镜像时，网卡的名字就是eth0。 就不会造成你在恢复后的计算机上无法上网的问题了。]]></content>
      <categories>
        <category>技术</category>
      </categories>
      <tags>
        <tag>linux</tag>
        <tag>ghost</tag>
        <tag>ubuntu</tag>
        <tag>镜像</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[mysql中没有mysql数据库]]></title>
    <url>%2F2016%2F05%2F26%2F2016-05-26-mysql-not-found-mysql%2F</url>
    <content type="text"><![CDATA[mysql安装完之后，登陆后发现只有两个数据库：mysql&gt; show databases; +——————–+ | Database | +——————–+ | information_schema | | test | +——————–+ ，mysql&gt; use mysql ERROR 1044 (42000): Access denied for user ‘‘@’localhost’ to database ‘mysql’ 访问被拒绝，原因就是在删除数据库时（rpm -e mysql*）没有删除干净，需要把/var/lib/mysql的目录全部删除干净，然后再重新安装即可。 顺便记一下一些常用的命令： 一、连接MYSQL。 格式： mysql -h主机地址 -u用户名 －p用户密码 1、连接到本机上的MYSQL。 mysql -u root -p回车后提示你输密码，注意用户名前可以有空格也可以没有空格，但是密码前必须没有空格，否则让你重新输入密码。 如果刚安装好MYSQL，超级用户root是没有密码的，故直接回车即可进入到MYSQL中了，MYSQL的提示符是： mysql&gt; 2、连接到远程主机上的MYSQL。假设远程主机的IP为：192.168.2.2，用户名为root，密码为123456。则键入以下命令： mysql -h192.168.2.2 -uroot -p1234563、退出MYSQL命令： exit （回车）二、修改密码。 格式：mysqladmin -u用户名 -p旧密码 password 新密码 1、给root加个密码123456。键入以下命令： mysqladmin -u root -password 1234562、再将root的密码改为56789。 mysqladmin -u root -p123456 password 56789三、增加新用户。 格式：grant select on 数据库.* to 用户名@登录主机 identified by “密码” 1、增加一个用户test1密码为abc，让他可以在任何主机上登录，并对所有数据库有查询、插入、修改、删除的权限。首先用root用户连入MYSQL，然后键入以下命令： mysql&gt;grant select,insert,update,delete on . to test1@”%” Identified by “abc”; mysql&gt;flush privileges; 使之生效 2、增加一个用户test2密码为abc,让他只可以在localhost上登录，并可以对数据库mydb进行查询、插入、修改、删除的操作（localhost指本地主机，即MYSQL数据库所在的那台主机），这样用户即使用知道test2的密码，他也无法从internet上直接访问数据库，只能通过MYSQL主机上的web页来访问了。 mysql&gt;grant select,insert,update,delete on mydb.* to test2@localhost identified by “abc”; mysql&gt;flush privileges; 使之生效 如果你不想test2有密码，可以再打一个命令将密码消掉。 mysql&gt;grant select,insert,update,delete on mydb.* to test2@localhost identified by “”; mysql&gt;flush privileges; 使之生效 操作技巧 1、如果你打命令时，回车后发现忘记加分号，你无须重打一遍命令，只要打个分号回车就可以了。也就是说你可以把一个完整的命令分成几行来打，完后用分号作结束标志就OK。 2、你可以使用光标上下键调出以前的命令。 查询、创建、删除、更新命令 1、显示当前数据库服务器中的数据库列表： mysql&gt;show databases; 注意：mysql库里面有MYSQL的系统信息，我们改密码和新增用户，实际上就是用这个库进行操作。 2、显示数据库中的数据表： mysql&gt;use 库名； mysql&gt;show tables; 3、显示数据表的结构： mysql&gt;describe 表名; 4、建立数据库： mysql&gt;create database 库名; 5、建立数据表： mysql&gt;use 库名; mysql&gt;create table 表名 (字段名 varchar(20), 字段名 char(1)); 6、删除数据库： mysql&gt;drop database 库名; 7、删除数据表： mysql&gt;drop table 表名; 8、将表中记录清空： mysql&gt;delete from 表名; 9、显示表中的记录： mysql&gt;select * from 表名; 10、往表中插入记录： mysql&gt;insert into 表名 values (”123”,”b”); 11、更新表中数据： mysql&gt;update 表名 set 字段名1=’a’,字段名2=’b’ where 字段名3=’c’; 12、用文本方式将数据装入数据表中： mysql&gt;load data local infile “/root/mysql.txt” into table 表名; 13、导入.sql文件命令： mysql&gt;use 数据库名; mysql&gt;source /root/mysql.sql; 14、命令行修改root密码： mysql&gt;update mysql.user set password=PASSWORD(‘新密码’) where user=’root’; mysql&gt;flush privileges; 15、显示use的数据库名： mysql&gt;select database(); 16、显示当前的user： mysql&gt;select user(); 备份数据库 1.导出整个数据库，导出文件默认是存在当前操作目录下 mysqldump -u 用户名 -p 数据库名 &gt; 导出的文件名mysqldump -u user_name -p123456 database_name &gt; outfile_name.sql2.导出一个表 mysqldump -u 用户名 -p 数据库名 表名&gt; 导出的文件名mysqldump -u user_name -p database_name table_name &gt; outfile_name.sql3.导出一个数据库结构 mysqldump -u user_name -p -d –add-drop-table database_name &gt; outfile_name.sql-d 没有数据 –add-drop-table 在每个create语句之前增加一个drop table 4.带语言参数导出 mysqldump -uroot -p –default-character-set=latin1 –set-charset=gbk –skip-opt database_name &gt; outfile_name.sql]]></content>
      <categories>
        <category>技术</category>
      </categories>
      <tags>
        <tag>linux</tag>
        <tag>mysql</tag>
        <tag>数据库</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[ubuntu修改/etc/fstab文件无法进入系统]]></title>
    <url>%2F2016%2F05%2F26%2F2016-05-26-ubuntu-modify-fstab-not-enter-system%2F</url>
    <content type="text"><![CDATA[ubuntu修改/etc/fstab文件无法进入系统： 重启进入第二个选项： 进入drop to root shell prompt #mount -o remount,rw / 然后vim /etc/fstab修改配置文件保存退出，重启即可。 redhat： 在虚拟机刚开启时按e键，进入到界面，有如下条目 Enterprise linux (2.6.18-128.el5) 然后按e键，进入一个界面，如下条目 kernel /vmlinuz-2.6.18-128.el5 ro root=LABEL=/ rhgb quite把光标移动这行后，再按一下e键，进入编辑这行；在行尾条一个空格 ，然后输入 linux single 也就是类似如下的： kernel /vmlinuz-2.6.18-128.el5 ro root=LABEL=/ rhgb quite linux quite结束编辑，按回车返回； 接着我们要启动系统，按一下b键启动； 在启动过程中，因为/etc/fstab修改错误，导致磁盘检查报错。此时，输入root密码后，进入字符界面， 系统是只读的（执行vi /etc/fstab后，无法保存，报错说read only），要运行下面的命令； #mount -o remount,rw / 然后，执行如下操作，改正/etc/fstab，保存退出，重启 #vi /etc/fstab #reboot]]></content>
      <categories>
        <category>linux</category>
      </categories>
      <tags>
        <tag>linux</tag>
        <tag>centos</tag>
        <tag>ubuntu</tag>
        <tag>系统</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[CentOS6.6安装配置wordpress]]></title>
    <url>%2F2016%2F05%2F25%2F2016-05-25-centos6-install-wordpress%2F</url>
    <content type="text"><![CDATA[1.安装配置php环境： yum install mysql-server php php-mysql httpd -y a. 启动mysql，创建数据库和用户： mysql create database db_name; grant all on db_name.* to username@localhost identified by ‘passwd’; 下载安装wordpress： a. 访问本机ip地址，显示apache界面表示正常，不正常可以查看一下防火墙配置； b. 官网下载wordpress安装包，解压以后放到站点目录； c.修改/etc/httpd/conf/httpd.conf 中 DocumentRoot “/var/html/wordpress” DirectoryIndex ?index.html index.html.var index.php d. 进入wordpress目录修改php配置： cp wp-config-sample.php wp-config.phpvim wp-config.php 配置mysql数据库； 修改wordpress目录权限：chown apache. * -R 配置以后重启apache：/etc/init.d/httpd restart c. 访问本机站点，按照提示安装wordpress ;]]></content>
      <categories>
        <category>技术</category>
      </categories>
      <tags>
        <tag>linux</tag>
      </tags>
  </entry>
</search>
